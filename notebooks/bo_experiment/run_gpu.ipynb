{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kacperwyrwal/miniconda3/envs/mdgp_requirements_test7/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "INFO: Using numpy backend\n",
      "INFO: Created a temporary directory at /tmp/tmpuc7xz916\n",
      "INFO: Writing /tmp/tmpuc7xz916/_remote_module_non_scriptable.py\n"
     ]
    }
   ],
   "source": [
    "import geometric_kernels.torch\n",
    "import os \n",
    "import warnings \n",
    "import torch \n",
    "from mdgp.bo_experiment.data import get_initial_data\n",
    "from mdgp.bo_experiment.model import create_model\n",
    "from mdgp.experiment_utils.logging import CSVLogger, finalize \n",
    "from mdgp.bo_experiment.fit import fit\n",
    "from mdgp.bo_experiment import ExperimentConfig, set_experiment_seed\n",
    "from mdgp.bo_experiment import BOArguments, ModelArguments, FitArguments, optimize_acqf_manifold\n",
    "from mdgp.experiment_utils import log, finalize \n",
    "from tqdm.autonotebook import tqdm \n",
    "from plotly import graph_objects as go\n",
    "from mdgp.utils import sphere_meshgrid\n",
    "\n",
    "torch.set_default_dtype(torch.float64)\n",
    "set_experiment_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def base_trace(num_meshgrid=50): \n",
    "    meshgrid = sphere_meshgrid(num_meshgrid, num_meshgrid)\n",
    "    x_meshgrid, y_meshgrid, z_meshgrid = meshgrid.unbind(-1)\n",
    "    grey_sphere_trace = go.Surface(x=x_meshgrid, y=y_meshgrid, z=z_meshgrid, colorscale='Greys', showscale=False)\n",
    "    return grey_sphere_trace\n",
    "\n",
    "\n",
    "def observations_trace(x, y=None):\n",
    "    x_scatter, y_scatter, z_scatter = x.mul(1.02).unbind(-1)\n",
    "    if y is None:\n",
    "        color_scatter = torch.zeros(x.shape[0])\n",
    "    else: \n",
    "        color_scatter = y.squeeze(-1)\n",
    "    scatter_trace = go.Scatter3d(x=x_scatter, y=y_scatter, z=z_scatter, mode='markers', marker=dict(size=5, color=color_scatter, colorscale='Viridis'))\n",
    "    return scatter_trace\n",
    "\n",
    "\n",
    "def prediction_trace(prediction_function, num_meshgrid=50):\n",
    "    meshgrid = sphere_meshgrid(num_meshgrid, num_meshgrid)\n",
    "    x_meshgrid, y_meshgrid, z_meshgrid = meshgrid.unbind(-1)\n",
    "    y = prediction_function(meshgrid.view(-1, meshgrid.shape[-1])).view_as(x_meshgrid)\n",
    "    sphere_trace = go.Surface(x=x_meshgrid, y=y_meshgrid, z=z_meshgrid, surfacecolor=y, colorscale='Viridis', showscale=True)\n",
    "    return sphere_trace\n",
    "\n",
    "\n",
    "def target_trace(target_function, num_meshgrid=50):\n",
    "    # 1. Compute y by evaluating target function on meshgrid\n",
    "    meshgrid = sphere_meshgrid(num_meshgrid, num_meshgrid)\n",
    "    x_meshgrid, y_meshgrid, z_meshgrid = meshgrid.unbind(-1)\n",
    "    y = torch.zeros_like(x_meshgrid)\n",
    "    for i in range(num_meshgrid): \n",
    "        for j in range(num_meshgrid): \n",
    "            y[i, j] = target_function(meshgrid[i, j])\n",
    "    color_meshgrid = y.squeeze(-1)\n",
    "\n",
    "    # 2. Plot a sphere colored by y\n",
    "    sphere_trace = go.Surface(x=x_meshgrid, y=y_meshgrid, z=z_meshgrid, surfacecolor=color_meshgrid, colorscale='Viridis', showscale=True)\n",
    "    return sphere_trace\n",
    "\n",
    "\n",
    "def plot_traces(*traces): \n",
    "    fig = go.Figure()\n",
    "    fig.add_traces([trace for trace in traces if trace is not None])\n",
    "    return fig\n",
    "\n",
    "\n",
    "def plot_observations(x, y=None, num_meshgrid=50): \n",
    "    # 1. Plot a grey sphere with meshgrid\n",
    "    grey_sphere_trace = base_trace(num_meshgrid=num_meshgrid)\n",
    "\n",
    "    # 2. Plot a scatter plot of observations slightly above the sphere\n",
    "    scatter_trace = observations_trace(x, y=None)\n",
    "\n",
    "    # 3. Add all traces to figure\n",
    "    fig = plot_traces(grey_sphere_trace, scatter_trace)\n",
    "    return fig\n",
    "\n",
    "\n",
    "def plot_prediction(prediction_function, x=None, y=None, num_meshgrid=50):\n",
    "    # 1. Plot a sphere colored by prediction function \n",
    "    sphere_trace = prediction_trace(prediction_function, num_meshgrid=num_meshgrid)\n",
    "\n",
    "    # 2. (Optional) Plot observations slightly above the sphere\n",
    "    if x is not None and y is not None: \n",
    "        scatter_trace = observations_trace(x, y)\n",
    "    else: \n",
    "        scatter_trace = None\n",
    "\n",
    "    # 3. Add all traces to figure\n",
    "    fig = plot_traces(sphere_trace, scatter_trace)\n",
    "    return fig\n",
    "\n",
    "def plot_target(target_function, num_meshgrid=50): \n",
    "    # 1. Plot a sphere colored by target function\n",
    "    sphere_trace = target_trace(target_function, num_meshgrid=num_meshgrid)\n",
    "\n",
    "    # 2. Add all traces to figure\n",
    "    fig = plot_traces(sphere_trace)\n",
    "    return fig "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from botorch.fit import fit_gpytorch_mll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXACT_ACQUISITION_X = None \n",
    "EXACT_ACQUISITION_Y = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPU acceleration would only be potentially useful for deep models; however, we might want it for exact models too, since a BO run might begin with exact and transition to deep \n",
    "We will certainly need to move the inputs and models to the chosen device \n",
    "We need also set the default device for the LAB backend "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_bo(initial_data, target_function, bo_args: BOArguments, model_args: ModelArguments, fit_args: FitArguments, loggers=None, show_fit_progress=False):\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "    x = initial_data\n",
    "    y = target_function(initial_data)\n",
    "    best_x = initial_data[y.argmin()]\n",
    "    best_y = y.min()\n",
    "         \n",
    "    pbar = tqdm(range(bo_args.num_iter), desc=\"BO\")\n",
    "    for iter in pbar: \n",
    "        # 1. Create model, mll, and optimizer \n",
    "        inducing_points = x\n",
    "        model = create_model(model_args=model_args, train_x=x, train_y=y, inducing_points=inducing_points)\n",
    "        optimizer = model_args.optimizer_factory(model=model.base_model, lr=fit_args.lr)\n",
    "        mll = model_args.mll_factory(model.base_model, y=y)\n",
    "\n",
    "        # 2. Fit model to observations  \n",
    "        if model_args.model_name == 'exact':\n",
    "            fit_gpytorch_mll(mll=mll)\n",
    "        elif model_args.model_name == 'deep':\n",
    "            print(\"Fitting...\", end='\\r')\n",
    "            fit(model=model.base_model, optimizer=optimizer, criterion=mll, train_inputs=x, train_targets=y, fit_args=fit_args, show_progress=show_fit_progress)\n",
    "            print(\"Fitted      \", end='\\r')\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown model name: {model_args.model_name}\")\n",
    "\n",
    "        def get_mean(x): \n",
    "            with torch.no_grad(): \n",
    "                if model_args.model_name == 'exact':\n",
    "                    model.eval()\n",
    "                    return model(x).mean\n",
    "                elif model_args.model_name == 'deep':\n",
    "                    return model.base_model(x, mean=True)\n",
    "        if iter % 5 == 0:\n",
    "            plot_prediction(get_mean, x=x, y=y, num_meshgrid=100).show()\n",
    "\n",
    "        # 3. Get acquisition function for the fitted model \n",
    "        acq_function = model_args.acqf_factory(model=model, best_f=best_y)\n",
    "\n",
    "        # 3. Get new observation \n",
    "        with torch.no_grad():\n",
    "            model.resample_weights()\n",
    "            new_x, _ = optimize_acqf_manifold(acq_function=acq_function, bo_args=bo_args)\n",
    "\n",
    "        # 4. Observe target function at acquired point and add to previous observations \n",
    "        new_x = new_x.unsqueeze(-2)\n",
    "        new_y = target_function(new_x)#.squeeze(0)\n",
    "\n",
    "        print(new_x, new_y)\n",
    "\n",
    "        x = torch.cat([x, new_x])\n",
    "        y = torch.cat([y, new_y])\n",
    "\n",
    "        # 5. Update best observation\n",
    "        if new_y < best_y: \n",
    "            best_y = new_y \n",
    "            best_x = new_x.squeeze()\n",
    "\n",
    "        # 6. Log best observation\n",
    "        metrics = dict(\n",
    "            best_x=best_x.tolist(), \n",
    "            best_y=best_y.item(),\n",
    "        )\n",
    "        log(loggers=loggers, metrics=metrics)\n",
    "        pbar.set_postfix(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_experiment(experiment_config: ExperimentConfig, dir_path: str, show_fit_progress: bool = False):\n",
    "    print(f\"Running experiment with the config: {os.path.join(dir_path, experiment_config.file_name)}\")\n",
    "    # 0. Unpack arguments\n",
    "    model_args, data_args, fit_args, bo_args = (\n",
    "        experiment_config.model_arguments, experiment_config.data_arguments, experiment_config.fit_arguments, experiment_config.bo_arguments\n",
    "    )\n",
    "\n",
    "    # 1. Get initial data and target function. Target function is observed at input points acquired via BO \n",
    "    print(\"Creating initial observations..\")\n",
    "    target_function = data_args.target_function\n",
    "    initial_data = get_initial_data(data_args=data_args)\n",
    "\n",
    "    # 2. Set up logger for capturing points and observations acquired via BO\n",
    "    bo_loggers = [CSVLogger(root_dir=os.path.join(dir_path, 'bo'))]\n",
    "\n",
    "    # 3. Run BO loop\n",
    "    print(\"Running Bayesian optimisation..\")\n",
    "    run_bo(initial_data=initial_data, target_function=target_function, bo_args=bo_args, model_args=model_args, fit_args=fit_args, loggers=bo_loggers, show_fit_progress=show_fit_progress)\n",
    "    finalize(bo_loggers)\n",
    "    \n",
    "    print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Global seed set to 0\n",
      "INFO: Global seed set to 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiment with the config: ./config.json\n",
      "Creating initial observations..\n",
      "Running Bayesian optimisation..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BO:   0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In fit_gpytorch_mll_scipy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BO:   0%|          | 0/200 [00:01<?, ?it/s]\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/home/kacperwyrwal/MDGP/MDGP-all-bo/notebooks/bo_experiment/run.ipynb Cell 8\u001b[0m line \u001b[0;36m6\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/kacperwyrwal/MDGP/MDGP-all-bo/notebooks/bo_experiment/run.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m experiment_config\u001b[39m.\u001b[39mdata_arguments\u001b[39m.\u001b[39mtarget_function_name \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mdgp_sample\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/kacperwyrwal/MDGP/MDGP-all-bo/notebooks/bo_experiment/run.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m set_experiment_seed(\u001b[39m0\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/kacperwyrwal/MDGP/MDGP-all-bo/notebooks/bo_experiment/run.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m run_experiment(experiment_config, \u001b[39m'\u001b[39;49m\u001b[39m./\u001b[39;49m\u001b[39m'\u001b[39;49m, show_fit_progress\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[1;32m/home/kacperwyrwal/MDGP/MDGP-all-bo/notebooks/bo_experiment/run.ipynb Cell 8\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/kacperwyrwal/MDGP/MDGP-all-bo/notebooks/bo_experiment/run.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=32'>33</a>\u001b[0m \u001b[39m# 3. Run BO loop\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/kacperwyrwal/MDGP/MDGP-all-bo/notebooks/bo_experiment/run.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=33'>34</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mRunning Bayesian optimisation..\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/kacperwyrwal/MDGP/MDGP-all-bo/notebooks/bo_experiment/run.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=34'>35</a>\u001b[0m run_bo(initial_data\u001b[39m=\u001b[39;49minitial_data, target_function\u001b[39m=\u001b[39;49mtarget_function, bo_args\u001b[39m=\u001b[39;49mbo_args, model_args\u001b[39m=\u001b[39;49mmodel_args, fit_args\u001b[39m=\u001b[39;49mfit_args, loggers\u001b[39m=\u001b[39;49mbo_loggers, show_fit_progress\u001b[39m=\u001b[39;49mshow_fit_progress)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/kacperwyrwal/MDGP/MDGP-all-bo/notebooks/bo_experiment/run.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=35'>36</a>\u001b[0m finalize(bo_loggers)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/kacperwyrwal/MDGP/MDGP-all-bo/notebooks/bo_experiment/run.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=37'>38</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mDone!\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;32m/home/kacperwyrwal/MDGP/MDGP-all-bo/notebooks/bo_experiment/run.ipynb Cell 8\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/kacperwyrwal/MDGP/MDGP-all-bo/notebooks/bo_experiment/run.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=34'>35</a>\u001b[0m \u001b[39m# 2. Fit model to observations  \u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/kacperwyrwal/MDGP/MDGP-all-bo/notebooks/bo_experiment/run.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=35'>36</a>\u001b[0m \u001b[39mif\u001b[39;00m model_args\u001b[39m.\u001b[39mmodel_name \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mexact\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/kacperwyrwal/MDGP/MDGP-all-bo/notebooks/bo_experiment/run.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=36'>37</a>\u001b[0m     fit_gpytorch_mll(mll\u001b[39m=\u001b[39;49mmll)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/kacperwyrwal/MDGP/MDGP-all-bo/notebooks/bo_experiment/run.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=37'>38</a>\u001b[0m \u001b[39melif\u001b[39;00m model_args\u001b[39m.\u001b[39mmodel_name \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mdeep\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/kacperwyrwal/MDGP/MDGP-all-bo/notebooks/bo_experiment/run.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=38'>39</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mFitting...\u001b[39m\u001b[39m\"\u001b[39m, end\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\\r\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/mdgp_requirements_test7/lib/python3.11/site-packages/botorch/fit.py:105\u001b[0m, in \u001b[0;36mfit_gpytorch_mll\u001b[0;34m(mll, closure, optimizer, closure_kwargs, optimizer_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[39mif\u001b[39;00m optimizer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:  \u001b[39m# defer to per-method defaults\u001b[39;00m\n\u001b[1;32m    103\u001b[0m     kwargs[\u001b[39m\"\u001b[39m\u001b[39moptimizer\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m optimizer\n\u001b[0;32m--> 105\u001b[0m \u001b[39mreturn\u001b[39;00m FitGPyTorchMLL(\n\u001b[1;32m    106\u001b[0m     mll,\n\u001b[1;32m    107\u001b[0m     \u001b[39mtype\u001b[39;49m(mll\u001b[39m.\u001b[39;49mlikelihood),\n\u001b[1;32m    108\u001b[0m     \u001b[39mtype\u001b[39;49m(mll\u001b[39m.\u001b[39;49mmodel),\n\u001b[1;32m    109\u001b[0m     closure\u001b[39m=\u001b[39;49mclosure,\n\u001b[1;32m    110\u001b[0m     closure_kwargs\u001b[39m=\u001b[39;49mclosure_kwargs,\n\u001b[1;32m    111\u001b[0m     optimizer_kwargs\u001b[39m=\u001b[39;49moptimizer_kwargs,\n\u001b[1;32m    112\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    113\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/mdgp_requirements_test7/lib/python3.11/site-packages/botorch/utils/dispatcher.py:93\u001b[0m, in \u001b[0;36mDispatcher.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     91\u001b[0m func \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__getitem__\u001b[39m(types\u001b[39m=\u001b[39mtypes)\n\u001b[1;32m     92\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 93\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     94\u001b[0m \u001b[39mexcept\u001b[39;00m MDNotImplementedError:\n\u001b[1;32m     95\u001b[0m     \u001b[39m# Traverses registered methods in order, yields whenever a match is found\u001b[39;00m\n\u001b[1;32m     96\u001b[0m     funcs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_iter(\u001b[39m*\u001b[39mtypes)\n",
      "File \u001b[0;32m~/miniconda3/envs/mdgp_requirements_test7/lib/python3.11/site-packages/botorch/fit.py:252\u001b[0m, in \u001b[0;36m_fit_fallback\u001b[0;34m(mll, _, __, closure, optimizer, closure_kwargs, optimizer_kwargs, max_attempts, warning_handler, caught_exception_types, **ignore)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[39mwith\u001b[39;00m catch_warnings(record\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m) \u001b[39mas\u001b[39;00m warning_list, debug(\u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m    251\u001b[0m     simplefilter(\u001b[39m\"\u001b[39m\u001b[39malways\u001b[39m\u001b[39m\"\u001b[39m, category\u001b[39m=\u001b[39mOptimizationWarning)\n\u001b[0;32m--> 252\u001b[0m     optimizer(mll, closure\u001b[39m=\u001b[39;49mclosure, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49moptimizer_kwargs)\n\u001b[1;32m    254\u001b[0m \u001b[39m# Resolved warnings and determine whether or not to retry\u001b[39;00m\n\u001b[1;32m    255\u001b[0m done \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/mdgp_requirements_test7/lib/python3.11/site-packages/botorch/optim/fit.py:121\u001b[0m, in \u001b[0;36mfit_gpytorch_mll_scipy\u001b[0;34m(mll, parameters, bounds, closure, closure_kwargs, method, options, callback, timeout_sec)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[39mif\u001b[39;00m closure_kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    119\u001b[0m     closure \u001b[39m=\u001b[39m partial(closure, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mclosure_kwargs)\n\u001b[0;32m--> 121\u001b[0m result \u001b[39m=\u001b[39m scipy_minimize(\n\u001b[1;32m    122\u001b[0m     closure\u001b[39m=\u001b[39;49mclosure,\n\u001b[1;32m    123\u001b[0m     parameters\u001b[39m=\u001b[39;49mparameters,\n\u001b[1;32m    124\u001b[0m     bounds\u001b[39m=\u001b[39;49mbounds,\n\u001b[1;32m    125\u001b[0m     method\u001b[39m=\u001b[39;49mmethod,\n\u001b[1;32m    126\u001b[0m     options\u001b[39m=\u001b[39;49moptions,\n\u001b[1;32m    127\u001b[0m     callback\u001b[39m=\u001b[39;49mcallback,\n\u001b[1;32m    128\u001b[0m     timeout_sec\u001b[39m=\u001b[39;49mtimeout_sec,\n\u001b[1;32m    129\u001b[0m )\n\u001b[1;32m    130\u001b[0m \u001b[39mif\u001b[39;00m result\u001b[39m.\u001b[39mstatus \u001b[39m!=\u001b[39m OptimizationStatus\u001b[39m.\u001b[39mSUCCESS:\n\u001b[1;32m    131\u001b[0m     warn(\n\u001b[1;32m    132\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m`scipy_minimize` terminated with status \u001b[39m\u001b[39m{\u001b[39;00mresult\u001b[39m.\u001b[39mstatus\u001b[39m}\u001b[39;00m\u001b[39m, displaying\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    133\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m original message from `scipy.optimize.minimize`: \u001b[39m\u001b[39m{\u001b[39;00mresult\u001b[39m.\u001b[39mmessage\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    134\u001b[0m         OptimizationWarning,\n\u001b[1;32m    135\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/mdgp_requirements_test7/lib/python3.11/site-packages/botorch/optim/core.py:109\u001b[0m, in \u001b[0;36mscipy_minimize\u001b[0;34m(closure, parameters, bounds, callback, x0, method, options, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m         result \u001b[39m=\u001b[39m OptimizationResult(\n\u001b[1;32m    102\u001b[0m             step\u001b[39m=\u001b[39m\u001b[39mnext\u001b[39m(call_counter),\n\u001b[1;32m    103\u001b[0m             fval\u001b[39m=\u001b[39m\u001b[39mfloat\u001b[39m(wrapped_closure(x)[\u001b[39m0\u001b[39m]),\n\u001b[1;32m    104\u001b[0m             status\u001b[39m=\u001b[39mOptimizationStatus\u001b[39m.\u001b[39mRUNNING,\n\u001b[1;32m    105\u001b[0m             runtime\u001b[39m=\u001b[39mmonotonic() \u001b[39m-\u001b[39m start_time,\n\u001b[1;32m    106\u001b[0m         )\n\u001b[1;32m    107\u001b[0m         \u001b[39mreturn\u001b[39;00m callback(parameters, result)  \u001b[39m# pyre-ignore [29]\u001b[39;00m\n\u001b[0;32m--> 109\u001b[0m raw \u001b[39m=\u001b[39m minimize_with_timeout(\n\u001b[1;32m    110\u001b[0m     wrapped_closure,\n\u001b[1;32m    111\u001b[0m     wrapped_closure\u001b[39m.\u001b[39;49mstate \u001b[39mif\u001b[39;49;00m x0 \u001b[39mis\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m \u001b[39melse\u001b[39;49;00m x0\u001b[39m.\u001b[39;49mastype(np_float64, copy\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m),\n\u001b[1;32m    112\u001b[0m     jac\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    113\u001b[0m     bounds\u001b[39m=\u001b[39;49mbounds_np,\n\u001b[1;32m    114\u001b[0m     method\u001b[39m=\u001b[39;49mmethod,\n\u001b[1;32m    115\u001b[0m     options\u001b[39m=\u001b[39;49moptions,\n\u001b[1;32m    116\u001b[0m     callback\u001b[39m=\u001b[39;49mwrapped_callback,\n\u001b[1;32m    117\u001b[0m     timeout_sec\u001b[39m=\u001b[39;49mtimeout_sec,\n\u001b[1;32m    118\u001b[0m )\n\u001b[1;32m    120\u001b[0m \u001b[39m# Post-processing and outcome handling\u001b[39;00m\n\u001b[1;32m    121\u001b[0m wrapped_closure\u001b[39m.\u001b[39mstate \u001b[39m=\u001b[39m asarray(raw\u001b[39m.\u001b[39mx)  \u001b[39m# set parameter state to optimal values\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/mdgp_requirements_test7/lib/python3.11/site-packages/botorch/optim/utils/timeout.py:80\u001b[0m, in \u001b[0;36mminimize_with_timeout\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options, timeout_sec)\u001b[0m\n\u001b[1;32m     77\u001b[0m     wrapped_callback \u001b[39m=\u001b[39m callback\n\u001b[1;32m     79\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 80\u001b[0m     \u001b[39mreturn\u001b[39;00m optimize\u001b[39m.\u001b[39;49mminimize(\n\u001b[1;32m     81\u001b[0m         fun\u001b[39m=\u001b[39;49mfun,\n\u001b[1;32m     82\u001b[0m         x0\u001b[39m=\u001b[39;49mx0,\n\u001b[1;32m     83\u001b[0m         args\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m     84\u001b[0m         method\u001b[39m=\u001b[39;49mmethod,\n\u001b[1;32m     85\u001b[0m         jac\u001b[39m=\u001b[39;49mjac,\n\u001b[1;32m     86\u001b[0m         hess\u001b[39m=\u001b[39;49mhess,\n\u001b[1;32m     87\u001b[0m         hessp\u001b[39m=\u001b[39;49mhessp,\n\u001b[1;32m     88\u001b[0m         bounds\u001b[39m=\u001b[39;49mbounds,\n\u001b[1;32m     89\u001b[0m         constraints\u001b[39m=\u001b[39;49mconstraints,\n\u001b[1;32m     90\u001b[0m         tol\u001b[39m=\u001b[39;49mtol,\n\u001b[1;32m     91\u001b[0m         callback\u001b[39m=\u001b[39;49mwrapped_callback,\n\u001b[1;32m     92\u001b[0m         options\u001b[39m=\u001b[39;49moptions,\n\u001b[1;32m     93\u001b[0m     )\n\u001b[1;32m     94\u001b[0m \u001b[39mexcept\u001b[39;00m OptimizationTimeoutError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     95\u001b[0m     msg \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mOptimization timed out after \u001b[39m\u001b[39m{\u001b[39;00me\u001b[39m.\u001b[39mruntime\u001b[39m}\u001b[39;00m\u001b[39m seconds.\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/mdgp_requirements_test7/lib/python3.11/site-packages/scipy/optimize/_minimize.py:710\u001b[0m, in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    707\u001b[0m     res \u001b[39m=\u001b[39m _minimize_newtoncg(fun, x0, args, jac, hess, hessp, callback,\n\u001b[1;32m    708\u001b[0m                              \u001b[39m*\u001b[39m\u001b[39m*\u001b[39moptions)\n\u001b[1;32m    709\u001b[0m \u001b[39melif\u001b[39;00m meth \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39ml-bfgs-b\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m--> 710\u001b[0m     res \u001b[39m=\u001b[39m _minimize_lbfgsb(fun, x0, args, jac, bounds,\n\u001b[1;32m    711\u001b[0m                            callback\u001b[39m=\u001b[39;49mcallback, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49moptions)\n\u001b[1;32m    712\u001b[0m \u001b[39melif\u001b[39;00m meth \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mtnc\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    713\u001b[0m     res \u001b[39m=\u001b[39m _minimize_tnc(fun, x0, args, jac, bounds, callback\u001b[39m=\u001b[39mcallback,\n\u001b[1;32m    714\u001b[0m                         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39moptions)\n",
      "File \u001b[0;32m~/miniconda3/envs/mdgp_requirements_test7/lib/python3.11/site-packages/scipy/optimize/_lbfgsb_py.py:365\u001b[0m, in \u001b[0;36m_minimize_lbfgsb\u001b[0;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[1;32m    359\u001b[0m task_str \u001b[39m=\u001b[39m task\u001b[39m.\u001b[39mtobytes()\n\u001b[1;32m    360\u001b[0m \u001b[39mif\u001b[39;00m task_str\u001b[39m.\u001b[39mstartswith(\u001b[39mb\u001b[39m\u001b[39m'\u001b[39m\u001b[39mFG\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m    361\u001b[0m     \u001b[39m# The minimization routine wants f and g at the current x.\u001b[39;00m\n\u001b[1;32m    362\u001b[0m     \u001b[39m# Note that interruptions due to maxfun are postponed\u001b[39;00m\n\u001b[1;32m    363\u001b[0m     \u001b[39m# until the completion of the current minimization iteration.\u001b[39;00m\n\u001b[1;32m    364\u001b[0m     \u001b[39m# Overwrite f and g:\u001b[39;00m\n\u001b[0;32m--> 365\u001b[0m     f, g \u001b[39m=\u001b[39m func_and_grad(x)\n\u001b[1;32m    366\u001b[0m \u001b[39melif\u001b[39;00m task_str\u001b[39m.\u001b[39mstartswith(\u001b[39mb\u001b[39m\u001b[39m'\u001b[39m\u001b[39mNEW_X\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m    367\u001b[0m     \u001b[39m# new iteration\u001b[39;00m\n\u001b[1;32m    368\u001b[0m     n_iterations \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/mdgp_requirements_test7/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py:285\u001b[0m, in \u001b[0;36mScalarFunction.fun_and_grad\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m np\u001b[39m.\u001b[39marray_equal(x, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mx):\n\u001b[1;32m    284\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_x_impl(x)\n\u001b[0;32m--> 285\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_update_fun()\n\u001b[1;32m    286\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_grad()\n\u001b[1;32m    287\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mg\n",
      "File \u001b[0;32m~/miniconda3/envs/mdgp_requirements_test7/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py:251\u001b[0m, in \u001b[0;36mScalarFunction._update_fun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_update_fun\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    250\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf_updated:\n\u001b[0;32m--> 251\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_update_fun_impl()\n\u001b[1;32m    252\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf_updated \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/mdgp_requirements_test7/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py:155\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.update_fun\u001b[0;34m()\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mupdate_fun\u001b[39m():\n\u001b[0;32m--> 155\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf \u001b[39m=\u001b[39m fun_wrapped(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mx)\n",
      "File \u001b[0;32m~/miniconda3/envs/mdgp_requirements_test7/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py:137\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.fun_wrapped\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnfev \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    134\u001b[0m \u001b[39m# Send a copy because the user may overwrite it.\u001b[39;00m\n\u001b[1;32m    135\u001b[0m \u001b[39m# Overwriting results in undefined behaviour because\u001b[39;00m\n\u001b[1;32m    136\u001b[0m \u001b[39m# fun(self.x) will change self.x, with the two no longer linked.\u001b[39;00m\n\u001b[0;32m--> 137\u001b[0m fx \u001b[39m=\u001b[39m fun(np\u001b[39m.\u001b[39;49mcopy(x), \u001b[39m*\u001b[39;49margs)\n\u001b[1;32m    138\u001b[0m \u001b[39m# Make sure the function returns a true scalar\u001b[39;00m\n\u001b[1;32m    139\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m np\u001b[39m.\u001b[39misscalar(fx):\n",
      "File \u001b[0;32m~/miniconda3/envs/mdgp_requirements_test7/lib/python3.11/site-packages/scipy/optimize/_optimize.py:77\u001b[0m, in \u001b[0;36mMemoizeJac.__call__\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, x, \u001b[39m*\u001b[39margs):\n\u001b[1;32m     76\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\" returns the function value \"\"\"\u001b[39;00m\n\u001b[0;32m---> 77\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_compute_if_needed(x, \u001b[39m*\u001b[39;49margs)\n\u001b[1;32m     78\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_value\n",
      "File \u001b[0;32m~/miniconda3/envs/mdgp_requirements_test7/lib/python3.11/site-packages/scipy/optimize/_optimize.py:71\u001b[0m, in \u001b[0;36mMemoizeJac._compute_if_needed\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m np\u001b[39m.\u001b[39mall(x \u001b[39m==\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mx) \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_value \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mjac \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     70\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mx \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(x)\u001b[39m.\u001b[39mcopy()\n\u001b[0;32m---> 71\u001b[0m     fg \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfun(x, \u001b[39m*\u001b[39;49margs)\n\u001b[1;32m     72\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mjac \u001b[39m=\u001b[39m fg[\u001b[39m1\u001b[39m]\n\u001b[1;32m     73\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_value \u001b[39m=\u001b[39m fg[\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/mdgp_requirements_test7/lib/python3.11/site-packages/botorch/optim/closures/core.py:160\u001b[0m, in \u001b[0;36mNdarrayOptimizationClosure.__call__\u001b[0;34m(self, state, **kwargs)\u001b[0m\n\u001b[1;32m    158\u001b[0m         index \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m size\n\u001b[1;32m    159\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m--> 160\u001b[0m     value, grads \u001b[39m=\u001b[39m _handle_numerical_errors(e, x\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstate, dtype\u001b[39m=\u001b[39;49mnp_float64)\n\u001b[1;32m    162\u001b[0m \u001b[39mreturn\u001b[39;00m value, grads\n",
      "File \u001b[0;32m~/miniconda3/envs/mdgp_requirements_test7/lib/python3.11/site-packages/botorch/optim/utils/common.py:52\u001b[0m, in \u001b[0;36m_handle_numerical_errors\u001b[0;34m(error, x, dtype)\u001b[0m\n\u001b[1;32m     50\u001b[0m     _dtype \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mdtype \u001b[39mif\u001b[39;00m dtype \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m dtype\n\u001b[1;32m     51\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39mfull((), \u001b[39m\"\u001b[39m\u001b[39mnan\u001b[39m\u001b[39m\"\u001b[39m, dtype\u001b[39m=\u001b[39m_dtype), np\u001b[39m.\u001b[39mfull_like(x, \u001b[39m\"\u001b[39m\u001b[39mnan\u001b[39m\u001b[39m\"\u001b[39m, dtype\u001b[39m=\u001b[39m_dtype)\n\u001b[0;32m---> 52\u001b[0m \u001b[39mraise\u001b[39;00m error\n",
      "File \u001b[0;32m~/miniconda3/envs/mdgp_requirements_test7/lib/python3.11/site-packages/botorch/optim/closures/core.py:150\u001b[0m, in \u001b[0;36mNdarrayOptimizationClosure.__call__\u001b[0;34m(self, state, **kwargs)\u001b[0m\n\u001b[1;32m    147\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate \u001b[39m=\u001b[39m state\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m     value_tensor, grad_tensors \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclosure(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m     value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mas_array(value_tensor)\n\u001b[1;32m    152\u001b[0m     grads \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_gradient_ndarray(fill_value\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfill_value)\n",
      "File \u001b[0;32m~/miniconda3/envs/mdgp_requirements_test7/lib/python3.11/site-packages/botorch/optim/closures/core.py:64\u001b[0m, in \u001b[0;36mForwardBackwardClosure.__call__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Tensor, Tuple[Optional[Tensor], \u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m]]:\n\u001b[1;32m     63\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontext_manager():\n\u001b[0;32m---> 64\u001b[0m         values \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     65\u001b[0m         value \u001b[39m=\u001b[39m values \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreducer \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreducer(values)\n\u001b[1;32m     66\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbackward(value)\n",
      "File \u001b[0;32m~/miniconda3/envs/mdgp_requirements_test7/lib/python3.11/site-packages/botorch/optim/closures/model_closures.py:176\u001b[0m, in \u001b[0;36m_get_loss_closure_exact_internal.<locals>.closure\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mclosure\u001b[39m(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m    175\u001b[0m     model_output \u001b[39m=\u001b[39m mll\u001b[39m.\u001b[39mmodel(\u001b[39m*\u001b[39mmll\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mtrain_inputs)\n\u001b[0;32m--> 176\u001b[0m     log_likelihood \u001b[39m=\u001b[39m mll(\n\u001b[1;32m    177\u001b[0m         model_output, mll\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mtrain_targets, \u001b[39m*\u001b[39;49mmll\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mtrain_inputs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m    178\u001b[0m     )\n\u001b[1;32m    179\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39m-\u001b[39mlog_likelihood\n",
      "File \u001b[0;32m~/miniconda3/envs/mdgp_requirements_test7/lib/python3.11/site-packages/gpytorch/module.py:31\u001b[0m, in \u001b[0;36mModule.__call__\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39minputs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Union[Tensor, Distribution, LinearOperator]:\n\u001b[0;32m---> 31\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(\u001b[39m*\u001b[39;49minputs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     32\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(outputs, \u001b[39mlist\u001b[39m):\n\u001b[1;32m     33\u001b[0m         \u001b[39mreturn\u001b[39;00m [_validate_module_outputs(output) \u001b[39mfor\u001b[39;00m output \u001b[39min\u001b[39;00m outputs]\n",
      "File \u001b[0;32m~/miniconda3/envs/mdgp_requirements_test7/lib/python3.11/site-packages/gpytorch/mlls/exact_marginal_log_likelihood.py:64\u001b[0m, in \u001b[0;36mExactMarginalLogLikelihood.forward\u001b[0;34m(self, function_dist, target, *params)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[39m# Get the log prob of the marginal distribution\u001b[39;00m\n\u001b[1;32m     63\u001b[0m output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlikelihood(function_dist, \u001b[39m*\u001b[39mparams)\n\u001b[0;32m---> 64\u001b[0m res \u001b[39m=\u001b[39m output\u001b[39m.\u001b[39;49mlog_prob(target)\n\u001b[1;32m     65\u001b[0m res \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_add_other_terms(res, params)\n\u001b[1;32m     67\u001b[0m \u001b[39m# Scale by the amount of data we have\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/mdgp_requirements_test7/lib/python3.11/site-packages/gpytorch/distributions/multivariate_normal.py:171\u001b[0m, in \u001b[0;36mMultivariateNormal.log_prob\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[39m\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    167\u001b[0m \u001b[39mSee :py:meth:`torch.distributions.Distribution.log_prob\u001b[39;00m\n\u001b[1;32m    168\u001b[0m \u001b[39m<torch.distributions.distribution.Distribution.log_prob>`.\u001b[39;00m\n\u001b[1;32m    169\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    170\u001b[0m \u001b[39mif\u001b[39;00m settings\u001b[39m.\u001b[39mfast_computations\u001b[39m.\u001b[39mlog_prob\u001b[39m.\u001b[39moff():\n\u001b[0;32m--> 171\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mlog_prob(value)\n\u001b[1;32m    173\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_args:\n\u001b[1;32m    174\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_sample(value)\n",
      "File \u001b[0;32m~/miniconda3/envs/mdgp_requirements_test7/lib/python3.11/site-packages/torch/distributions/multivariate_normal.py:216\u001b[0m, in \u001b[0;36mMultivariateNormal.log_prob\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_sample(value)\n\u001b[1;32m    215\u001b[0m diff \u001b[39m=\u001b[39m value \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloc\n\u001b[0;32m--> 216\u001b[0m M \u001b[39m=\u001b[39m _batch_mahalanobis(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_unbroadcasted_scale_tril, diff)\n\u001b[1;32m    217\u001b[0m half_log_det \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_unbroadcasted_scale_tril\u001b[39m.\u001b[39mdiagonal(dim1\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m2\u001b[39m, dim2\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mlog()\u001b[39m.\u001b[39msum(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m    218\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39m-\u001b[39m\u001b[39m0.5\u001b[39m \u001b[39m*\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_event_shape[\u001b[39m0\u001b[39m] \u001b[39m*\u001b[39m math\u001b[39m.\u001b[39mlog(\u001b[39m2\u001b[39m \u001b[39m*\u001b[39m math\u001b[39m.\u001b[39mpi) \u001b[39m+\u001b[39m M) \u001b[39m-\u001b[39m half_log_det\n",
      "File \u001b[0;32m~/miniconda3/envs/mdgp_requirements_test7/lib/python3.11/site-packages/gpytorch/distributions/multivariate_normal.py:88\u001b[0m, in \u001b[0;36mMultivariateNormal._unbroadcasted_scale_tril\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[39m@property\u001b[39m\n\u001b[1;32m     85\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_unbroadcasted_scale_tril\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m     86\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mislazy \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__unbroadcasted_scale_tril \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     87\u001b[0m         \u001b[39m# cache root decoposition\u001b[39;00m\n\u001b[0;32m---> 88\u001b[0m         ust \u001b[39m=\u001b[39m to_dense(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlazy_covariance_matrix\u001b[39m.\u001b[39;49mcholesky())\n\u001b[1;32m     89\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__unbroadcasted_scale_tril \u001b[39m=\u001b[39m ust\n\u001b[1;32m     90\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__unbroadcasted_scale_tril\n",
      "File \u001b[0;32m~/miniconda3/envs/mdgp_requirements_test7/lib/python3.11/site-packages/linear_operator/operators/_linear_operator.py:1303\u001b[0m, in \u001b[0;36mLinearOperator.cholesky\u001b[0;34m(self, upper)\u001b[0m\n\u001b[1;32m   1293\u001b[0m \u001b[39m@_implements\u001b[39m(torch\u001b[39m.\u001b[39mlinalg\u001b[39m.\u001b[39mcholesky)\n\u001b[1;32m   1294\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcholesky\u001b[39m(\n\u001b[1;32m   1295\u001b[0m     \u001b[39mself\u001b[39m: Float[LinearOperator, \u001b[39m\"\u001b[39m\u001b[39m*batch N N\u001b[39m\u001b[39m\"\u001b[39m], upper: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m   1296\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Float[LinearOperator, \u001b[39m\"\u001b[39m\u001b[39m*batch N N\u001b[39m\u001b[39m\"\u001b[39m]:  \u001b[39m# returns TriangularLinearOperator\u001b[39;00m\n\u001b[1;32m   1297\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1298\u001b[0m \u001b[39m    Cholesky-factorizes the LinearOperator.\u001b[39;00m\n\u001b[1;32m   1299\u001b[0m \n\u001b[1;32m   1300\u001b[0m \u001b[39m    :param upper: Upper triangular or lower triangular factor (default: False).\u001b[39;00m\n\u001b[1;32m   1301\u001b[0m \u001b[39m    :return: Cholesky factor (lower or upper triangular)\u001b[39;00m\n\u001b[1;32m   1302\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1303\u001b[0m     chol \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_cholesky(upper\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m   1304\u001b[0m     \u001b[39mif\u001b[39;00m upper:\n\u001b[1;32m   1305\u001b[0m         chol \u001b[39m=\u001b[39m chol\u001b[39m.\u001b[39m_transpose_nonbatch()\n",
      "File \u001b[0;32m~/miniconda3/envs/mdgp_requirements_test7/lib/python3.11/site-packages/linear_operator/utils/memoize.py:59\u001b[0m, in \u001b[0;36m_cached.<locals>.g\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     57\u001b[0m kwargs_pkl \u001b[39m=\u001b[39m pickle\u001b[39m.\u001b[39mdumps(kwargs)\n\u001b[1;32m     58\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m _is_in_cache(\u001b[39mself\u001b[39m, cache_name, \u001b[39m*\u001b[39margs, kwargs_pkl\u001b[39m=\u001b[39mkwargs_pkl):\n\u001b[0;32m---> 59\u001b[0m     \u001b[39mreturn\u001b[39;00m _add_to_cache(\u001b[39mself\u001b[39m, cache_name, method(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs), \u001b[39m*\u001b[39margs, kwargs_pkl\u001b[39m=\u001b[39mkwargs_pkl)\n\u001b[1;32m     60\u001b[0m \u001b[39mreturn\u001b[39;00m _get_from_cache(\u001b[39mself\u001b[39m, cache_name, \u001b[39m*\u001b[39margs, kwargs_pkl\u001b[39m=\u001b[39mkwargs_pkl)\n",
      "File \u001b[0;32m~/miniconda3/envs/mdgp_requirements_test7/lib/python3.11/site-packages/linear_operator/operators/_linear_operator.py:510\u001b[0m, in \u001b[0;36mLinearOperator._cholesky\u001b[0;34m(self, upper)\u001b[0m\n\u001b[1;32m    507\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mkeops_linear_operator\u001b[39;00m \u001b[39mimport\u001b[39;00m KeOpsLinearOperator\n\u001b[1;32m    508\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mtriangular_linear_operator\u001b[39;00m \u001b[39mimport\u001b[39;00m TriangularLinearOperator\n\u001b[0;32m--> 510\u001b[0m evaluated_kern_mat \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mevaluate_kernel()\n\u001b[1;32m    512\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39many\u001b[39m(\u001b[39misinstance\u001b[39m(sub_mat, KeOpsLinearOperator) \u001b[39mfor\u001b[39;00m sub_mat \u001b[39min\u001b[39;00m evaluated_kern_mat\u001b[39m.\u001b[39m_args):\n\u001b[1;32m    513\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCannot run Cholesky with KeOps: it will either be really slow or not work.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/mdgp_requirements_test7/lib/python3.11/site-packages/linear_operator/operators/added_diag_linear_operator.py:209\u001b[0m, in \u001b[0;36mAddedDiagLinearOperator.evaluate_kernel\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mevaluate_kernel\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 209\u001b[0m     added_diag_linear_op \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrepresentation_tree()(\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrepresentation())\n\u001b[1;32m    210\u001b[0m     \u001b[39mreturn\u001b[39;00m added_diag_linear_op\u001b[39m.\u001b[39m_linear_op \u001b[39m+\u001b[39m added_diag_linear_op\u001b[39m.\u001b[39m_diag_tensor\n",
      "File \u001b[0;32m~/miniconda3/envs/mdgp_requirements_test7/lib/python3.11/site-packages/linear_operator/operators/_linear_operator.py:2064\u001b[0m, in \u001b[0;36mLinearOperator.representation_tree\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2054\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrepresentation_tree\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m LinearOperatorRepresentationTree:\n\u001b[1;32m   2055\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   2056\u001b[0m \u001b[39m    Returns a\u001b[39;00m\n\u001b[1;32m   2057\u001b[0m \u001b[39m    :obj:`linear_operator.operators.LinearOperatorRepresentationTree` tree\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2062\u001b[0m \u001b[39m    including all subobjects. This is used internally.\u001b[39;00m\n\u001b[1;32m   2063\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2064\u001b[0m     \u001b[39mreturn\u001b[39;00m LinearOperatorRepresentationTree(\u001b[39mself\u001b[39;49m)\n",
      "File \u001b[0;32m~/miniconda3/envs/mdgp_requirements_test7/lib/python3.11/site-packages/linear_operator/operators/linear_operator_representation_tree.py:15\u001b[0m, in \u001b[0;36mLinearOperatorRepresentationTree.__init__\u001b[0;34m(self, linear_op)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39mfor\u001b[39;00m arg \u001b[39min\u001b[39;00m itertools\u001b[39m.\u001b[39mchain(linear_op\u001b[39m.\u001b[39m_args, linear_op\u001b[39m.\u001b[39m_differentiable_kwargs\u001b[39m.\u001b[39mvalues()):\n\u001b[1;32m     14\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(arg, \u001b[39m\"\u001b[39m\u001b[39mrepresentation\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mcallable\u001b[39m(arg\u001b[39m.\u001b[39mrepresentation):  \u001b[39m# Is it a lazy tensor?\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m         representation_size \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(arg\u001b[39m.\u001b[39;49mrepresentation())\n\u001b[1;32m     16\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren\u001b[39m.\u001b[39mappend((\u001b[39mslice\u001b[39m(counter, counter \u001b[39m+\u001b[39m representation_size, \u001b[39mNone\u001b[39;00m), arg\u001b[39m.\u001b[39mrepresentation_tree()))\n\u001b[1;32m     17\u001b[0m         counter \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m representation_size\n",
      "File \u001b[0;32m~/miniconda3/envs/mdgp_requirements_test7/lib/python3.11/site-packages/gpytorch/lazy/lazy_evaluated_kernel_tensor.py:397\u001b[0m, in \u001b[0;36mLazyEvaluatedKernelTensor.representation\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    393\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mrepresentation()\n\u001b[1;32m    394\u001b[0m \u001b[39m# Otherwise, we'll evaluate the kernel (or at least its LinearOperator representation) and use its\u001b[39;00m\n\u001b[1;32m    395\u001b[0m \u001b[39m# representation\u001b[39;00m\n\u001b[1;32m    396\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 397\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mevaluate_kernel()\u001b[39m.\u001b[39mrepresentation()\n",
      "File \u001b[0;32m~/miniconda3/envs/mdgp_requirements_test7/lib/python3.11/site-packages/gpytorch/utils/memoize.py:59\u001b[0m, in \u001b[0;36m_cached.<locals>.g\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     57\u001b[0m kwargs_pkl \u001b[39m=\u001b[39m pickle\u001b[39m.\u001b[39mdumps(kwargs)\n\u001b[1;32m     58\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m _is_in_cache(\u001b[39mself\u001b[39m, cache_name, \u001b[39m*\u001b[39margs, kwargs_pkl\u001b[39m=\u001b[39mkwargs_pkl):\n\u001b[0;32m---> 59\u001b[0m     \u001b[39mreturn\u001b[39;00m _add_to_cache(\u001b[39mself\u001b[39m, cache_name, method(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs), \u001b[39m*\u001b[39margs, kwargs_pkl\u001b[39m=\u001b[39mkwargs_pkl)\n\u001b[1;32m     60\u001b[0m \u001b[39mreturn\u001b[39;00m _get_from_cache(\u001b[39mself\u001b[39m, cache_name, \u001b[39m*\u001b[39margs, kwargs_pkl\u001b[39m=\u001b[39mkwargs_pkl)\n",
      "File \u001b[0;32m~/miniconda3/envs/mdgp_requirements_test7/lib/python3.11/site-packages/gpytorch/lazy/lazy_evaluated_kernel_tensor.py:25\u001b[0m, in \u001b[0;36mrecall_grad_state.<locals>.wrapped\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(method)\n\u001b[1;32m     23\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     24\u001b[0m     \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mset_grad_enabled(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_grad_enabled):\n\u001b[0;32m---> 25\u001b[0m         output \u001b[39m=\u001b[39m method(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     26\u001b[0m     \u001b[39mreturn\u001b[39;00m output\n",
      "File \u001b[0;32m~/miniconda3/envs/mdgp_requirements_test7/lib/python3.11/site-packages/gpytorch/lazy/lazy_evaluated_kernel_tensor.py:355\u001b[0m, in \u001b[0;36mLazyEvaluatedKernelTensor.evaluate_kernel\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    353\u001b[0m     temp_active_dims \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkernel\u001b[39m.\u001b[39mactive_dims\n\u001b[1;32m    354\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkernel\u001b[39m.\u001b[39mactive_dims \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 355\u001b[0m     res \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkernel(\n\u001b[1;32m    356\u001b[0m         x1,\n\u001b[1;32m    357\u001b[0m         x2,\n\u001b[1;32m    358\u001b[0m         diag\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    359\u001b[0m         last_dim_is_batch\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlast_dim_is_batch,\n\u001b[1;32m    360\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparams,\n\u001b[1;32m    361\u001b[0m     )\n\u001b[1;32m    362\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkernel\u001b[39m.\u001b[39mactive_dims \u001b[39m=\u001b[39m temp_active_dims\n\u001b[1;32m    364\u001b[0m \u001b[39m# Check the size of the output\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/mdgp_requirements_test7/lib/python3.11/site-packages/gpytorch/kernels/kernel.py:530\u001b[0m, in \u001b[0;36mKernel.__call__\u001b[0;34m(self, x1, x2, diag, last_dim_is_batch, **params)\u001b[0m\n\u001b[1;32m    527\u001b[0m     res \u001b[39m=\u001b[39m LazyEvaluatedKernelTensor(x1_, x2_, kernel\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m, last_dim_is_batch\u001b[39m=\u001b[39mlast_dim_is_batch, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams)\n\u001b[1;32m    528\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    529\u001b[0m     res \u001b[39m=\u001b[39m to_linear_operator(\n\u001b[0;32m--> 530\u001b[0m         \u001b[39msuper\u001b[39;49m(Kernel, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(x1_, x2_, last_dim_is_batch\u001b[39m=\u001b[39;49mlast_dim_is_batch, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mparams)\n\u001b[1;32m    531\u001b[0m     )\n\u001b[1;32m    532\u001b[0m \u001b[39mreturn\u001b[39;00m res\n",
      "File \u001b[0;32m~/miniconda3/envs/mdgp_requirements_test7/lib/python3.11/site-packages/gpytorch/module.py:31\u001b[0m, in \u001b[0;36mModule.__call__\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39minputs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Union[Tensor, Distribution, LinearOperator]:\n\u001b[0;32m---> 31\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(\u001b[39m*\u001b[39;49minputs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     32\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(outputs, \u001b[39mlist\u001b[39m):\n\u001b[1;32m     33\u001b[0m         \u001b[39mreturn\u001b[39;00m [_validate_module_outputs(output) \u001b[39mfor\u001b[39;00m output \u001b[39min\u001b[39;00m outputs]\n",
      "File \u001b[0;32m~/miniconda3/envs/mdgp_requirements_test7/lib/python3.11/site-packages/gpytorch/kernels/scale_kernel.py:109\u001b[0m, in \u001b[0;36mScaleKernel.forward\u001b[0;34m(self, x1, x2, last_dim_is_batch, diag, **params)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x1, x2, last_dim_is_batch\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, diag\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams):\n\u001b[0;32m--> 109\u001b[0m     orig_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbase_kernel\u001b[39m.\u001b[39;49mforward(x1, x2, diag\u001b[39m=\u001b[39;49mdiag, last_dim_is_batch\u001b[39m=\u001b[39;49mlast_dim_is_batch, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mparams)\n\u001b[1;32m    110\u001b[0m     outputscales \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutputscale\n\u001b[1;32m    111\u001b[0m     \u001b[39mif\u001b[39;00m last_dim_is_batch:\n",
      "File \u001b[0;32m~/miniconda3/envs/mdgp_requirements_test7/lib/python3.11/site-packages/geometric_kernels/frontends/pytorch/gpytorch.py:88\u001b[0m, in \u001b[0;36mGPytorchGeometricKernel.forward\u001b[0;34m(self, x1, x2, diag, last_dim_is_batch, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m     res \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_kernel\u001b[39m.\u001b[39mK_diag(params, x1)\n\u001b[1;32m     87\u001b[0m \u001b[39melse\u001b[39;00m: \n\u001b[0;32m---> 88\u001b[0m     res \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_kernel\u001b[39m.\u001b[39;49mK(params, x1, x2)\n\u001b[1;32m     90\u001b[0m \u001b[39mreturn\u001b[39;00m res \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_shape_scaling_factor\n",
      "File \u001b[0;32m~/miniconda3/envs/mdgp_requirements_test7/lib/python3.11/site-packages/geometric_kernels/kernels/geometric_kernels.py:142\u001b[0m, in \u001b[0;36mMaternKarhunenLoeveKernel.K\u001b[0;34m(self, params, X, X2, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mK\u001b[39m(\n\u001b[1;32m    139\u001b[0m     \u001b[39mself\u001b[39m, params, X: B\u001b[39m.\u001b[39mNumeric, X2: Optional[B\u001b[39m.\u001b[39mNumeric] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs  \u001b[39m# type: ignore\u001b[39;00m\n\u001b[1;32m    140\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m B\u001b[39m.\u001b[39mNumeric:\n\u001b[1;32m    141\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Compute the mesh kernel via Laplace eigendecomposition\"\"\"\u001b[39;00m\n\u001b[0;32m--> 142\u001b[0m     weights \u001b[39m=\u001b[39m B\u001b[39m.\u001b[39mcast(B\u001b[39m.\u001b[39mdtype(params[\u001b[39m\"\u001b[39m\u001b[39mnu\u001b[39m\u001b[39m\"\u001b[39m]), \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49meigenvalues(params))  \u001b[39m# [M, 1]\u001b[39;00m\n\u001b[1;32m    143\u001b[0m     Phi \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39meigenfunctions\n\u001b[1;32m    145\u001b[0m     \u001b[39mreturn\u001b[39;00m Phi\u001b[39m.\u001b[39mweighted_outerproduct(weights, X, X2, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams)\n",
      "File \u001b[0;32m~/miniconda3/envs/mdgp_requirements_test7/lib/python3.11/site-packages/geometric_kernels/kernels/geometric_kernels.py:118\u001b[0m, in \u001b[0;36mMaternKarhunenLoeveKernel.eigenvalues\u001b[0;34m(self, params, normalize)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mlengthscale\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m params\n\u001b[1;32m    116\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnu\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m params\n\u001b[0;32m--> 118\u001b[0m spectral_values \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_spectrum(\n\u001b[1;32m    119\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49meigenvalues_laplacian\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39m0.5\u001b[39;49m,\n\u001b[1;32m    120\u001b[0m     nu\u001b[39m=\u001b[39;49mparams[\u001b[39m\"\u001b[39;49m\u001b[39mnu\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m    121\u001b[0m     lengthscale\u001b[39m=\u001b[39;49mparams[\u001b[39m\"\u001b[39;49m\u001b[39mlengthscale\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m    122\u001b[0m )\n\u001b[1;32m    123\u001b[0m normalize \u001b[39m=\u001b[39m normalize \u001b[39mor\u001b[39;00m (normalize \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnormalize)\n\u001b[1;32m    124\u001b[0m \u001b[39mif\u001b[39;00m normalize:\n",
      "File \u001b[0;32m~/miniconda3/envs/mdgp_requirements_test7/lib/python3.11/site-packages/geometric_kernels/kernels/geometric_kernels.py:92\u001b[0m, in \u001b[0;36mMaternKarhunenLoeveKernel._spectrum\u001b[0;34m(self, s, nu, lengthscale)\u001b[0m\n\u001b[1;32m     90\u001b[0m     spectral_values \u001b[39m=\u001b[39m base\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpower\n\u001b[1;32m     91\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 92\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m\n\u001b[1;32m     93\u001b[0m \u001b[39mreturn\u001b[39;00m spectral_values\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "experiment_config = ExperimentConfig()\n",
    "experiment_config.model_arguments.model_name = 'exact'\n",
    "experiment_config.data_arguments.target_function_name = 'dgp_sample'\n",
    "\n",
    "run_experiment(experiment_config, './', show_fit_progress=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mdgp_requirements_test7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
