{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load in data\n",
    "Currently supported datasets: power, protein, kin8nm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import geometric_kernels.torch \n",
    "\n",
    "torch.set_default_dtype(torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd \n",
    "import torch \n",
    "from torch import Tensor\n",
    "from torch.utils.data import TensorDataset, DataLoader, Dataset\n",
    "\n",
    "\n",
    "class UCIDataset:\n",
    "\n",
    "    UCI_BASE_URL = 'https://archive.ics.uci.edu/ml/machine-learning-databases/'\n",
    "\n",
    "    def __init__(self, name: str, path: str = '../../data/uci/', normalize: bool = True, seed: int | None = None): \n",
    "        self.name = name \n",
    "        self.path = path \n",
    "        self.csv_path = os.path.join(self.path, self.name + '.csv')\n",
    "\n",
    "        # Set generator if seed is provided.\n",
    "        self.generator = torch.Generator()\n",
    "        if seed is not None: \n",
    "            self.generator.manual_seed(seed)\n",
    "\n",
    "        # Load, shuffle, split, and normalize data. TODO except for load, these don't need to be object methods. \n",
    "        # We keep the standard deviation of the test set for log-likelihood evaluation.\n",
    "        x, y = self.load_data()\n",
    "        x, y = self.shuffle(x, y, generator=self.generator)     \n",
    "        self.train_x, self.train_y, self.test_x, self.test_y = self.split(x, y)\n",
    "        self.test_y_std = self.test_y.std(dim=0, keepdim=True)\n",
    "        self.train_x, self.train_y, self.test_x, self.test_y = map(\n",
    "            self.normalize, (self.train_x, self.train_y, self.test_x, self.test_y))\n",
    "\n",
    "    @property\n",
    "    def dimension(self) -> int:\n",
    "        return self.train_x.shape[-1]\n",
    "\n",
    "    @property \n",
    "    def train_dataset(self) -> Dataset:\n",
    "        return TensorDataset(self.train_x, self.train_y)\n",
    "    \n",
    "    @property\n",
    "    def test_dataset(self) -> Dataset:\n",
    "        return TensorDataset(self.test_x, self.test_y)\n",
    "\n",
    "    def read_data(self) -> tuple[Tensor, Tensor]:\n",
    "        xy = torch.from_numpy(pd.read_csv(self.csv_path).values)\n",
    "        return xy[:, :-1], xy[:, -1]\n",
    "\n",
    "    def download_data(self) -> None:\n",
    "        NotImplementedError\n",
    "\n",
    "    def load_data(self, overwrite: bool = False) -> tuple[Tensor, Tensor]:\n",
    "        if overwrite or not os.path.isfile(self.csv_path):\n",
    "            self.download_data()\n",
    "        return self.read_data()\n",
    "\n",
    "    def normalize(self, x: Tensor) -> Tensor:\n",
    "        return (x - x.mean(dim=0)) / x.std(dim=0, keepdim=True)\n",
    "    \n",
    "    def shuffle(self, x: Tensor, y: Tensor, generator: torch.Generator) -> tuple[Tensor, Tensor]:\n",
    "        perm_idx = torch.randperm(x.size(0), generator=generator)\n",
    "        return x[perm_idx], y[perm_idx]\n",
    "    \n",
    "    def split(self, x: Tensor, y: Tensor, test_size: float = 0.1) -> tuple[Tensor, Tensor, Tensor, Tensor]: \n",
    "        \"\"\"\n",
    "        Split the dataset into train and test sets.\n",
    "        \"\"\"\n",
    "        split_idx = int(test_size * x.size(0))\n",
    "        return x[split_idx:], y[split_idx:], x[:split_idx], y[:split_idx]\n",
    "\n",
    "\n",
    "class Kin8mn(UCIDataset):\n",
    "\n",
    "    DEFAULT_URL = 'https://raw.githubusercontent.com/liusiyan/UQnet/master/datasets/UCI_datasets/kin8nm/dataset_2175_kin8nm.csv'\n",
    "\n",
    "    def __init__(self, path: str = '../../data/uci/', normalize: bool = True, seed: int | None = None, url: str = DEFAULT_URL):\n",
    "        super().__init__(name='kin8nm', path=path, normalize=normalize, seed=seed)\n",
    "        self.url = url \n",
    "\n",
    "    def download_data(self) -> None:\n",
    "        df = pd.read_csv(self.url)\n",
    "        os.makedirs(self.path, exist_ok=True)\n",
    "        df.to_csv(self.csv_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instantiate model\n",
    "\n",
    "This is done using the same model arguments as for the benchmarking experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from linear_operator.operators import DiagLinearOperator\n",
    "from gpytorch.distributions import MultivariateNormal\n",
    "\n",
    "\n",
    "class SphereProjector(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        b = torch.tensor(2.0)\n",
    "        self.register_parameter('b', torch.nn.Parameter(b))\n",
    "        self.norm = None \n",
    "\n",
    "    def forward(self, x: Tensor, y: Tensor | None = None) -> tuple[Tensor, Tensor] | Tensor:\n",
    "        b = self.b.expand(*x.shape[:-1], 1)\n",
    "        x_cat_b = torch.cat([x, b], dim=-1)\n",
    "        self.norm = x_cat_b.norm(dim=-1, keepdim=True)\n",
    "        if y is None:\n",
    "            return x_cat_b / self.norm\n",
    "        else:\n",
    "            return x_cat_b / self.norm, y / self.norm.squeeze(-1)\n",
    "    \n",
    "    def inverse(self, mvn: MultivariateNormal) -> MultivariateNormal:\n",
    "        L = DiagLinearOperator(self.norm.squeeze(-1))\n",
    "        mean = mvn.mean @ L\n",
    "        cov = L @ mvn.lazy_covariance_matrix @ L\n",
    "        return MultivariateNormal(mean=mean, covariance_matrix=cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Using numpy backend\n"
     ]
    }
   ],
   "source": [
    "from torch import Tensor \n",
    "from gpytorch.means import Mean\n",
    "from gpytorch.kernels import ScaleKernel\n",
    "from gpytorch.models import ApproximateGP\n",
    "from gpytorch.variational import CholeskyVariationalDistribution\n",
    "from mdgp.kernels import GeometricMaternKernel\n",
    "\n",
    "\n",
    "import torch \n",
    "from gpytorch import Module, settings\n",
    "from gpytorch.distributions import MultivariateNormal\n",
    "from gpytorch.utils.memoize import cached, clear_cache_hook\n",
    "from linear_operator.operators import DiagLinearOperator\n",
    "from functools import cached_property\n",
    "# TODO Maybe just move the functions from spherical_harmonic_features.py into this file?\n",
    "from mdgp.utils.spherical_harmonic_features import num_spherical_harmonics_to_degree, matern_Kuu, matern_LT_Phi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VariationalDistribution(torch.nn.Module):\n",
    "    def __init__(self, num_inducing: int):\n",
    "        super().__init__()\n",
    "        self.num_inducing = num_inducing\n",
    "        self.chol_variational_covar = torch.nn.Parameter(torch.eye(num_inducing))\n",
    "\n",
    "    def forward(self) -> MultivariateNormal:\n",
    "        covar = self.chol_variational_covar @ self.chol_variational_covar.mT\n",
    "        return MultivariateNormal(torch.zeros(self.num_inducing), covar)\n",
    "    \n",
    "\n",
    "class SHVariationalStrategy(torch.nn.Module):\n",
    "    def __init__(self,\n",
    "        covar_module: GeometricMaternKernel,\n",
    "        dimension: int,\n",
    "        num_spherical_harmonics: int,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.covar_module = covar_module\n",
    "        self.dimension = dimension\n",
    "        self.degree, self.num_spherical_harmonics = num_spherical_harmonics_to_degree(num_spherical_harmonics, dimension)\n",
    "        self._variational_distribution = VariationalDistribution(num_spherical_harmonics)\n",
    "\n",
    "    @property\n",
    "    def kappa(self) -> Tensor:\n",
    "        return torch.tensor([[0.001]])\n",
    "    \n",
    "    @property\n",
    "    def nu(self) -> Tensor | float:\n",
    "        return torch.tensor([[2.5]])\n",
    "\n",
    "    @property \n",
    "    def sigma(self) -> Tensor: \n",
    "        return torch.tensor(1.0)\n",
    "\n",
    "    @property\n",
    "    def prior_distribution(self) -> MultivariateNormal:\n",
    "        covariance_matrix = torch.eye(self.num_spherical_harmonics)\n",
    "        mean = torch.zeros(self.num_spherical_harmonics)\n",
    "        return MultivariateNormal(mean=mean, covariance_matrix=covariance_matrix)\n",
    "        \n",
    "    @property\n",
    "    def variational_distribution(self) -> MultivariateNormal:\n",
    "        return self._variational_distribution()\n",
    "\n",
    "    def forward(self, x: Tensor, **kwargs) -> MultivariateNormal:\n",
    "        # inducing-inducing prior\n",
    "        pu = self.prior_distribution\n",
    "        invL_Kuu_invLt = pu.lazy_covariance_matrix\n",
    "\n",
    "        # input-input prior\n",
    "        Kxx = self.covar_module(x)\n",
    "\n",
    "        # inducing-inducing variational\n",
    "        qu = self.variational_distribution\n",
    "        invL_S_invLt = qu.lazy_covariance_matrix\n",
    "\n",
    "        # inducing-input prior  \n",
    "        LT_Phi = matern_LT_Phi(x, max_ell=self.degree, d=self.dimension, kappa=self.kappa, nu=self.nu, sigma=self.sigma,) # [..., O, num_harmonics, N]\n",
    "\n",
    "        # Update the covariance matrix\n",
    "        covariance_matrix_update = LT_Phi.mT @ (invL_S_invLt - invL_Kuu_invLt) @ LT_Phi # [O, num_harmonics, num_harmonics] @ [O, num_harmonics, num_harmonics] @ [O, num_harmonics, N] -> [O, num_harmonics, N]\n",
    "        updated_covariance_matrix = Kxx + covariance_matrix_update # [..., O, N, N] + [..., O, N, N] -> [..., O, N, N]\n",
    "\n",
    "        return MultivariateNormal(mean=torch.zeros(x.shape[:-1]), covariance_matrix=updated_covariance_matrix)\n",
    "\n",
    "    def kl_divergence(self) -> Tensor:\n",
    "        with settings.max_preconditioner_size(0):\n",
    "            kl_divergence = torch.distributions.kl.kl_divergence(self.variational_distribution, self.prior_distribution)\n",
    "        return kl_divergence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple shallow variational GP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gpytorch\n",
    "\n",
    "\n",
    "class SHApproximateGP(gpytorch.models.ApproximateGP):\n",
    "    def __init__(self, dimension: int, num_spherical_harmonics: int, \n",
    "                 mean: Mean, covar_module: GeometricMaternKernel, variational_distribution: CholeskyVariationalDistribution):\n",
    "        variational_strategy = SHVariationalStrategy(\n",
    "            covar_module=covar_module,\n",
    "            dimension=dimension,\n",
    "            num_spherical_harmonics=num_spherical_harmonics,\n",
    "        )\n",
    "        super().__init__(variational_strategy)\n",
    "        self.mean_module = mean\n",
    "        self.covar_module = covar_module\n",
    "        self.likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "\n",
    "\n",
    "    def forward(self, x: Tensor) -> MultivariateNormal:\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return MultivariateNormal(mean_x, covar_x)\n",
    "    \n",
    "\n",
    "class IPApproximateGP(gpytorch.models.ApproximateGP):\n",
    "    def __init__(self, mean: Mean, covar_module: GeometricMaternKernel, inducing_points: Tensor, variational_distribution: CholeskyVariationalDistribution):\n",
    "        variational_strategy = gpytorch.variational.VariationalStrategy(\n",
    "            self, \n",
    "            inducing_points=inducing_points,\n",
    "            variational_distribution=variational_distribution, \n",
    "            learn_inducing_locations=False\n",
    "        )\n",
    "        super().__init__(variational_strategy)\n",
    "        self.mean_module = mean\n",
    "        self.covar_module = covar_module\n",
    "        self.likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "\n",
    "    def forward(self, x: Tensor) -> MultivariateNormal:\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return MultivariateNormal(mean_x, covar_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model\n",
    "Training has to be done differently from the bechmarking experiment, because we need minibatch SGD with the larger datasets and minibatch metrics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_smallest_eigenvalues(covar):\n",
    "    # mvn = projector.inverse(mvn)\n",
    "    smallest_eigenvalues = torch.linalg.eigvalsh(covar).min()\n",
    "    print(f\"Smallest eigenvalue: {smallest_eigenvalues.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of spherical harmonics requested does not lead to complete levels of spherical harmonics. We have thus increased the number to 54, which includes all spherical harmonics up to degree 3 (incl.)\n"
     ]
    }
   ],
   "source": [
    "from geometric_kernels.spaces import Hypersphere\n",
    "from mdgp.utils.spherical_harmonic_features import num_spherical_harmonics_to_degree\n",
    "\n",
    "\n",
    "dataset = Kin8mn()\n",
    "\n",
    "# Generic parameters\n",
    "num_spherical_harmonics = 50\n",
    "dimension = dataset.dimension + 1\n",
    "\n",
    "degree, num_spherical_harmonics = num_spherical_harmonics_to_degree(num_spherical_harmonics, dimension)\n",
    "space = Hypersphere(dimension)\n",
    "\n",
    "batch_shape = torch.Size([])\n",
    "\n",
    "# Model with spherical harmonic features\n",
    "mean = gpytorch.means.ZeroMean()\n",
    "covar_module = GeometricMaternKernel(nu=2.5, space=space, num_eigenfunctions=4, batch_shape=batch_shape)\n",
    "covar_module.initialize(lengthscale=0.001)\n",
    "variational_distribution = gpytorch.variational.CholeskyVariationalDistribution(\n",
    "    num_inducing_points=num_spherical_harmonics, batch_shape=batch_shape\n",
    ")\n",
    "\n",
    "model_sh = SHApproximateGP(\n",
    "    dimension=dimension,\n",
    "    num_spherical_harmonics=num_spherical_harmonics,\n",
    "    mean=mean,\n",
    "    covar_module=covar_module,\n",
    "    variational_distribution=variational_distribution,\n",
    ")\n",
    "\n",
    "# Model with inducing points \n",
    "mean = gpytorch.means.ZeroMean()\n",
    "covar_module = GeometricMaternKernel(nu=2.5, space=space, num_eigenfunctions=4, batch_shape=batch_shape)\n",
    "covar_module.initialize(lengthscale=0.001)\n",
    "variational_distribution = gpytorch.variational.CholeskyVariationalDistribution(\n",
    "    num_inducing_points=num_spherical_harmonics, batch_shape=batch_shape\n",
    ")\n",
    "\n",
    "inducing_points = torch.randn(num_spherical_harmonics, dimension)\n",
    "inducing_points = inducing_points / inducing_points.norm(dim=-1, keepdim=True)\n",
    "model_ip = IPApproximateGP(\n",
    "    mean=mean,\n",
    "    covar_module=covar_module,\n",
    "    inducing_points=inducing_points,\n",
    "    variational_distribution=variational_distribution\n",
    ")\n",
    "\n",
    "\n",
    "# Arbitrary projector \n",
    "projector = SphereProjector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smallest eigenvalue: -8.539810600761202e-16\n",
      "1.5191257954071244\n",
      "Smallest eigenvalue: -136.1258971113906\n",
      "0.8105078918494112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kacperwyrwal/miniconda3/envs/mdgp_requirements_test1/lib/python3.11/site-packages/gpytorch/distributions/multivariate_normal.py:319: NumericalWarning: Negative variance values detected. This is likely due to numerical instabilities. Rounding negative variances up to 1e-10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smallest eigenvalue: -287.7599835117475\n",
      "0.8163001603029809\n",
      "Smallest eigenvalue: -482.57887036014\n",
      "0.8095743322329015\n",
      "Smallest eigenvalue: -571.6914296331513\n",
      "0.8115499110227326\n",
      "Smallest eigenvalue: -638.939747107378\n",
      "0.8145526181551925\n",
      "Smallest eigenvalue: -898.4196045896805\n",
      "0.8196612829389804\n",
      "Smallest eigenvalue: -1056.485055463041\n",
      "0.8222150550682458\n",
      "Smallest eigenvalue: -1032.5997457992926\n",
      "0.8228187181822895\n",
      "Smallest eigenvalue: -1126.74362062649\n",
      "0.8210939060517253\n",
      "Smallest eigenvalue: -1184.9486269121878\n",
      "0.8271823576917376\n",
      "Smallest eigenvalue: -1191.9954117463662\n",
      "0.8207942911335442\n",
      "Smallest eigenvalue: -1371.0319215640118\n",
      "0.8334859064801701\n",
      "Smallest eigenvalue: -1465.4813286437043\n",
      "0.827732060656523\n",
      "Smallest eigenvalue: -1399.289028553287\n",
      "0.8374343147879489\n",
      "Smallest eigenvalue: -1459.2125410330486\n",
      "0.8297887488986532\n",
      "Smallest eigenvalue: -1470.5824500901851\n",
      "0.8339177306692076\n",
      "Smallest eigenvalue: -1516.9764870117442\n",
      "0.8238165171158781\n",
      "Smallest eigenvalue: -1533.5609379776736\n",
      "0.8286446458423938\n",
      "Smallest eigenvalue: -1568.7605531218305\n",
      "0.8317368481524577\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m x_batch, y_batch \u001b[38;5;241m=\u001b[39m projector(x_batch, y_batch)\n\u001b[1;32m     15\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 16\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvariational_strategy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m print_smallest_eigenvalues(output\u001b[38;5;241m.\u001b[39mcovariance_matrix)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# print_smallest_eigenvalues(model.variational_strategy.variational_distribution.covariance_matrix)\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/mdgp_requirements_test1/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/mdgp_requirements_test1/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[36], line 59\u001b[0m, in \u001b[0;36mSHVariationalStrategy.forward\u001b[0;34m(self, x, **kwargs)\u001b[0m\n\u001b[1;32m     56\u001b[0m invL_S_invLt \u001b[38;5;241m=\u001b[39m qu\u001b[38;5;241m.\u001b[39mlazy_covariance_matrix\n\u001b[1;32m     58\u001b[0m \u001b[38;5;66;03m# inducing-input prior  \u001b[39;00m\n\u001b[0;32m---> 59\u001b[0m LT_Phi \u001b[38;5;241m=\u001b[39m \u001b[43mmatern_LT_Phi\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_ell\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdegree\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdimension\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkappa\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkappa\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnu\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msigma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msigma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# [..., O, num_harmonics, N]\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;66;03m# Update the covariance matrix\u001b[39;00m\n\u001b[1;32m     62\u001b[0m covariance_matrix_update \u001b[38;5;241m=\u001b[39m LT_Phi\u001b[38;5;241m.\u001b[39mmT \u001b[38;5;241m@\u001b[39m (invL_S_invLt \u001b[38;5;241m-\u001b[39m invL_Kuu_invLt) \u001b[38;5;241m@\u001b[39m LT_Phi \u001b[38;5;66;03m# [O, num_harmonics, num_harmonics] @ [O, num_harmonics, num_harmonics] @ [O, num_harmonics, N] -> [O, num_harmonics, N]\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/mdgp_requirements_test1/lib/python3.11/site-packages/mdgp/utils/spherical_harmonic_features.py:149\u001b[0m, in \u001b[0;36mmatern_LT_Phi\u001b[0;34m(x, max_ell, d, kappa, nu, sigma)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmatern_LT_Phi\u001b[39m(x: Tensor, max_ell: \u001b[38;5;28mint\u001b[39m, d: \u001b[38;5;28mint\u001b[39m, kappa: \u001b[38;5;28mfloat\u001b[39m, nu: \u001b[38;5;28mfloat\u001b[39m, sigma: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor: \n\u001b[1;32m    140\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;124;03m    Returns the feature vector of spherical harmonics evaluated at x. \u001b[39;00m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;124;03m    x: [..., O, N, D]\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;124;03m    sigma: [O, 1, 1]\u001b[39;00m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 149\u001b[0m     Kux \u001b[38;5;241m=\u001b[39m \u001b[43mmatern_Kux\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_ell\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_ell\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43md\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# [..., O, num_harmonics, N]\u001b[39;00m\n\u001b[1;32m    150\u001b[0m     ahat_sqrt \u001b[38;5;241m=\u001b[39m matern_repeated_ahat(max_ell\u001b[38;5;241m=\u001b[39mmax_ell, d\u001b[38;5;241m=\u001b[39md, kappa\u001b[38;5;241m=\u001b[39mkappa, nu\u001b[38;5;241m=\u001b[39mnu, sigma\u001b[38;5;241m=\u001b[39msigma)\u001b[38;5;241m.\u001b[39msqrt() \u001b[38;5;66;03m# [O, num_harmonics, 1]\u001b[39;00m\n\u001b[1;32m    151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Kux \u001b[38;5;241m*\u001b[39m ahat_sqrt\n",
      "File \u001b[0;32m~/miniconda3/envs/mdgp_requirements_test1/lib/python3.11/site-packages/mdgp/utils/spherical_harmonic_features.py:136\u001b[0m, in \u001b[0;36mmatern_Kux\u001b[0;34m(x, max_ell, d)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmatern_Kux\u001b[39m(x: Tensor, max_ell: \u001b[38;5;28mint\u001b[39m, d: \u001b[38;5;28mint\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor: \n\u001b[0;32m--> 136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mspherical_harmonics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_ell\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_ell\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43md\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mmT\n",
      "File \u001b[0;32m~/miniconda3/envs/mdgp_requirements_test1/lib/python3.11/site-packages/mdgp/utils/spherical_harmonic_features.py:132\u001b[0m, in \u001b[0;36mspherical_harmonics\u001b[0;34m(x, max_ell, d)\u001b[0m\n\u001b[1;32m    129\u001b[0m f \u001b[38;5;241m=\u001b[39m SphericalHarmonics(dimension\u001b[38;5;241m=\u001b[39md, degrees\u001b[38;5;241m=\u001b[39mmax_ell \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;66;03m# [... * O, N, num_harmonics]\u001b[39;00m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;66;03m# Evaluate x and reintroduce batch dimensions\u001b[39;00m\n\u001b[0;32m--> 132\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m*\u001b[39mbatch_shape, n, total_num_harmonics(max_ell, d))\n",
      "File \u001b[0;32m~/miniconda3/envs/mdgp_requirements_test1/lib/python3.11/site-packages/spherical_harmonics/spherical_harmonics.py:80\u001b[0m, in \u001b[0;36mSphericalHarmonics.__call__\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;124;03mEvaluates each of the spherical harmonic level in the collection,\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;124;03mand stacks the results.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;124;03m:return: [N, num harmonics in collection]\u001b[39;00m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     76\u001b[0m values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmap\u001b[39m(\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m harmonic: harmonic(x), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mharmonic_levels\n\u001b[1;32m     78\u001b[0m )  \u001b[38;5;66;03m# List of length `max_degree` with Tensor [num_harmonics_degree, N]\u001b[39;00m\n\u001b[0;32m---> 80\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m B\u001b[38;5;241m.\u001b[39mtranspose(B\u001b[38;5;241m.\u001b[39mconcat(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlist\u001b[39m(values), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m))\n",
      "File \u001b[0;32m~/miniconda3/envs/mdgp_requirements_test1/lib/python3.11/site-packages/spherical_harmonics/spherical_harmonics.py:77\u001b[0m, in \u001b[0;36mSphericalHarmonics.__call__.<locals>.<lambda>\u001b[0;34m(harmonic)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     67\u001b[0m     x: B\u001b[38;5;241m.\u001b[39mNumeric,\n\u001b[1;32m     68\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m B\u001b[38;5;241m.\u001b[39mNumeric:\n\u001b[1;32m     69\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;124;03m    Evaluates each of the spherical harmonic level in the collection,\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;124;03m    and stacks the results.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;124;03m    :return: [N, num harmonics in collection]\u001b[39;00m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m     76\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmap\u001b[39m(\n\u001b[0;32m---> 77\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m harmonic: \u001b[43mharmonic\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mharmonic_levels\n\u001b[1;32m     78\u001b[0m     )  \u001b[38;5;66;03m# List of length `max_degree` with Tensor [num_harmonics_degree, N]\u001b[39;00m\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m B\u001b[38;5;241m.\u001b[39mtranspose(B\u001b[38;5;241m.\u001b[39mconcat(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlist\u001b[39m(values), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m))\n",
      "File \u001b[0;32m~/miniconda3/envs/mdgp_requirements_test1/lib/python3.11/site-packages/spherical_harmonics/spherical_harmonics.py:151\u001b[0m, in \u001b[0;36mSphericalHarmonicsLevel.__call__\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: B\u001b[38;5;241m.\u001b[39mNumeric) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m B\u001b[38;5;241m.\u001b[39mNumeric:\n\u001b[1;32m    145\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;124;03m    :param X: M normalised (i.e. unit) D-dimensional vector, [N, D]\u001b[39;00m\n\u001b[1;32m    147\u001b[0m \n\u001b[1;32m    148\u001b[0m \u001b[38;5;124;03m    :return: `X` evaluated at the M spherical harmonics in the set.\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;124;03m        [\\phi_m(x_i)], shape [M, N]\u001b[39;00m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 151\u001b[0m     VXT \u001b[38;5;241m=\u001b[39m \u001b[43mB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    152\u001b[0m \u001b[43m        \u001b[49m\u001b[43mB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mV\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtr_b\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m    153\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# [M, N]\u001b[39;00m\n\u001b[1;32m    154\u001b[0m     zonals \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgegenbauer(VXT)  \u001b[38;5;66;03m# [M, N]\u001b[39;00m\n\u001b[1;32m    155\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m B\u001b[38;5;241m.\u001b[39mmatmul(B\u001b[38;5;241m.\u001b[39mcast(B\u001b[38;5;241m.\u001b[39mdtype(X), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mL_inv), zonals)\n",
      "File \u001b[0;32m~/miniconda3/envs/mdgp_requirements_test1/lib/python3.11/site-packages/plum/function.py:399\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kw_args)\u001b[0m\n\u001b[1;32m    397\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw_args):\n\u001b[1;32m    398\u001b[0m     method, return_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_resolve_method_with_cache(args\u001b[38;5;241m=\u001b[39margs)\n\u001b[0;32m--> 399\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _convert(\u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw_args\u001b[49m\u001b[43m)\u001b[49m, return_type)\n",
      "File \u001b[0;32m~/miniconda3/envs/mdgp_requirements_test1/lib/python3.11/site-packages/lab/shape.py:185\u001b[0m, in \u001b[0;36mdispatch_unwrap_dimensions.<locals>.unwrapped_dispatch.<locals>.f_wrapped\u001b[0;34m(*args, **kw_args)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    184\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mf_wrapped\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw_args):\n\u001b[0;32m--> 185\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43munwrap_dimension\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw_args\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/mdgp_requirements_test1/lib/python3.11/site-packages/lab/torch/linear_algebra.py:19\u001b[0m, in \u001b[0;36mmatmul\u001b[0;34m(a, b, tr_a, tr_b)\u001b[0m\n\u001b[1;32m     17\u001b[0m a \u001b[38;5;241m=\u001b[39m transpose(a) \u001b[38;5;28;01mif\u001b[39;00m tr_a \u001b[38;5;28;01melse\u001b[39;00m a\n\u001b[1;32m     18\u001b[0m b \u001b[38;5;241m=\u001b[39m transpose(b) \u001b[38;5;28;01mif\u001b[39;00m tr_b \u001b[38;5;28;01melse\u001b[39;00m b\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = model_sh\n",
    "\n",
    "batch_size = 256\n",
    "train_loader = DataLoader(dataset.train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# \n",
    "parameters = [\n",
    "    model.variational_strategy._variational_distribution.chol_variational_covar,\n",
    "]\n",
    "optimizer = torch.optim.Adam(parameters, lr=0.1)\n",
    "mll = gpytorch.mlls.VariationalELBO(model.likelihood, model, dataset.train_x.size(0))\n",
    "\n",
    "for x_batch, y_batch in train_loader:\n",
    "    x_batch, y_batch = projector(x_batch, y_batch)\n",
    "    optimizer.zero_grad()\n",
    "    output = model.variational_strategy(x_batch)\n",
    "    print_smallest_eigenvalues(output.covariance_matrix)\n",
    "    # print_smallest_eigenvalues(model.variational_strategy.variational_distribution.covariance_matrix)\n",
    "    loss = -mll(output, y_batch)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smallest eigenvalue: 9.999999988798501e-07\n",
      "1.5182695768211714\n",
      "Smallest eigenvalue: 9.999999989562332e-07\n",
      "1.4947433100617336\n",
      "Smallest eigenvalue: 9.99999998908287e-07\n",
      "1.4414993314065088\n",
      "Smallest eigenvalue: 9.999999988947179e-07\n",
      "1.4041950480701977\n",
      "Smallest eigenvalue: 9.999999990619052e-07\n",
      "1.3796913437218985\n",
      "Smallest eigenvalue: 9.999999991144903e-07\n",
      "1.3637745642671706\n",
      "Smallest eigenvalue: 9.999999990971003e-07\n",
      "1.3576423747766195\n",
      "Smallest eigenvalue: 9.999999990506075e-07\n",
      "1.3314937268999756\n",
      "Smallest eigenvalue: 9.9999999894546e-07\n",
      "1.3163540589840574\n",
      "Smallest eigenvalue: 9.99999999111952e-07\n",
      "1.3129889125774872\n",
      "Smallest eigenvalue: 9.999999990953514e-07\n",
      "1.3158454601627185\n",
      "Smallest eigenvalue: 9.999999990809995e-07\n",
      "1.323727298242035\n",
      "Smallest eigenvalue: 9.999999991838973e-07\n",
      "1.321055025913\n",
      "Smallest eigenvalue: 9.999999990535063e-07\n",
      "1.3224700873685378\n",
      "Smallest eigenvalue: 9.999999991874656e-07\n",
      "1.314687115369776\n",
      "Smallest eigenvalue: 9.999999991031666e-07\n",
      "1.3197032585534363\n",
      "Smallest eigenvalue: 9.999999990905072e-07\n",
      "1.3025987587707133\n",
      "Smallest eigenvalue: 9.999999991054512e-07\n",
      "1.3050405370506881\n",
      "Smallest eigenvalue: 9.999999992019376e-07\n",
      "1.3067107869455115\n",
      "Smallest eigenvalue: 9.999999990118287e-07\n",
      "1.304530700425213\n",
      "Smallest eigenvalue: 9.999999990095876e-07\n",
      "1.3092560000679492\n",
      "Smallest eigenvalue: 9.99999999079284e-07\n",
      "1.3116082613670794\n",
      "Smallest eigenvalue: 9.999999990838131e-07\n",
      "1.2969262832222974\n",
      "Smallest eigenvalue: 9.999999991489845e-07\n",
      "1.3213335387188043\n",
      "Smallest eigenvalue: 9.999999991351312e-07\n",
      "1.299386153966815\n",
      "Smallest eigenvalue: 9.99999999031657e-07\n",
      "1.2998667549983527\n",
      "Smallest eigenvalue: 9.999999991025478e-07\n",
      "1.2892492662864095\n",
      "Smallest eigenvalue: 9.999999989155013e-07\n",
      "1.3155163803022312\n",
      "Smallest eigenvalue: 1.0161330979551277e-06\n",
      "1.307991938396744\n"
     ]
    }
   ],
   "source": [
    "model = model_ip\n",
    "\n",
    "batch_size = 256\n",
    "train_loader = DataLoader(dataset.train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# \n",
    "parameters = [\n",
    "    model.variational_strategy._variational_distribution.chol_variational_covar,\n",
    "]\n",
    "optimizer = torch.optim.Adam(parameters, lr=0.1)\n",
    "mll = gpytorch.mlls.VariationalELBO(model.likelihood, model, dataset.train_x.size(0))\n",
    "\n",
    "for x_batch, y_batch in train_loader:\n",
    "    x_batch, y_batch = projector(x_batch, y_batch)\n",
    "    optimizer.zero_grad()\n",
    "    output = model(x_batch)\n",
    "    print_smallest_eigenvalues(output.covariance_matrix)\n",
    "    loss = -mll(output, y_batch)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print(loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px \n",
    "import pandas as pd \n",
    "\n",
    "\n",
    "def plot_kernel_vs_angle(kernel, dimension: int, n: int = 100): \n",
    "    pole = torch.zeros(1, dimension)\n",
    "    pole[:, -1] = 1.\n",
    "    theta = torch.linspace(0, torch.pi, n)\n",
    "    x = torch.cat([torch.zeros(n, dimension - 2), theta.cos().unsqueeze(-1), theta.sin().unsqueeze(-1)], dim=-1)\n",
    "    with torch.no_grad():\n",
    "        y = kernel(x).lazy_covariance_matrix[..., 0]\n",
    "        if y.ndim == 2: \n",
    "            y = y.mean(0)\n",
    "\n",
    "    data = pd.DataFrame({'theta': theta.squeeze().numpy(), 'y': y})\n",
    "    fig = px.line(data, x='theta', y='y')\n",
    "    fig.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mdgp_requirements_test1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
