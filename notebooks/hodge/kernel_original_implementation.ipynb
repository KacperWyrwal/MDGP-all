{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax \n",
    "import jax.numpy as jnp \n",
    "from jax.scipy.special import lpmn_values\n",
    "MAX_ELL = 35\n",
    "\n",
    "\n",
    "def array(els):\n",
    "    return jnp.array(els, dtype='float64')\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def legendre_values(x, y):\n",
    "    # x, y in cartesian coordinates\n",
    "    legendre_vals = lpmn_values(MAX_ELL, MAX_ELL, jnp.dot(x, y)[None], False)\n",
    "    legendre_vals = jnp.squeeze(legendre_vals[0, :, :])\n",
    "    return legendre_vals\n",
    "\n",
    "\n",
    "@jax.jit \n",
    "def lambd(ell: int) -> int: \n",
    "    return ell * (ell + 1)\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def phi(kappa: float, nu: float, lam: float) -> float: \n",
    "    return jnp.power(2 * nu / kappa + lam, -nu - 1)\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def legendre_tilde_constant(kappa: float, nu: float, ell: int) -> float:\n",
    "    lambd_ell = lambd(ell)\n",
    "    return (2 * ell + 1) / (4 * jnp.pi * lambd_ell) * phi(kappa, nu, lambd_ell)\n",
    "\n",
    "\n",
    "@jax.jit \n",
    "def legendre_tilde_values(x, y, kappa: float = 1.0, nu: float = 2.5):\n",
    "    legendre_vals = legendre_values(x, y)[1:]\n",
    "    return jnp.multiply(\n",
    "        legendre_vals, \n",
    "        array([legendre_tilde_constant(kappa, nu, ell) for ell in jnp.arange(1, MAX_ELL + 1)])\n",
    "    )\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def hodge_matern_k_mine(x, y, kappa: float = 1.0, nu: float = 2.5):\n",
    "    \"\"\"\n",
    "    This to me is the math-to-code translation of the equation for the (unnormalized)\n",
    "    curl-free kernel. \n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    # x, y in cartesian coordinates\n",
    "    dx = jax.jacfwd(legendre_tilde_values, argnums=0)(x, y, kappa, nu) # grad wrt x P(x cdot y)\n",
    "    dy = jax.jacfwd(legendre_tilde_values, argnums=1)(x, y, kappa, nu) # grad wrt y P(x cdot y)\n",
    "    dxody = jnp.einsum('ij, ik -> ijk', dx, dy) # outer product' # dx outer dy \n",
    "    return dxody.sum(axis=0) # sum of outer products\n",
    "    return jnp.einsum('ij, ik -> jk', dx, dy) # sum of outer products \n",
    "\n",
    "\n",
    "# The first implementation is taken directly from the code for Intrinsic Gaussian Vector Fields on Manifolds. \n",
    "# The second implementation is equivalent to the first.     \n",
    "\n",
    "@jax.jit\n",
    "def hodge_matern_k(x, y, kappa: float = 1.0, nu: float = 2.5):\n",
    "    \"\"\"\n",
    "    Unnormalized hodge matern kernel on the sphere. \n",
    "    \"\"\"\n",
    "    # x, y in cartesian coordinates\n",
    "    dd_legendre_vals = jax.jacfwd(jax.jacfwd(legendre_values, argnums=0), argnums=1)(x, y)[1:]\n",
    "    # d term\n",
    "    dd = jnp.multiply(\n",
    "        dd_legendre_vals,\n",
    "        array([\n",
    "            jnp.power(2 * nu / kappa + ell * (ell + 1), -nu - 1) * (2 * ell + 1) / (4 * jnp.pi * ell * (ell + 1)) # legendre_tilde_constant\n",
    "            for ell in jnp.arange(1, MAX_ELL + 1)])[:, None, None]\n",
    "    ).sum(axis=0)\n",
    "    # vector k\n",
    "    vk = dd\n",
    "    return vk\n",
    "\n",
    "\n",
    "@jax.jit \n",
    "def scalar_matern_k(x, y, kappa: float = 1.0, nu: float = 2.5): \n",
    "    \"\"\"\n",
    "    Unnormalized matern kernel on the sphere. \n",
    "    \"\"\"\n",
    "    return legendre_tilde_values(x, y, kappa, nu).sum(axis=0)\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def hodge_matern_k_equivalent_curl_free(x, y, kappa: float = 1.0, nu: float = 2.5):\n",
    "    \"\"\"\n",
    "    Unnormalized hodge matern kernel on the sphere. Equivalent to hodge_matern_k. \n",
    "\n",
    "    How does a sum of outer products of gradients relate to the second order partial derivatives? \n",
    "    \"\"\"\n",
    "    return jax.jacfwd(jax.jacfwd(scalar_matern_k, argnums=0), argnums=1)(x, y, kappa, nu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_458897/3176565350.py:8: UserWarning: Explicitly requested dtype float64 requested in array is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  return jnp.array(els, dtype='float64')\n",
      "An NVIDIA GPU may be present on this machine, but a CUDA-enabled jaxlib is not installed. Falling back to cpu.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.00019812 0.         0.        ]\n",
      " [0.         0.00019812 0.        ]\n",
      " [0.         0.         0.0003328 ]]\n",
      "[[0.00019812 0.         0.        ]\n",
      " [0.         0.00019812 0.        ]\n",
      " [0.         0.         0.0003328 ]]\n",
      "[[0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 1.9545936e-08]]\n"
     ]
    }
   ],
   "source": [
    "x = array([0., 0., 1.])\n",
    "y = array([0., 1., 0.])\n",
    "\n",
    "print(hodge_matern_k(x, x))\n",
    "print(hodge_matern_k_equivalent(x, x))\n",
    "print(hodge_matern_k_mine(x, x))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mdgp_requirements_test1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
