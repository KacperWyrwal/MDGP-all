{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load in data\n",
    "Currently supported datasets: power, protein, kin8nm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import geometric_kernels.torch \n",
    "\n",
    "torch.set_default_dtype(torch.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create data on S^D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Using numpy backend\n"
     ]
    }
   ],
   "source": [
    "from geometric_kernels.spaces import Hypersphere\n",
    "from mdgp.utils.sphere import sphere_uniform_grid, spherical_harmonic\n",
    "\n",
    "\n",
    "def get_space_and_data(n=200):\n",
    "    x = sphere_uniform_grid(n)\n",
    "    y = spherical_harmonic(x, 2, 3)\n",
    "    return Hypersphere(2), x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instantiate model\n",
    "\n",
    "This is done using the same model arguments as for the benchmarking experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import Tensor \n",
    "from gpytorch.means import Mean\n",
    "from gpytorch.kernels import ScaleKernel\n",
    "from gpytorch.models import ApproximateGP\n",
    "from gpytorch.variational import CholeskyVariationalDistribution\n",
    "from mdgp.kernels import GeometricMaternKernel\n",
    "\n",
    "\n",
    "import torch \n",
    "from gpytorch import settings\n",
    "from gpytorch.distributions import MultivariateNormal\n",
    "# TODO Maybe just move the functions from spherical_harmonic_features.py into this file?\n",
    "from mdgp.utils.spherical_harmonic_features import num_spherical_harmonics_to_degree, matern_Kuu, matern_LT_Phi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VariationalDistribution(torch.nn.Module):\n",
    "    def __init__(self, num_inducing: int):\n",
    "        super().__init__()\n",
    "        self.num_inducing = num_inducing\n",
    "        self.chol_variational_covar = torch.nn.Parameter(torch.eye(num_inducing))\n",
    "\n",
    "    def forward(self) -> MultivariateNormal:\n",
    "        covar = self.chol_variational_covar @ self.chol_variational_covar.mT\n",
    "        return MultivariateNormal(torch.zeros(self.num_inducing), covar)\n",
    "    \n",
    "\n",
    "class SHVariationalStrategy(torch.nn.Module):\n",
    "    def __init__(self,\n",
    "        covar_module: GeometricMaternKernel,\n",
    "        dimension: int,\n",
    "        num_spherical_harmonics: int,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.covar_module = covar_module\n",
    "        self.dimension = dimension\n",
    "        self.degree, self.num_spherical_harmonics = num_spherical_harmonics_to_degree(num_spherical_harmonics, dimension)\n",
    "        self._variational_distribution = VariationalDistribution(num_spherical_harmonics)\n",
    "\n",
    "    @property\n",
    "    def kappa(self) -> Tensor:\n",
    "        return torch.tensor([[0.001]])\n",
    "    \n",
    "    @property\n",
    "    def nu(self) -> Tensor | float:\n",
    "        return torch.tensor([[2.5]])\n",
    "\n",
    "    @property \n",
    "    def sigma(self) -> Tensor: \n",
    "        return torch.tensor(1.0)\n",
    "\n",
    "    @property\n",
    "    def prior_distribution(self) -> MultivariateNormal:\n",
    "        covariance_matrix = torch.eye(self.num_spherical_harmonics)\n",
    "        mean = torch.zeros(self.num_spherical_harmonics)\n",
    "        return MultivariateNormal(mean=mean, covariance_matrix=covariance_matrix)\n",
    "        \n",
    "    @property\n",
    "    def variational_distribution(self) -> MultivariateNormal:\n",
    "        return self._variational_distribution()\n",
    "\n",
    "    def forward(self, x: Tensor, **kwargs) -> MultivariateNormal:\n",
    "        # inducing-inducing prior\n",
    "        pu = self.prior_distribution\n",
    "        invL_Kuu_invLt = pu.lazy_covariance_matrix\n",
    "\n",
    "        # input-input prior\n",
    "        Kxx = self.covar_module(x)\n",
    "\n",
    "        # inducing-inducing variational\n",
    "        qu = self.variational_distribution\n",
    "        invL_S_invLt = qu.lazy_covariance_matrix\n",
    "\n",
    "        # inducing-input prior  \n",
    "        LT_Phi = matern_LT_Phi(x, max_ell=self.degree, d=self.dimension, kappa=self.kappa, nu=self.nu, sigma=self.sigma,) # [..., O, num_harmonics, N]\n",
    "\n",
    "        # Update the covariance matrix\n",
    "        covariance_matrix_update = LT_Phi.mT @ (invL_S_invLt - invL_Kuu_invLt) @ LT_Phi # [O, num_harmonics, num_harmonics] @ [O, num_harmonics, num_harmonics] @ [O, num_harmonics, N] -> [O, num_harmonics, N]\n",
    "        updated_covariance_matrix = Kxx + covariance_matrix_update # [..., O, N, N] + [..., O, N, N] -> [..., O, N, N]\n",
    "\n",
    "        return MultivariateNormal(mean=torch.zeros(x.shape[:-1]), covariance_matrix=updated_covariance_matrix)\n",
    "\n",
    "    def kl_divergence(self) -> Tensor:\n",
    "        with settings.max_preconditioner_size(0):\n",
    "            kl_divergence = torch.distributions.kl.kl_divergence(self.variational_distribution, self.prior_distribution)\n",
    "        return kl_divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mdgp.utils.spherical_harmonic_features import matern_Kux, matern_Kuu\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class SHVariationalStrategy(torch.nn.Module):\n",
    "    def __init__(self,\n",
    "        covar_module: GeometricMaternKernel,\n",
    "        dimension: int,\n",
    "        num_spherical_harmonics: int,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.covar_module = covar_module\n",
    "        self.dimension = dimension\n",
    "        self.degree, self.num_spherical_harmonics = num_spherical_harmonics_to_degree(num_spherical_harmonics, dimension)\n",
    "        self._variational_distribution = VariationalDistribution(num_spherical_harmonics)\n",
    "        self._variational_distribution.chol_variational_covar = torch.nn.Parameter(\n",
    "            matern_Kuu(max_ell=self.degree, d=self.dimension, kappa=self.kappa, nu=self.nu, sigma=self.sigma).sqrt().to_dense()\n",
    "        )\n",
    "\n",
    "    @property\n",
    "    def kappa(self) -> Tensor:\n",
    "        return torch.tensor([[0.001]])\n",
    "    \n",
    "    @property\n",
    "    def nu(self) -> Tensor | float:\n",
    "        return torch.tensor([[2.5]])\n",
    "\n",
    "    @property \n",
    "    def sigma(self) -> Tensor: \n",
    "        return torch.tensor(1.0)\n",
    "\n",
    "    @property\n",
    "    def prior_distribution(self) -> MultivariateNormal:\n",
    "        covariance_matrix = matern_Kuu(max_ell=self.degree, d=self.dimension, kappa=self.kappa, nu=self.nu, sigma=self.sigma)\n",
    "        mean = torch.zeros(self.num_spherical_harmonics)\n",
    "        return MultivariateNormal(mean=mean, covariance_matrix=covariance_matrix)\n",
    "        \n",
    "    @property\n",
    "    def variational_distribution(self) -> MultivariateNormal:\n",
    "        return self._variational_distribution()\n",
    "\n",
    "    def forward(self, x: Tensor, **kwargs) -> MultivariateNormal:\n",
    "        jitter = 1e-6\n",
    "        # inducing-inducing prior\n",
    "        Kuu = matern_Kuu(max_ell=self.degree, d=self.dimension, kappa=self.kappa, nu=self.nu, sigma=self.sigma)\n",
    "        Kuu = Kuu.add_jitter(jitter)\n",
    "        Kuu_inv = Kuu.to_dense().inverse()\n",
    "\n",
    "        # input-input prior\n",
    "        Kxx = self.covar_module(x)\n",
    "        Kxx = Kxx.add_jitter(jitter)\n",
    "\n",
    "        # inducing-input prior\n",
    "        Kux = matern_Kux(x, max_ell=self.degree, d=self.dimension)\n",
    "\n",
    "        # inducing-inducing variational\n",
    "        S = self.variational_distribution.covariance_matrix\n",
    "\n",
    "        # inducing-input prior  \n",
    "        covariance_matrix_update = Kux.mT @ Kuu_inv.mT @ (S - Kuu) @ Kuu_inv @ Kux # Since Kxx is always PSD, if the updated cov is not PSD, then the update must not be PSD\n",
    "        # covariance_matrix_update = covariance_matrix_update + torch.eye(covariance_matrix_update.shape[-1]).mul(jitter)\n",
    "        updated_covariance_matrix = Kxx + covariance_matrix_update \n",
    "\n",
    "        return MultivariateNormal(mean=torch.zeros(x.shape[:-1]), covariance_matrix=updated_covariance_matrix)\n",
    "\n",
    "    def kl_divergence(self) -> Tensor:\n",
    "        with settings.max_preconditioner_size(0):\n",
    "            kl_divergence = torch.distributions.kl.kl_divergence(self.variational_distribution, self.prior_distribution)\n",
    "        return kl_divergence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple shallow variational GP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gpytorch\n",
    "\n",
    "\n",
    "class SHApproximateGP(gpytorch.models.ApproximateGP):\n",
    "    def __init__(self, dimension: int, num_spherical_harmonics: int, \n",
    "                 mean: Mean, covar_module: GeometricMaternKernel, variational_distribution: CholeskyVariationalDistribution):\n",
    "        variational_strategy = SHVariationalStrategy(\n",
    "            covar_module=covar_module,\n",
    "            dimension=dimension,\n",
    "            num_spherical_harmonics=num_spherical_harmonics,\n",
    "        )\n",
    "        super().__init__(variational_strategy)\n",
    "        self.mean_module = mean\n",
    "        self.covar_module = covar_module\n",
    "        self.likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "\n",
    "\n",
    "    def forward(self, x: Tensor) -> MultivariateNormal:\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return MultivariateNormal(mean_x, covar_x)\n",
    "    \n",
    "\n",
    "class IPApproximateGP(gpytorch.models.ApproximateGP):\n",
    "    def __init__(self, mean: Mean, covar_module: GeometricMaternKernel, inducing_points: Tensor, variational_distribution: CholeskyVariationalDistribution):\n",
    "        variational_strategy = gpytorch.variational.UnwhitenedVariationalStrategy(\n",
    "            self, \n",
    "            inducing_points=inducing_points,\n",
    "            variational_distribution=variational_distribution, \n",
    "            learn_inducing_locations=False\n",
    "        )\n",
    "        super().__init__(variational_strategy)\n",
    "        self.mean_module = mean\n",
    "        self.covar_module = covar_module\n",
    "        self.likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "\n",
    "    def forward(self, x: Tensor) -> MultivariateNormal:\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return MultivariateNormal(mean_x, covar_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model\n",
    "Training has to be done differently from the bechmarking experiment, because we need minibatch SGD with the larger datasets and minibatch metrics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_smallest_eigenvalues(covar):\n",
    "    # mvn = projector.inverse(mvn)\n",
    "    smallest_eigenvalues = torch.linalg.eigvalsh(covar).min()\n",
    "    print(f\"Smallest eigenvalue: {smallest_eigenvalues.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of spherical harmonics requested does not lead to complete levels of spherical harmonics. We have thus increased the number to 529, which includes all spherical harmonics up to degree 23 (incl.)\n"
     ]
    }
   ],
   "source": [
    "from geometric_kernels.spaces import Hypersphere\n",
    "from mdgp.utils.spherical_harmonic_features import num_spherical_harmonics_to_degree\n",
    "\n",
    "\n",
    "dimension = 2\n",
    "space, x, y = get_space_and_data(200)\n",
    "num_spherical_harmonics = 500\n",
    "\n",
    "degree, num_spherical_harmonics = num_spherical_harmonics_to_degree(num_spherical_harmonics, dimension + 1)\n",
    "\n",
    "batch_shape = torch.Size([])\n",
    "\n",
    "# Model with spherical harmonic features\n",
    "mean = gpytorch.means.ZeroMean()\n",
    "covar_module = GeometricMaternKernel(nu=2.5, space=space, num_eigenfunctions=30, batch_shape=batch_shape)\n",
    "covar_module.initialize(lengthscale=1.0)\n",
    "covar_module = ScaleKernel(covar_module)\n",
    "variational_distribution = gpytorch.variational.CholeskyVariationalDistribution(\n",
    "    num_inducing_points=num_spherical_harmonics, batch_shape=batch_shape\n",
    ")\n",
    "\n",
    "model_sh = SHApproximateGP(\n",
    "    dimension=dimension + 1,\n",
    "    num_spherical_harmonics=num_spherical_harmonics,\n",
    "    mean=mean,\n",
    "    covar_module=covar_module,\n",
    "    variational_distribution=variational_distribution,\n",
    ")\n",
    "\n",
    "# Model with inducing points \n",
    "mean = gpytorch.means.ZeroMean()\n",
    "covar_module = GeometricMaternKernel(nu=2.5, space=space, num_eigenfunctions=30, batch_shape=batch_shape)\n",
    "covar_module.initialize(lengthscale=1.0)\n",
    "variational_distribution = gpytorch.variational.CholeskyVariationalDistribution(\n",
    "    num_inducing_points=num_spherical_harmonics, batch_shape=batch_shape\n",
    ")\n",
    "\n",
    "inducing_points = torch.randn(num_spherical_harmonics, dimension + 1)\n",
    "inducing_points = inducing_points / inducing_points.norm(dim=-1, keepdim=True)\n",
    "model_ip = IPApproximateGP(\n",
    "    mean=mean,\n",
    "    covar_module=covar_module,\n",
    "    inducing_points=inducing_points,\n",
    "    variational_distribution=variational_distribution\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smallest eigenvalue: 0.000138436906963486\n",
      "1.2643801216225734\n",
      "Smallest eigenvalue: -0.05670803228225404\n",
      "1.2461014181538244\n",
      "Smallest eigenvalue: -0.11158823229680875\n",
      "1.2288470769104518\n",
      "Smallest eigenvalue: -0.16427468676872647\n",
      "1.212423815069876\n",
      "Smallest eigenvalue: -0.21479486884665155\n",
      "1.1965878577848377\n",
      "Smallest eigenvalue: -0.26320631844133957\n",
      "1.181235522393201\n",
      "Smallest eigenvalue: -0.3095788170674781\n",
      "1.1663263047864552\n",
      "Smallest eigenvalue: -0.35395804260083913\n",
      "1.1518324214004605\n",
      "Smallest eigenvalue: -0.396357346097838\n",
      "1.1377288360970554\n",
      "Smallest eigenvalue: -0.4367697429263466\n",
      "1.1239917991715833\n",
      "Smallest eigenvalue: -0.47519045600118875\n",
      "1.1105985933241764\n",
      "Smallest eigenvalue: -0.511633643576327\n",
      "1.0975272229438278\n",
      "Smallest eigenvalue: -0.5461348873312788\n",
      "1.0847561555432066\n",
      "Smallest eigenvalue: -0.5787491663370447\n",
      "1.0722642800419695\n",
      "Smallest eigenvalue: -0.6095455730285996\n",
      "1.06003100088277\n",
      "Smallest eigenvalue: -0.638598516848669\n",
      "1.0480363013234315\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1000\u001b[39m):\n\u001b[1;32m      9\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 10\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvariational_strategy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m     print_smallest_eigenvalues(output\u001b[38;5;241m.\u001b[39mcovariance_matrix)\n\u001b[1;32m     12\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39mmll(output, y)\n",
      "File \u001b[0;32m~/miniconda3/envs/mdgp_requirements_test1/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/mdgp_requirements_test1/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[5], line 59\u001b[0m, in \u001b[0;36mSHVariationalStrategy.forward\u001b[0;34m(self, x, **kwargs)\u001b[0m\n\u001b[1;32m     56\u001b[0m Kxx \u001b[38;5;241m=\u001b[39m Kxx\u001b[38;5;241m.\u001b[39madd_jitter(jitter)\n\u001b[1;32m     58\u001b[0m \u001b[38;5;66;03m# inducing-input prior\u001b[39;00m\n\u001b[0;32m---> 59\u001b[0m Kux \u001b[38;5;241m=\u001b[39m \u001b[43mmatern_Kux\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_ell\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdegree\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdimension\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;66;03m# inducing-inducing variational\u001b[39;00m\n\u001b[1;32m     62\u001b[0m S \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvariational_distribution\u001b[38;5;241m.\u001b[39mcovariance_matrix\n",
      "File \u001b[0;32m~/miniconda3/envs/mdgp_requirements_test1/lib/python3.11/site-packages/mdgp/utils/spherical_harmonic_features.py:136\u001b[0m, in \u001b[0;36mmatern_Kux\u001b[0;34m(x, max_ell, d)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmatern_Kux\u001b[39m(x: Tensor, max_ell: \u001b[38;5;28mint\u001b[39m, d: \u001b[38;5;28mint\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor: \n\u001b[0;32m--> 136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mspherical_harmonics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_ell\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_ell\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43md\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mmT\n",
      "File \u001b[0;32m~/miniconda3/envs/mdgp_requirements_test1/lib/python3.11/site-packages/mdgp/utils/spherical_harmonic_features.py:129\u001b[0m, in \u001b[0;36mspherical_harmonics\u001b[0;34m(x, max_ell, d)\u001b[0m\n\u001b[1;32m    126\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mflatten(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    128\u001b[0m \u001b[38;5;66;03m# Get spherical harmonics callable\u001b[39;00m\n\u001b[0;32m--> 129\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[43mSphericalHarmonics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdimension\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43md\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdegrees\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_ell\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# [... * O, N, num_harmonics]\u001b[39;00m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;66;03m# Evaluate x and reintroduce batch dimensions\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m f(x)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m*\u001b[39mbatch_shape, n, total_num_harmonics(max_ell, d))\n",
      "File \u001b[0;32m~/miniconda3/envs/mdgp_requirements_test1/lib/python3.11/site-packages/spherical_harmonics/spherical_harmonics.py:60\u001b[0m, in \u001b[0;36mSphericalHarmonics.__init__\u001b[0;34m(self, dimension, degrees, debug)\u001b[0m\n\u001b[1;32m     57\u001b[0m     degrees \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mrange\u001b[39m(degrees))\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfundamental_system \u001b[38;5;241m=\u001b[39m FundamentalSystemCache(dimension)\n\u001b[0;32m---> 60\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mharmonic_levels \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m    \u001b[49m\u001b[43mSphericalHarmonicsLevel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdimension\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdegree\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfundamental_system\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdegree\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdegrees\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[43m\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/mdgp_requirements_test1/lib/python3.11/site-packages/spherical_harmonics/spherical_harmonics.py:61\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     57\u001b[0m     degrees \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mrange\u001b[39m(degrees))\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfundamental_system \u001b[38;5;241m=\u001b[39m FundamentalSystemCache(dimension)\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mharmonic_levels \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m---> 61\u001b[0m     \u001b[43mSphericalHarmonicsLevel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdimension\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdegree\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfundamental_system\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m degree \u001b[38;5;129;01min\u001b[39;00m degrees\n\u001b[1;32m     63\u001b[0m ]\n",
      "File \u001b[0;32m~/miniconda3/envs/mdgp_requirements_test1/lib/python3.11/site-packages/spherical_harmonics/spherical_harmonics.py:141\u001b[0m, in \u001b[0;36mSphericalHarmonicsLevel.__init__\u001b[0;34m(self, dimension, degree, fundamental_system)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mL \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mcholesky(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mA)  \u001b[38;5;66;03m# [M, M]\u001b[39;00m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;66;03m# Cholesky inverse corresponds to the weights you get from Gram-Schmidt\u001b[39;00m\n\u001b[0;32m--> 141\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mL_inv \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msolve\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mL\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meye\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mL\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgegenbauer \u001b[38;5;241m=\u001b[39m Gegenbauer(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdegree, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malpha)\n",
      "File \u001b[0;32m~/miniconda3/envs/mdgp_requirements_test1/lib/python3.11/site-packages/numpy/linalg/linalg.py:409\u001b[0m, in \u001b[0;36msolve\u001b[0;34m(a, b)\u001b[0m\n\u001b[1;32m    407\u001b[0m signature \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDD->D\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m isComplexType(t) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdd->d\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    408\u001b[0m extobj \u001b[38;5;241m=\u001b[39m get_linalg_error_extobj(_raise_linalgerror_singular)\n\u001b[0;32m--> 409\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43mgufunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    411\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrap(r\u001b[38;5;241m.\u001b[39mastype(result_t, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = model_sh\n",
    "\n",
    "# \n",
    "parameters = model.parameters()\n",
    "optimizer = torch.optim.Adam(parameters, lr=0.01)\n",
    "mll = gpytorch.mlls.VariationalELBO(model.likelihood, model, y.size(0))\n",
    "\n",
    "for i in range(1000):\n",
    "    optimizer.zero_grad()\n",
    "    output = model.variational_strategy(x)\n",
    "    print_smallest_eigenvalues(output.covariance_matrix)\n",
    "    loss = -mll(output, y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smallest eigenvalue: 1.1481051897019095e-07\n",
      "418.7588268497319\n",
      "Smallest eigenvalue: 1.1481051896040093e-07\n",
      "135206.41611263787\n",
      "Smallest eigenvalue: 1.1481051931463858e-07\n",
      "28516.621114224683\n",
      "Smallest eigenvalue: 1.1481051833897677e-07\n",
      "45890.731124151054\n",
      "Smallest eigenvalue: 1.1481051960847277e-07\n",
      "70374.32070225292\n",
      "Smallest eigenvalue: 1.1481051681177052e-07\n",
      "50411.19093092461\n",
      "Smallest eigenvalue: 1.1481051870067949e-07\n",
      "24583.84176166236\n",
      "Smallest eigenvalue: 1.1481051827941582e-07\n",
      "17814.314417809554\n",
      "Smallest eigenvalue: 1.1481051978054234e-07\n",
      "26099.420989398466\n",
      "Smallest eigenvalue: 1.1481051856745828e-07\n",
      "31718.77870604916\n",
      "Smallest eigenvalue: 1.1481051885604307e-07\n",
      "26540.292297390377\n",
      "Smallest eigenvalue: 1.1481051846563987e-07\n",
      "16712.760769188648\n",
      "Smallest eigenvalue: 1.14810519520386e-07\n",
      "10931.868048022894\n",
      "Smallest eigenvalue: 1.148105188095749e-07\n",
      "11693.621856448437\n",
      "Smallest eigenvalue: 1.1481051872180677e-07\n",
      "15096.564575818524\n",
      "Smallest eigenvalue: 1.1481051965177757e-07\n",
      "15992.366172978744\n",
      "Smallest eigenvalue: 1.1481052005829007e-07\n",
      "12954.293522717497\n",
      "Smallest eigenvalue: 1.1481051941792441e-07\n",
      "8600.563698422908\n",
      "Smallest eigenvalue: 1.1481052070833112e-07\n",
      "6173.361088366788\n",
      "Smallest eigenvalue: 1.1481052072434743e-07\n",
      "6539.342745968342\n",
      "Smallest eigenvalue: 1.1481052000251959e-07\n",
      "7973.095812849791\n",
      "Smallest eigenvalue: 1.1481051810938668e-07\n",
      "8270.691107346289\n",
      "Smallest eigenvalue: 1.1481051922345273e-07\n",
      "6812.5173728317495\n",
      "Smallest eigenvalue: 1.1481052021868902e-07\n",
      "4748.816324895329\n",
      "Smallest eigenvalue: 1.1481051885260184e-07\n",
      "3602.2475945075375\n",
      "Smallest eigenvalue: 1.1481051828838996e-07\n",
      "3806.7709712339765\n",
      "Smallest eigenvalue: 1.1481051782952309e-07\n",
      "4469.469370350108\n",
      "Smallest eigenvalue: 1.1481051957098448e-07\n",
      "4448.5661634709595\n",
      "Smallest eigenvalue: 1.1481052036820288e-07\n",
      "3531.0608860487246\n",
      "Smallest eigenvalue: 1.1481051933284449e-07\n",
      "2480.0563796768306\n",
      "Smallest eigenvalue: 1.1481052018031788e-07\n",
      "2081.0794333473937\n",
      "Smallest eigenvalue: 1.1481051921927876e-07\n",
      "2349.6708933969994\n",
      "Smallest eigenvalue: 1.1481051925378123e-07\n",
      "2635.6074270258537\n",
      "Smallest eigenvalue: 1.1481051909289035e-07\n",
      "2402.0466831861954\n",
      "Smallest eigenvalue: 1.1481051882728592e-07\n",
      "1766.0214392414657\n",
      "Smallest eigenvalue: 1.1481052045219045e-07\n",
      "1265.5013035122802\n",
      "Smallest eigenvalue: 1.148105178155423e-07\n",
      "1224.620878309891\n",
      "Smallest eigenvalue: 1.1481051848710135e-07\n",
      "1460.2078280541427\n",
      "Smallest eigenvalue: 1.148105195133998e-07\n",
      "1543.3529870495374\n",
      "Smallest eigenvalue: 1.148105186179844e-07\n",
      "1303.3357761833993\n",
      "Smallest eigenvalue: 1.1481051942220488e-07\n",
      "958.0653584654943\n",
      "Smallest eigenvalue: 1.1481051917933115e-07\n",
      "808.7203534919557\n",
      "Smallest eigenvalue: 1.1481051789506438e-07\n",
      "901.1980634441861\n",
      "Smallest eigenvalue: 1.1481051961083613e-07\n",
      "997.2638132854672\n",
      "Smallest eigenvalue: 1.1481051935413709e-07\n",
      "885.5876326044498\n",
      "Smallest eigenvalue: 1.148105205659657e-07\n",
      "632.063729631743\n",
      "Smallest eigenvalue: 1.148105202323831e-07\n",
      "462.334575597158\n",
      "Smallest eigenvalue: 1.148105185516907e-07\n",
      "470.0407892061788\n",
      "Smallest eigenvalue: 1.1481051938696865e-07\n",
      "543.2291527689259\n",
      "Smallest eigenvalue: 1.1481051767002159e-07\n",
      "527.656932271006\n",
      "Smallest eigenvalue: 1.1481051892582691e-07\n",
      "416.4581790505814\n",
      "Smallest eigenvalue: 1.148105189188279e-07\n",
      "332.4206663566661\n",
      "Smallest eigenvalue: 1.148105199221656e-07\n",
      "344.4211898500307\n",
      "Smallest eigenvalue: 1.1481051888287002e-07\n",
      "384.9875980185453\n",
      "Smallest eigenvalue: 1.1481052015793952e-07\n",
      "362.0879357190781\n",
      "Smallest eigenvalue: 1.1481052037486989e-07\n",
      "279.1238384535686\n",
      "Smallest eigenvalue: 1.148105186953101e-07\n",
      "215.31748585476726\n",
      "Smallest eigenvalue: 1.1481051877058303e-07\n",
      "213.18797856445545\n",
      "Smallest eigenvalue: 1.1481051942030864e-07\n",
      "230.9272147614558\n",
      "Smallest eigenvalue: 1.1481052040839663e-07\n",
      "213.66658639921857\n",
      "Smallest eigenvalue: 1.1481051950561239e-07\n",
      "165.75508771761454\n",
      "Smallest eigenvalue: 1.1481051963934313e-07\n",
      "134.99475795064325\n",
      "Smallest eigenvalue: 1.1481051892712958e-07\n",
      "139.93874208924376\n",
      "Smallest eigenvalue: 1.1481052003499916e-07\n",
      "175.33655121233184\n",
      "Smallest eigenvalue: 1.1481051976833133e-07\n",
      "239.17032507050433\n",
      "Smallest eigenvalue: 1.1481051934480276e-07\n",
      "314.7486339574727\n",
      "Smallest eigenvalue: 1.1481052023448629e-07\n",
      "388.14312830938684\n",
      "Smallest eigenvalue: 1.148105200887281e-07\n",
      "447.0661868997433\n",
      "Smallest eigenvalue: 1.1481051802704814e-07\n",
      "472.60189601736664\n",
      "Smallest eigenvalue: 1.1481051807188182e-07\n",
      "463.5112907730969\n",
      "Smallest eigenvalue: 1.1481051901703278e-07\n",
      "438.3333752595299\n",
      "Smallest eigenvalue: 1.148105191223377e-07\n",
      "408.4925060370695\n",
      "Smallest eigenvalue: 1.1481051899484518e-07\n",
      "388.7160598186813\n",
      "Smallest eigenvalue: 1.1481051864274269e-07\n",
      "373.82540715727333\n",
      "Smallest eigenvalue: 1.1481051847880547e-07\n",
      "342.21078508667614\n",
      "Smallest eigenvalue: 1.1481051934717834e-07\n",
      "295.4127150176938\n",
      "Smallest eigenvalue: 1.1481052002841511e-07\n",
      "243.38370120761886\n",
      "Smallest eigenvalue: 1.1481051876783952e-07\n",
      "194.32206599808347\n",
      "Smallest eigenvalue: 1.1481051860253701e-07\n",
      "155.56163009094752\n",
      "Smallest eigenvalue: 1.1481051821683856e-07\n",
      "129.18678224754217\n",
      "Smallest eigenvalue: 1.148105197836233e-07\n",
      "113.04579990344757\n",
      "Smallest eigenvalue: 1.1481051982128549e-07\n",
      "105.30226975205188\n",
      "Smallest eigenvalue: 1.1481051919634689e-07\n",
      "104.9873741999304\n",
      "Smallest eigenvalue: 1.1481052100162909e-07\n",
      "107.18247049504888\n",
      "Smallest eigenvalue: 1.1481051963612603e-07\n",
      "107.94177423244638\n",
      "Smallest eigenvalue: 1.148105194173823e-07\n",
      "108.29959289509183\n",
      "Smallest eigenvalue: 1.1481051993322609e-07\n",
      "109.71581474008319\n",
      "Smallest eigenvalue: 1.1481051930936919e-07\n",
      "111.91918515020105\n",
      "Smallest eigenvalue: 1.1481052031024068e-07\n",
      "110.56779096596576\n",
      "Smallest eigenvalue: 1.1481052085235785e-07\n",
      "102.21159570083678\n",
      "Smallest eigenvalue: 1.1481051789662738e-07\n",
      "89.18610286074998\n",
      "Smallest eigenvalue: 1.1481051833216277e-07\n",
      "74.69041775965252\n",
      "Smallest eigenvalue: 1.1481051886542338e-07\n",
      "60.55937198065565\n",
      "Smallest eigenvalue: 1.1481052025528972e-07\n",
      "48.29727893921249\n",
      "Smallest eigenvalue: 1.1481051885699299e-07\n",
      "39.39632108454535\n",
      "Smallest eigenvalue: 1.1481051852249502e-07\n",
      "34.34762908517111\n",
      "Smallest eigenvalue: 1.1481051904003052e-07\n",
      "31.850435491267945\n",
      "Smallest eigenvalue: 1.1481051800411721e-07\n",
      "30.251482489314302\n",
      "Smallest eigenvalue: 1.1481051963975122e-07\n",
      "30.354760800640793\n",
      "Smallest eigenvalue: 1.1481051915543345e-07\n",
      "31.929598364604185\n"
     ]
    }
   ],
   "source": [
    "model = model_ip\n",
    "batch_size = 256\n",
    "\n",
    "# \n",
    "parameters = [\n",
    "    model.variational_strategy._variational_distribution.chol_variational_covar,\n",
    "]\n",
    "optimizer = torch.optim.Adam(parameters, lr=0.1)\n",
    "mll = gpytorch.mlls.VariationalELBO(model.likelihood, model, y.size(0))\n",
    "\n",
    "for i in range(100):\n",
    "    optimizer.zero_grad()\n",
    "    output = model.variational_strategy(x)\n",
    "    print_smallest_eigenvalues(output.covariance_matrix)\n",
    "    # print_smallest_eigenvalues(model.variational_strategy.variational_distribution.covariance_matrix)\n",
    "    loss = -mll(output, y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print(loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px \n",
    "import pandas as pd \n",
    "\n",
    "\n",
    "def plot_kernel_vs_angle(kernel, dimension: int, n: int = 100): \n",
    "    pole = torch.zeros(1, dimension)\n",
    "    pole[:, -1] = 1.\n",
    "    theta = torch.linspace(0, torch.pi, n)\n",
    "    x = torch.cat([torch.zeros(n, dimension - 2), theta.cos().unsqueeze(-1), theta.sin().unsqueeze(-1)], dim=-1)\n",
    "    with torch.no_grad():\n",
    "        y = kernel(x).lazy_covariance_matrix[..., 0]\n",
    "        if y.ndim == 2: \n",
    "            y = y.mean(0)\n",
    "\n",
    "    data = pd.DataFrame({'theta': theta.squeeze().numpy(), 'y': y})\n",
    "    fig = px.line(data, x='theta', y='y')\n",
    "    fig.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mdgp_requirements_test1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
