{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load in data\n",
    "Currently supported datasets: power, protein, kin8nm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import gpytorch \n",
    "import geometric_kernels.torch \n",
    "\n",
    "torch.set_default_dtype(torch.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create data on S^D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geometric_kernels.spaces import Hypersphere\n",
    "\n",
    "\n",
    "def get_space_and_data(dim):\n",
    "    space = Hypersphere(dim)\n",
    "    x = torch.tensor(space.random_uniform(100))\n",
    "    y = torch.sin(x[:, 0])\n",
    "    return space, x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make sure that these god-forsaken functions are correctly implemented by reproducing the geometric_kernels kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import Tensor \n",
    "\n",
    "import torch \n",
    "from math import comb \n",
    "from spherical_harmonics import SphericalHarmonics\n",
    "\n",
    "\n",
    "def num_harmonics_single(ell: int, d: int) -> int:\n",
    "    r\"\"\"\n",
    "    Number of spherical harmonics of degree ell on S^{d - 1}.\n",
    "    \"\"\"\n",
    "    if ell == 0:\n",
    "        return 1\n",
    "    if d == 3:\n",
    "        return 2 * ell + 1\n",
    "    else:\n",
    "        return (2 * ell + d - 2) * comb(ell + d - 3, ell - 1) // ell\n",
    "\n",
    "\n",
    "def num_harmonics(ell: Tensor | int, d: int) -> Tensor:\n",
    "    \"\"\"\n",
    "    Vectorized version of num_harmonics_single\n",
    "    \"\"\"\n",
    "    if isinstance(ell, int):\n",
    "        return num_harmonics_single(ell, d)\n",
    "    return ell.apply_(lambda e: num_harmonics_single(ell=e, d=d))\n",
    "\n",
    "\n",
    "def total_num_harmonics(max_ell: int, d: int) -> int:\n",
    "    \"\"\"\n",
    "    Total number of spherical harmonics on S^{d-1} with degree <= max_ell\n",
    "    \"\"\"\n",
    "    return int(sum(num_harmonics(ell=torch.arange(max_ell + 1), d=d)))\n",
    "\n",
    "\n",
    "def eigenvalue_laplacian(ell: Tensor, d: int) -> Tensor:\n",
    "    \"\"\"\n",
    "    Eigenvalue of the Laplace-Beltrami operator for a spherical harmonic of degree ell on S_{d-1}\n",
    "    ell: [...]\n",
    "    d: []\n",
    "    return: [...]\n",
    "    \"\"\"\n",
    "    return ell * (ell + d - 2)\n",
    "\n",
    "\n",
    "def unnormalized_matern_spectral_density(n: Tensor, d: int, kappa: Tensor | float, nu: Tensor | float) -> Tensor | float: \n",
    "    \"\"\"\n",
    "    compute (unnormalized) spectral density of the matern kernel on S_{d-1}\n",
    "    n: [N]\n",
    "    d: []\n",
    "    kappa: [O, 1, 1]\n",
    "    nu: [O, 1, 1]\n",
    "    return: [O, 1, N]\n",
    "    \"\"\"\n",
    "    # Squared exponential kernel \n",
    "    if torch.all(nu.isinf()):\n",
    "        exponent = -kappa ** 2 / 2 * eigenvalue_laplacian(ell=n, d=d) # [O, N, 1]\n",
    "        return torch.exp(exponent)\n",
    "    # Matern kernel\n",
    "    else:\n",
    "        base = (\n",
    "            2.0 * nu / kappa**2 + # [O, 1, 1]\n",
    "            eigenvalue_laplacian(ell=n, d=d).unsqueeze(-1) # [N, 1]\n",
    "        ) # [O, N, 1]\n",
    "        exponent = -nu - (d - 1) / 2.0 # [O, 1, 1]\n",
    "        return base ** exponent # [O, N, 1]\n",
    "\n",
    "\n",
    "def matern_spectral_density_normalizer(d: int, max_ell: int, kappa: Tensor | float, nu: Tensor | float) -> Tensor:\n",
    "    \"\"\"\n",
    "    Normalizing constant for the spectral density of the Matern kernel on S^{d-1}. \n",
    "    Depends on kappa and nu. Also depends on max_ell, as truncation of the infinite \n",
    "    sum from Karhunen-Loeve decomposition. \n",
    "    \"\"\"\n",
    "    n = torch.arange(max_ell + 1)\n",
    "    spectral_values = unnormalized_matern_spectral_density(n=n, d=d, kappa=kappa, nu=nu) # [O, max_ell + 1, 1]\n",
    "    num_harmonics_per_level = num_harmonics(torch.arange(max_ell + 1), d=d).type(spectral_values.dtype) # [max_ell + 1]\n",
    "    normalizer = spectral_values.mT @ num_harmonics_per_level # [O, 1, max_ell + 1] @ [max_ell + 1] -> [O, 1]\n",
    "    return normalizer.unsqueeze(-2) # [O, 1, 1]\n",
    "\n",
    "\n",
    "def matern_spectral_density(n: Tensor, d: int, kappa: Tensor, nu: Tensor, max_ell: int, sigma: float = 1.0) -> Tensor:\n",
    "    \"\"\"\n",
    "    Spectral density of the Matern kernel on S^{d-1}\n",
    "    \"\"\"\n",
    "    return (\n",
    "        unnormalized_matern_spectral_density(n=n, d=d, kappa=kappa, nu=nu) / # [O, N, 1]\n",
    "        matern_spectral_density_normalizer(d=d, max_ell=max_ell, kappa=kappa, nu=nu) * # [O, 1, 1]\n",
    "        (sigma ** 2)[..., *(None,) * (kappa.ndim - 1)] # [O, 1, 1] NOTE the reason for this seemingly overcomplicated broadcasting is that sigma can be a scalar if O is empty\n",
    "    ) # [O, N, 1] / [O, 1, 1] * [O, 1, 1] -> [O, N, 1]\n",
    "\n",
    "\n",
    "def matern_ahat(ell: Tensor, d: int, max_ell: int, kappa: Tensor | float, nu: Tensor | float, \n",
    "                m: int | None = None, sigma: Tensor | float = 1.0) -> float:\n",
    "    \"\"\"\n",
    "    :math: `\\hat{a} = \\rho(\\ell)` where :math: `\\rho` is the spectral density on S^{d-1}\n",
    "    \"\"\"\n",
    "    return matern_spectral_density(n=ell, d=d, kappa=kappa, nu=nu, max_ell=max_ell, sigma=sigma) # [O, N, 1]\n",
    "\n",
    "\n",
    "def matern_repeated_ahat(max_ell: int, d: int, kappa: Tensor | float, nu: Tensor | float, sigma: Tensor | float = 1.0) -> Tensor:\n",
    "    \"\"\"\n",
    "    Returns a tensor of repeated ahat values for each ell. \n",
    "    \"\"\"\n",
    "    ells = torch.arange(max_ell + 1) # [max_ell + 1]\n",
    "    ahat = matern_ahat(ell=ells, d=d, max_ell=max_ell, kappa=kappa, nu=nu, sigma=sigma) # [O, max_ell + 1, 1]\n",
    "    repeats = num_harmonics(ell=ells, d=d) # [max_ell + 1]\n",
    "    return torch.repeat_interleave(ahat, repeats=repeats, dim=-2) # [O, num_harmonics, 1]\n",
    "\n",
    "\n",
    "def matern_Kuu(max_ell: int, d: int, kappa: float, nu: float, sigma: float = 1.0) -> Tensor : \n",
    "    \"\"\"\n",
    "    Returns the covariance matrix, which is a diagonal matrix with entries \n",
    "    equal to inv_ahat of the corresponding ell. \n",
    "    \"\"\"\n",
    "    return torch.diag(1 / matern_repeated_ahat(max_ell, d, kappa, nu, sigma=sigma).squeeze(-1)) # [O, num_harmonics, num_harmonics]\n",
    "\n",
    "\n",
    "def spherical_harmonics(x: Tensor, max_ell: int, d: int) -> Tensor: \n",
    "    # Make sure that x is at least 2d and flatten it\n",
    "    x = torch.atleast_2d(x)\n",
    "    batch_shape, n = x.shape[:-2], x.shape[-2]\n",
    "    x = x.flatten(0, -2)\n",
    "\n",
    "    # Get spherical harmonics callable\n",
    "    f = SphericalHarmonics(dimension=d, degrees=max_ell + 1) # [... * O, N, num_harmonics]\n",
    "\n",
    "    # Evaluate x and reintroduce batch dimensions\n",
    "    return f(x).reshape(*batch_shape, n, total_num_harmonics(max_ell, d)) # [..., O, N, num_harmonics]\n",
    "\n",
    "\n",
    "def matern_Kux(x: Tensor, max_ell: int, d: int) -> Tensor: \n",
    "    return spherical_harmonics(x, max_ell=max_ell, d=d).mT # [..., O, num_harmonics, N]\n",
    "\n",
    "\n",
    "def num_spherical_harmonics_to_degree(num_spherical_harmonics: int, dimension: int) -> tuple[int, int]:\n",
    "    \"\"\"\n",
    "    Returns the minimum degree for which there are at least\n",
    "    `num_eigenfunctions` in the collection.\n",
    "    \"\"\"\n",
    "    n, degree = 0, 0  # n: number of harmonics, d: degree (or level)\n",
    "    while n < num_spherical_harmonics:\n",
    "        n += num_harmonics(d=dimension, ell=degree)\n",
    "        degree += 1\n",
    "\n",
    "    if n > num_spherical_harmonics:\n",
    "        print(\n",
    "            \"The number of spherical harmonics requested does not lead to complete \"\n",
    "            \"levels of spherical harmonics. We have thus increased the number to \"\n",
    "            f\"{n}, which includes all spherical harmonics up to degree {degree} (incl.)\"\n",
    "        )\n",
    "    return degree - 1, n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geometric_kernels.kernels import MaternKarhunenLoeveKernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matern_kernel(x: Tensor, y:Tensor, max_ell: int, d: int, kappa: float, nu: float, sigma: float = 1.0) -> Tensor:\n",
    "    \"\"\"\n",
    "    Returns the kernel matrix for the Matern kernel on S^{d-1}\n",
    "    x: [..., O, N, D]\n",
    "    max_ell: []\n",
    "    d: []\n",
    "    kappa: [O, 1, 1]\n",
    "    nu: [O, 1, 1]\n",
    "    sigma: [O, 1, 1]\n",
    "    \"\"\"\n",
    "    Kux = matern_Kux(x, max_ell=max_ell, d=d) # [..., O, num_harmonics, N]\n",
    "    Kuy = matern_Kux(y, max_ell=max_ell, d=d) # [..., O, num_harmonics, M]\n",
    "    ahat = matern_repeated_ahat(max_ell=max_ell, d=d, kappa=kappa, nu=nu, sigma=sigma) # [O, num_harmonics, 1]\n",
    "    return (ahat * Kux).mT @ Kuy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3757, 0.3757, 1.0000],\n",
      "        [0.3757, 1.0000, 0.3757]]) tensor([[0.3757, 0.3757, 1.0000],\n",
      "        [0.3757, 1.0000, 0.3757]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([[0.0, 0.0, 1.0], [0.0, 1.0, 0.0]])\n",
    "y = torch.tensor([[1.0, 0.0, 0.0], [0.0, 1.0, 0.0], [0.0, 0.0, 1.0]])\n",
    "nu = torch.tensor([[2.5]])\n",
    "kappa = torch.tensor([[1.0]])\n",
    "max_ell = 2\n",
    "d = 3\n",
    "sigma = torch.tensor(1.0)\n",
    "K_mine = matern_kernel(x, y, max_ell, d, kappa, nu, sigma)\n",
    "\n",
    "params = {\n",
    "    'lengthscale': kappa, \n",
    "    'nu': nu,\n",
    "}\n",
    "K_theirs = MaternKarhunenLoeveKernel(Hypersphere(d - 1), num_levels=max_ell + 1, normalize=True).K(\n",
    "    params=params, X=x, X2=y\n",
    ")\n",
    "\n",
    "print(K_mine, K_theirs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Since the two implementation coincide, we can trust in the implementation of Kux and repeated_ahat. Since Kuu is correct iff repeated_ahat is correct, we can also trust Kuu. In principle the correctness of the implementation of the variational posterior depends only on Kux and Kuu, so it seems that we can trust the implemenation of the variational posterior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensure that all implementations of conditioning on variational posterior give the same results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matern_Phi(x, max_ell, d, kappa, nu, sigma):\n",
    "    Kux = matern_Kux(x, max_ell, d)\n",
    "    ahat_sqrt = matern_repeated_ahat(max_ell, d, kappa, nu, sigma)\n",
    "    return Kux * ahat_sqrt\n",
    "\n",
    "\n",
    "def matern_LT_Phi(x: Tensor, max_ell: int, d: int, kappa: float, nu: float, sigma: float = 1.0) -> Tensor: \n",
    "    Kux = matern_Kux(x, max_ell=max_ell, d=d) # [..., O, num_harmonics, N]\n",
    "    ahat_sqrt = matern_repeated_ahat(max_ell=max_ell, d=d, kappa=kappa, nu=nu, sigma=sigma).sqrt() # [O, num_harmonics, 1]\n",
    "    return Kux * ahat_sqrt # [..., O, num_harmonics, N]\n",
    "\n",
    "\n",
    "def variational_posterior_covar_full(x, K, S, max_ell, kappa, nu, sigma):\n",
    "    Kxx = K(x)\n",
    "    Kuu = matern_Kuu(max_ell, d, kappa, nu, sigma)\n",
    "    Kuu_inv = Kuu.inverse()\n",
    "    Kux = matern_Kux(x, max_ell, d)\n",
    "    Kxu = Kux.mT\n",
    "    return Kxx + Kxu @ Kuu_inv @ (S - Kuu) @ Kuu_inv @ Kux\n",
    "\n",
    "\n",
    "def variational_posterior_covar_paper(x, K, S, max_ell, kappa, nu, sigma):\n",
    "    Kxx = K(x)\n",
    "    Kuu = matern_Kuu(max_ell, d, kappa, nu, sigma)\n",
    "    Phiux = matern_Phi(x, max_ell, d, kappa, nu, sigma)\n",
    "    Phixu = Phiux.mT\n",
    "    return Kxx + Phixu @ (S - Kuu) @ Phiux\n",
    "\n",
    "\n",
    "def variational_posterior_covar_whitened(x, K, Linv_S_LTinv, max_ell, kappa, nu, sigma):\n",
    "    Kxx = K(x)\n",
    "    Linv_Kuu_LTinv = torch.eye(total_num_harmonics(max_ell, d))\n",
    "    LT_Phiux = matern_LT_Phi(x, max_ell, d, kappa, nu, sigma)\n",
    "    Phixu_L = LT_Phiux.mT\n",
    "    return Kxx + Phixu_L @ (Linv_S_LTinv - Linv_Kuu_LTinv) @ LT_Phiux\n",
    "\n",
    "\n",
    "# assumes zero mean prior \n",
    "def variational_posterior_mean_full(x, m, max_ell, kappa, nu, sigma):\n",
    "    Kuu_inv = matern_Kuu(max_ell, d, kappa, nu, sigma).inverse()\n",
    "    Kxu = matern_Kux(x, max_ell, d).mT\n",
    "    return Kxu @ Kuu_inv @ m\n",
    "\n",
    "\n",
    "def variational_posterior_mean_paper(x, m, max_ell, kappa, nu, sigma):\n",
    "    Phixu = matern_Phi(x, max_ell, d, kappa, nu, sigma).mT\n",
    "    return Phixu @ m\n",
    "\n",
    "\n",
    "def variational_posterior_mean_whitened(x, Linv_m, max_ell, kappa, nu, sigma):\n",
    "    Phixu_L = matern_LT_Phi(x, max_ell, d, kappa, nu, sigma).mT\n",
    "    return Phixu_L @ Linv_m\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variational distribution\n",
    "z = total_num_harmonics(max_ell, d)\n",
    "C = torch.tril(torch.randn(z, z))\n",
    "S = C @ C.mT\n",
    "\n",
    "# Whitened variational distribution\n",
    "L = matern_Kuu(max_ell, d, kappa, nu, sigma).sqrt()\n",
    "Linv_S_LTinv = L.inverse() @ S @ L.inverse().mT\n",
    "\n",
    "# Prior covariance\n",
    "K = lambda x: matern_kernel(x, x, max_ell, d, kappa, nu, sigma)\n",
    "q_covar_full = variational_posterior_covar_full(x, K, S, max_ell, kappa, nu, sigma)\n",
    "q_covar_paper = variational_posterior_covar_paper(x, K, S, max_ell, kappa, nu, sigma)\n",
    "q_covar_whitened = variational_posterior_covar_whitened(x, K, Linv_S_LTinv, max_ell, kappa, nu, sigma)\n",
    "\n",
    "assert torch.allclose(q_covar_full, q_covar_paper) and torch.allclose(q_covar_full, q_covar_whitened), \"All variational posterior covariances should be equivalent.\"\n",
    "\n",
    "\n",
    "# Prior mean\n",
    "m = torch.randn(z)\n",
    "Linv_m = L.inverse() @ m\n",
    "q_mean_full = variational_posterior_mean_full(x, m, max_ell, kappa, nu, sigma)\n",
    "q_mean_paper = variational_posterior_mean_paper(x, m, max_ell, kappa, nu, sigma)\n",
    "q_mean_whitened = variational_posterior_mean_whitened(x, Linv_m, max_ell, kappa, nu, sigma)\n",
    "\n",
    "assert torch.allclose(q_mean_full, q_mean_paper) and torch.allclose(q_mean_full, q_mean_whitened), \"All variational posterior means should be equivalent.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maybe manually implement the ELBO?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math \n",
    "\n",
    "\n",
    "def log_gaussian_likelihood(y, f, sigma):\n",
    "    n = len(y)\n",
    "    log_p_y_given_f = -0.5 * (y - f).T @ (y -f) / sigma**2\n",
    "    log_p_y_given_f += -0.5 * n * math.log(2 * math.pi) - n * torch.log(sigma)\n",
    "    return log_p_y_given_f\n",
    "\n",
    "\n",
    "def kl_divergence_between_gaussians(mu1, sigma1, mu2, sigma2):\n",
    "    d = mu1.shape[-1]\n",
    "    sigma2_inv = sigma2.inverse()\n",
    "    mu_diff = mu2 - mu1\n",
    "    return 0.5 * (torch.logdet(sigma2) - torch.logdet(sigma1) - d + (mu_diff.T @ sigma2_inv @ mu_diff).item() + torch.trace(sigma2_inv @ sigma1))\n",
    "\n",
    "\n",
    "def elbo(y, p_mu, p_sigma, q_mu, q_sigma, epsilon_sigma):\n",
    "    return log_gaussian_likelihood(y, q_mu, epsilon_sigma) - kl_divergence_between_gaussians(q_mu, q_sigma, p_mu, p_sigma)\n",
    "\n",
    "\n",
    "def torch_log_gaussian_likelihood(y, f, sigma):\n",
    "    return torch.distributions.MultivariateNormal(f, torch.eye(len(y)) * sigma ** 2).log_prob(y)\n",
    "\n",
    "\n",
    "def torch_kl_divergence_between_gaussians(mu1, sigma1, mu2, sigma2):\n",
    "    p = torch.distributions.MultivariateNormal(mu1, sigma1)\n",
    "    q = torch.distributions.MultivariateNormal(mu2, sigma2)\n",
    "    return torch.distributions.kl.kl_divergence(p, q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.randn(len(x))\n",
    "p_mu = torch.zeros_like(y)\n",
    "p_sigma = K(x)\n",
    "q_mu = torch.randn_like(y)\n",
    "q_sigma = q_covar_full\n",
    "epsilon_sigma = torch.tensor(1e-4)\n",
    "\n",
    "# Test KL divergence \n",
    "kl_mine = kl_divergence_between_gaussians(q_mu, q_sigma, p_mu, p_sigma)\n",
    "kl_theirs = torch_kl_divergence_between_gaussians(q_mu, q_sigma, p_mu, p_sigma)\n",
    "assert torch.allclose(kl_mine, kl_theirs), \"KL divergences should be equal.\"\n",
    "\n",
    "# Test log likelihood \n",
    "log_likelihood_mine = log_gaussian_likelihood(y, q_mu, epsilon_sigma)\n",
    "log_likelihood_theirs = torch_log_gaussian_likelihood(y, q_mu, epsilon_sigma)\n",
    "assert torch.allclose(log_likelihood_mine, log_likelihood_theirs), \"Log likelihoods should be equal.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Seeing that both log likelihood and KL divergence is correct, we can use our ELBO to optimise the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_jitter(x, jitter):\n",
    "    return x + torch.eye(x.shape[-1]) * jitter\n",
    "\n",
    "\n",
    "class SGP(torch.nn.Module):\n",
    "    def __init__(self, max_ell, d, epsilon_sigma=0.01, jitter=1e-6): \n",
    "        super().__init__()\n",
    "        self.jitter = jitter\n",
    "        self.max_ell = max_ell\n",
    "\n",
    "        # Variational parameters\n",
    "        m = total_num_harmonics(self.max_ell, d)\n",
    "        self.Linv_S_LTinv = torch.nn.Parameter(torch.eye(m))\n",
    "        self.Linv_m = torch.nn.Parameter(torch.randn(m))\n",
    "        \n",
    "        # fix prior hyperparams \n",
    "        self.kappa = torch.tensor(1.0)\n",
    "        self.nu = torch.tensor(2.5)\n",
    "        self.sigma = torch.tensor(1.0)\n",
    "        self.epsilon_sigma = torch.tensor(epsilon_sigma)\n",
    "\n",
    "    def K(self, x):\n",
    "        return matern_kernel(x, x, self.max_ell, d, self.kappa, self.nu, self.sigma)\n",
    "    \n",
    "    def q(self, x):\n",
    "        sigma = variational_posterior_covar_whitened(x, self.K, self.Linv_S_LTinv, self.max_ell, self.kappa, self.nu, self.sigma)\n",
    "        sigma = add_jitter(sigma, self.jitter)\n",
    "        mu = variational_posterior_mean_whitened(x, self.Linv_m, self.max_ell, self.kappa, self.nu, self.sigma)\n",
    "        return mu, sigma\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.q(x)\n",
    "    \n",
    "    def p(self, x):\n",
    "        sigma = self.K(x)\n",
    "        sigma = add_jitter(sigma, self.jitter)\n",
    "\n",
    "        mu = torch.zeros(x.shape[:-1])\n",
    "        return mu, sigma\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mdgp.utils.sphere import sphere_uniform_grid, spherical_harmonic\n",
    "\n",
    "\n",
    "model = SGP(max_ell, d)\n",
    "train_x = sphere_uniform_grid(100)\n",
    "train_f = spherical_harmonic(train_x, 2, 3)\n",
    "train_f = (train_f - train_f.mean()) / train_f.std()\n",
    "train_y = train_f + torch.randn_like(train_f) * 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-827190.9862, grad_fn=<AddBackward0>),\n",
       " tensor(4.6184, grad_fn=<MulBackward0>),\n",
       " tensor(-827190.9862, grad_fn=<SubBackward0>),\n",
       " tensor(4.6184, grad_fn=<AddBackward0>))"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_mu, q_sigma = model.q(train_x)\n",
    "p_mu, p_sigma = model.p(train_x)\n",
    "epsilon_sigma = model.epsilon_sigma\n",
    "q_mu, q_sigma, p_mu, p_sigma, epsilon_sigma\n",
    "\n",
    "log_gaussian_likelihood(train_y, q_mu, epsilon_sigma), kl_divergence_between_gaussians(q_mu, q_sigma, p_mu, p_sigma), torch_log_gaussian_likelihood(train_y, q_mu, epsilon_sigma), torch_kl_divergence_between_gaussians(q_mu, q_sigma, p_mu, p_sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4966.510410591241\n",
      "4964.254661275754\n",
      "4961.380098217402\n",
      "4959.121456981891\n",
      "4957.124198089693\n",
      "4955.096837987876\n",
      "4953.174545093312\n",
      "4951.5003428840455\n",
      "4950.0931000608925\n",
      "4948.858512496029\n",
      "4947.713687540028\n",
      "4946.6632234499975\n",
      "4945.754541522602\n",
      "4945.015534488616\n",
      "4944.426029200804\n",
      "4943.935985819044\n",
      "4943.511117907346\n",
      "4943.153338227842\n",
      "4942.8820519031615\n",
      "4942.705250999055\n",
      "4942.606083392888\n",
      "4942.554097142201\n",
      "4942.5282201183445\n",
      "4942.5265635163705\n",
      "4942.5561268540305\n",
      "4942.616595281867\n",
      "4942.694056455088\n",
      "4942.769425669033\n",
      "4942.831731094461\n",
      "4942.882073202071\n",
      "4942.925962114064\n",
      "4942.963731063731\n",
      "4942.9887573770575\n",
      "4942.994264931321\n",
      "4942.980381139038\n",
      "4942.953728389382\n",
      "4942.92098312645\n",
      "4942.883898372489\n",
      "4942.840650395798\n",
      "4942.791016636282\n",
      "4942.738938248274\n",
      "4942.6898501569385\n",
      "4942.646436257241\n",
      "4942.607716502531\n",
      "4942.572019156372\n",
      "4942.539881540654\n",
      "4942.513543336129\n",
      "4942.49418259317\n",
      "4942.4805346911835\n",
      "4942.470406310856\n",
      "4942.462919067646\n",
      "4942.45870465946\n",
      "4942.458158953975\n",
      "4942.460225242537\n",
      "4942.4631732076205\n",
      "4942.466135912297\n",
      "4942.46936855213\n",
      "4942.473105099452\n",
      "4942.476704510607\n",
      "4942.479164700775\n",
      "4942.480144063847\n",
      "4942.480075483236\n",
      "4942.479356287456\n",
      "4942.477827156659\n",
      "4942.475184338147\n",
      "4942.471606219573\n",
      "4942.467680788143\n",
      "4942.463812877624\n",
      "4942.459984287651\n",
      "4942.4561229681585\n",
      "4942.452450146488\n",
      "4942.449305463187\n",
      "4942.446773785789\n",
      "4942.444678117938\n",
      "4942.4428962520415\n",
      "4942.441500811965\n",
      "4942.44055861103\n",
      "4942.439949502299\n",
      "4942.4394788037425\n",
      "4942.439078389538\n",
      "4942.438790086816\n",
      "4942.438596973892\n",
      "4942.438383847331\n",
      "4942.438066204031\n",
      "4942.437664343806\n",
      "4942.437218844732\n",
      "4942.436703024589\n",
      "4942.436066531797\n",
      "4942.435319297493\n",
      "4942.4345174149985\n",
      "4942.433687985113\n",
      "4942.432818646135\n",
      "4942.431914395238\n",
      "4942.431017674195\n",
      "4942.430163579151\n",
      "4942.429350310138\n",
      "4942.428567683957\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[149], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1000\u001b[39m):\n\u001b[1;32m      4\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m----> 5\u001b[0m     q_mu, q_sigma \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mq\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_x\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m     p_mu, p_sigma \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mp(train_x)\n\u001b[1;32m      7\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39melbo(train_y, p_mu, p_sigma, q_mu, q_sigma, model\u001b[38;5;241m.\u001b[39mepsilon_sigma) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_y)\n",
      "Cell \u001b[0;32mIn[144], line 28\u001b[0m, in \u001b[0;36mSGP.q\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     26\u001b[0m sigma \u001b[38;5;241m=\u001b[39m variational_posterior_covar_whitened(x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mK, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mLinv_S_LTinv, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_ell, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkappa, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnu, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msigma)\n\u001b[1;32m     27\u001b[0m sigma \u001b[38;5;241m=\u001b[39m add_jitter(sigma, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjitter)\n\u001b[0;32m---> 28\u001b[0m mu \u001b[38;5;241m=\u001b[39m \u001b[43mvariational_posterior_mean_whitened\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLinv_m\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_ell\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkappa\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msigma\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m mu, sigma\n",
      "Cell \u001b[0;32mIn[135], line 51\u001b[0m, in \u001b[0;36mvariational_posterior_mean_whitened\u001b[0;34m(x, Linv_m, max_ell, kappa, nu, sigma)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvariational_posterior_mean_whitened\u001b[39m(x, Linv_m, max_ell, kappa, nu, sigma):\n\u001b[0;32m---> 51\u001b[0m     Phixu_L \u001b[38;5;241m=\u001b[39m \u001b[43mmatern_LT_Phi\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_ell\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkappa\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msigma\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mmT\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Phixu_L \u001b[38;5;241m@\u001b[39m Linv_m\n",
      "Cell \u001b[0;32mIn[135], line 8\u001b[0m, in \u001b[0;36mmatern_LT_Phi\u001b[0;34m(x, max_ell, d, kappa, nu, sigma)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmatern_LT_Phi\u001b[39m(x: Tensor, max_ell: \u001b[38;5;28mint\u001b[39m, d: \u001b[38;5;28mint\u001b[39m, kappa: \u001b[38;5;28mfloat\u001b[39m, nu: \u001b[38;5;28mfloat\u001b[39m, sigma: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor: \n\u001b[0;32m----> 8\u001b[0m     Kux \u001b[38;5;241m=\u001b[39m \u001b[43mmatern_Kux\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_ell\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_ell\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43md\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# [..., O, num_harmonics, N]\u001b[39;00m\n\u001b[1;32m      9\u001b[0m     ahat_sqrt \u001b[38;5;241m=\u001b[39m matern_repeated_ahat(max_ell\u001b[38;5;241m=\u001b[39mmax_ell, d\u001b[38;5;241m=\u001b[39md, kappa\u001b[38;5;241m=\u001b[39mkappa, nu\u001b[38;5;241m=\u001b[39mnu, sigma\u001b[38;5;241m=\u001b[39msigma)\u001b[38;5;241m.\u001b[39msqrt() \u001b[38;5;66;03m# [O, num_harmonics, 1]\u001b[39;00m\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Kux \u001b[38;5;241m*\u001b[39m ahat_sqrt\n",
      "Cell \u001b[0;32mIn[6], line 133\u001b[0m, in \u001b[0;36mmatern_Kux\u001b[0;34m(x, max_ell, d)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmatern_Kux\u001b[39m(x: Tensor, max_ell: \u001b[38;5;28mint\u001b[39m, d: \u001b[38;5;28mint\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor: \n\u001b[0;32m--> 133\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mspherical_harmonics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_ell\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_ell\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43md\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mmT\n",
      "Cell \u001b[0;32mIn[6], line 129\u001b[0m, in \u001b[0;36mspherical_harmonics\u001b[0;34m(x, max_ell, d)\u001b[0m\n\u001b[1;32m    126\u001b[0m f \u001b[38;5;241m=\u001b[39m SphericalHarmonics(dimension\u001b[38;5;241m=\u001b[39md, degrees\u001b[38;5;241m=\u001b[39mmax_ell \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;66;03m# [... * O, N, num_harmonics]\u001b[39;00m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;66;03m# Evaluate x and reintroduce batch dimensions\u001b[39;00m\n\u001b[0;32m--> 129\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m f(x)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m*\u001b[39mbatch_shape, n, \u001b[43mtotal_num_harmonics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_ell\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m)\u001b[49m)\n",
      "Cell \u001b[0;32mIn[6], line 33\u001b[0m, in \u001b[0;36mtotal_num_harmonics\u001b[0;34m(max_ell, d)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtotal_num_harmonics\u001b[39m(max_ell: \u001b[38;5;28mint\u001b[39m, d: \u001b[38;5;28mint\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mint\u001b[39m:\n\u001b[1;32m     30\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;124;03m    Total number of spherical harmonics on S^{d-1} with degree <= max_ell\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 33\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28msum\u001b[39m(num_harmonics(ell\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39marange(max_ell \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m), d\u001b[38;5;241m=\u001b[39md)))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "for step in range(1000):\n",
    "    optimizer.zero_grad()\n",
    "    q_mu, q_sigma = model.q(train_x)\n",
    "    p_mu, p_sigma = model.p(train_x)\n",
    "    loss = -elbo(train_y, p_mu, p_sigma, q_mu, q_sigma, model.epsilon_sigma) / len(train_y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(loss.item())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mdgp.utils.sphere import sphere_meshgrid\n",
    "\n",
    "\n",
    "test_x = sphere_meshgrid(50, 50)\n",
    "with torch.no_grad():\n",
    "    x, y, z = test_x.unbind(-1)\n",
    "    surfacecolor = model(test_x.view(-1, d))[0].view(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "\n    Invalid value of type 'builtins.int' received for the 'z' property of surface\n        Received value: 9\n\n    The 'z' property is an array that may be specified as a tuple,\n    list, numpy array, or pandas Series",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[152], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mplotly\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m graph_objects \u001b[38;5;28;01mas\u001b[39;00m go \n\u001b[1;32m      4\u001b[0m fig \u001b[38;5;241m=\u001b[39m go\u001b[38;5;241m.\u001b[39mFigure(\n\u001b[0;32m----> 5\u001b[0m     \u001b[43mgo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSurface\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mz\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mz\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msurfacecolor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msurfacecolor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolorscale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mViridis\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/mdgp_requirements_test1/lib/python3.11/site-packages/plotly/graph_objs/_surface.py:2807\u001b[0m, in \u001b[0;36mSurface.__init__\u001b[0;34m(self, arg, autocolorscale, cauto, cmax, cmid, cmin, coloraxis, colorbar, colorscale, connectgaps, contours, customdata, customdatasrc, hidesurface, hoverinfo, hoverinfosrc, hoverlabel, hovertemplate, hovertemplatesrc, hovertext, hovertextsrc, ids, idssrc, legend, legendgroup, legendgrouptitle, legendrank, legendwidth, lighting, lightposition, meta, metasrc, name, opacity, opacityscale, reversescale, scene, showlegend, showscale, stream, surfacecolor, surfacecolorsrc, text, textsrc, uid, uirevision, visible, x, xcalendar, xhoverformat, xsrc, y, ycalendar, yhoverformat, ysrc, z, zcalendar, zhoverformat, zsrc, **kwargs)\u001b[0m\n\u001b[1;32m   2805\u001b[0m _v \u001b[38;5;241m=\u001b[39m z \u001b[38;5;28;01mif\u001b[39;00m z \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m _v\n\u001b[1;32m   2806\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _v \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 2807\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mz\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m _v\n\u001b[1;32m   2808\u001b[0m _v \u001b[38;5;241m=\u001b[39m arg\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzcalendar\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m   2809\u001b[0m _v \u001b[38;5;241m=\u001b[39m zcalendar \u001b[38;5;28;01mif\u001b[39;00m zcalendar \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m _v\n",
      "File \u001b[0;32m~/miniconda3/envs/mdgp_requirements_test1/lib/python3.11/site-packages/plotly/basedatatypes.py:4874\u001b[0m, in \u001b[0;36mBasePlotlyType.__setitem__\u001b[0;34m(self, prop, value)\u001b[0m\n\u001b[1;32m   4870\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_array_prop(prop, value)\n\u001b[1;32m   4872\u001b[0m     \u001b[38;5;66;03m# ### Handle simple property ###\u001b[39;00m\n\u001b[1;32m   4873\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 4874\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_prop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4875\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   4876\u001b[0m     \u001b[38;5;66;03m# Make sure properties dict is initialized\u001b[39;00m\n\u001b[1;32m   4877\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_props()\n",
      "File \u001b[0;32m~/miniconda3/envs/mdgp_requirements_test1/lib/python3.11/site-packages/plotly/basedatatypes.py:5218\u001b[0m, in \u001b[0;36mBasePlotlyType._set_prop\u001b[0;34m(self, prop, val)\u001b[0m\n\u001b[1;32m   5216\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m   5217\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 5218\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[1;32m   5220\u001b[0m \u001b[38;5;66;03m# val is None\u001b[39;00m\n\u001b[1;32m   5221\u001b[0m \u001b[38;5;66;03m# -----------\u001b[39;00m\n\u001b[1;32m   5222\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m val \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   5223\u001b[0m     \u001b[38;5;66;03m# Check if we should send null update\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/mdgp_requirements_test1/lib/python3.11/site-packages/plotly/basedatatypes.py:5213\u001b[0m, in \u001b[0;36mBasePlotlyType._set_prop\u001b[0;34m(self, prop, val)\u001b[0m\n\u001b[1;32m   5210\u001b[0m validator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_validator(prop)\n\u001b[1;32m   5212\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 5213\u001b[0m     val \u001b[38;5;241m=\u001b[39m \u001b[43mvalidator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate_coerce\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m   5215\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_skip_invalid:\n",
      "File \u001b[0;32m~/miniconda3/envs/mdgp_requirements_test1/lib/python3.11/site-packages/_plotly_utils/basevalidators.py:412\u001b[0m, in \u001b[0;36mDataArrayValidator.validate_coerce\u001b[0;34m(self, v)\u001b[0m\n\u001b[1;32m    410\u001b[0m     v \u001b[38;5;241m=\u001b[39m to_scalar_or_list(v)\n\u001b[1;32m    411\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 412\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_invalid_val\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    413\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m v\n",
      "File \u001b[0;32m~/miniconda3/envs/mdgp_requirements_test1/lib/python3.11/site-packages/_plotly_utils/basevalidators.py:296\u001b[0m, in \u001b[0;36mBaseValidator.raise_invalid_val\u001b[0;34m(self, v, inds)\u001b[0m\n\u001b[1;32m    293\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m inds:\n\u001b[1;32m    294\u001b[0m                 name \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(i) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 296\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    297\u001b[0m \u001b[38;5;250m            \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    298\u001b[0m \u001b[38;5;124;03m    Invalid value of type {typ} received for the '{name}' property of {pname}\u001b[39;00m\n\u001b[1;32m    299\u001b[0m \u001b[38;5;124;03m        Received value: {v}\u001b[39;00m\n\u001b[1;32m    300\u001b[0m \n\u001b[1;32m    301\u001b[0m \u001b[38;5;124;03m{valid_clr_desc}\"\"\"\u001b[39;00m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    302\u001b[0m                 name\u001b[38;5;241m=\u001b[39mname,\n\u001b[1;32m    303\u001b[0m                 pname\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparent_name,\n\u001b[1;32m    304\u001b[0m                 typ\u001b[38;5;241m=\u001b[39mtype_str(v),\n\u001b[1;32m    305\u001b[0m                 v\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mrepr\u001b[39m(v),\n\u001b[1;32m    306\u001b[0m                 valid_clr_desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdescription(),\n\u001b[1;32m    307\u001b[0m             )\n\u001b[1;32m    308\u001b[0m         )\n",
      "\u001b[0;31mValueError\u001b[0m: \n    Invalid value of type 'builtins.int' received for the 'z' property of surface\n        Received value: 9\n\n    The 'z' property is an array that may be specified as a tuple,\n    list, numpy array, or pandas Series"
     ]
    }
   ],
   "source": [
    "from plotly import graph_objects as go \n",
    "\n",
    "\n",
    "fig = go.Figure(\n",
    "    go.Surface(\n",
    "        x=x, y=y, z=z, surfacecolor=surfacecolor, colorscale='Viridis'\n",
    "    )\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mdgp_requirements_test1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
