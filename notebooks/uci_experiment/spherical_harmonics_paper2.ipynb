{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook reproduces results from the spherical harmonics paper on UCI datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import Tensor \n",
    "\n",
    "\n",
    "import torch \n",
    "import gpytorch \n",
    "import geometric_kernels.torch \n",
    "from math import comb \n",
    "from spherical_harmonics import SphericalHarmonics\n",
    "from geometric_kernels.spaces import Hypersphere\n",
    "from gpytorch.variational import CholeskyVariationalDistribution\n",
    "from gpytorch.distributions import MultivariateNormal\n",
    "from linear_operator.operators import DiagLinearOperator, LinearOperator\n",
    "from mdgp.kernels import GeometricMaternKernel\n",
    "from tqdm.autonotebook import tqdm \n",
    "from gpytorch.metrics import negative_log_predictive_density, mean_squared_error\n",
    "\n",
    "\n",
    "torch.set_default_dtype(torch.float64)\n",
    "from mdgp.variational.spherical_harmonic_features.utils import * \n",
    "from mdgp.variational.spherical_harmonic_features_variational_strategy import SphericalHarmonicFeaturesVariationalStrategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class gpytorchSGP(gpytorch.models.ApproximateGP):\n",
    "    def __init__(self, max_ell, d, max_ell_prior, epsilon_sigma=1.0, kappa=1.0, nu=2.5, sigma=1.0, batch_shape=torch.Size([]), jitter_val=1e-6, optimize_nu: bool = True):\n",
    "        m = total_num_harmonics(max_ell, d)\n",
    "        variational_distribution = CholeskyVariationalDistribution(num_inducing_points=m, batch_shape=batch_shape)\n",
    "        variational_strategy = SphericalHarmonicFeaturesVariationalStrategy(self, variational_distribution, num_levels=max_ell, jitter_val=jitter_val)\n",
    "        super().__init__(variational_strategy=variational_strategy)\n",
    "\n",
    "        # constants \n",
    "        self.jitter_val = jitter_val\n",
    "        self.max_ell = max_ell\n",
    "        self.max_ell_prior = max_ell_prior\n",
    "        self.d = d\n",
    "\n",
    "        # modules \n",
    "        base_kernel = GeometricMaternKernel(\n",
    "            space=Hypersphere(d),\n",
    "            lengthscale=kappa, \n",
    "            nu=nu, \n",
    "            trainable_nu=optimize_nu, \n",
    "            num_eigenfunctions=max_ell_prior,\n",
    "        )\n",
    "        self.covar_module = gpytorch.kernels.ScaleKernel(base_kernel)\n",
    "        self.mean_module = gpytorch.means.ConstantMean()\n",
    "        self.likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "\n",
    "        # prior hyperparams \n",
    "        self.covar_module.outputscale = sigma ** 2\n",
    "        self.likelihood.noise = epsilon_sigma ** 2\n",
    "\n",
    "    def forward(self, x) -> MultivariateNormal:\n",
    "        p_sigma = self.covar_module(x)\n",
    "        p_mu = self.mean_module(x)\n",
    "        return MultivariateNormal(p_mu, p_sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from linear_operator.operators import DiagLinearOperator\n",
    "from gpytorch.distributions import MultivariateNormal\n",
    "\n",
    "\n",
    "class SphereProjector(torch.nn.Module):\n",
    "    def __init__(self, b: float = 2.0):\n",
    "        super().__init__()\n",
    "        self.b = torch.nn.Parameter(torch.tensor(b))\n",
    "        self.norm = None \n",
    "\n",
    "    def forward(self, x: Tensor, y: Tensor | None = None) -> tuple[Tensor, Tensor] | Tensor:\n",
    "        b = self.b.expand(*x.shape[:-1], 1)\n",
    "        x_cat_b = torch.cat([x, b], dim=-1)\n",
    "        self.norm = x_cat_b.norm(dim=-1, keepdim=True)\n",
    "        if y is None:\n",
    "            return x_cat_b / self.norm\n",
    "        else:\n",
    "            return x_cat_b / self.norm, y / self.norm.squeeze(-1)\n",
    "    \n",
    "    def inverse(self, mvn: MultivariateNormal) -> MultivariateNormal:\n",
    "        L = DiagLinearOperator(self.norm.squeeze(-1))\n",
    "        mean = mvn.mean @ L\n",
    "        cov = L @ mvn.lazy_covariance_matrix @ L\n",
    "        return MultivariateNormal(mean=mean, covariance_matrix=cov)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UCI data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd \n",
    "import torch \n",
    "from torch import Tensor\n",
    "from torch.utils.data import TensorDataset, DataLoader, Dataset\n",
    "\n",
    "\n",
    "class UCIDataset:\n",
    "\n",
    "    UCI_BASE_URL = 'https://archive.ics.uci.edu/ml/machine-learning-databases/'\n",
    "\n",
    "    def __init__(self, name: str, url: str, path: str = '../../data/uci/', normalize: bool = True, seed: int | None = None): \n",
    "        self.name = name \n",
    "        self.url = url\n",
    "        self.path = path \n",
    "        self.csv_path = os.path.join(self.path, self.name + '.csv')\n",
    "\n",
    "        # Set generator if seed is provided.\n",
    "        self.generator = torch.Generator()\n",
    "        if seed is not None: \n",
    "            self.generator.manual_seed(seed)\n",
    "\n",
    "        # Load, shuffle, split, and normalize data. TODO except for load, these don't need to be object methods. \n",
    "        # We keep the standard deviation of the test set for log-likelihood evaluation.\n",
    "        x, y = self.load_data()\n",
    "        x, y = self.shuffle(x, y, generator=self.generator)     \n",
    "        self.train_x, self.train_y, self.test_x, self.test_y = self.split(x, y)\n",
    "        self.test_y_std = self.test_y.std(dim=0, keepdim=True)\n",
    "        self.train_x, self.train_y, self.test_x, self.test_y = map(\n",
    "            self.normalize, (self.train_x, self.train_y, self.test_x, self.test_y))\n",
    "\n",
    "    @property\n",
    "    def dimension(self) -> int:\n",
    "        return self.train_x.shape[-1]\n",
    "\n",
    "    @property \n",
    "    def train_dataset(self) -> Dataset:\n",
    "        return TensorDataset(self.train_x, self.train_y)\n",
    "    \n",
    "    @property\n",
    "    def test_dataset(self) -> Dataset:\n",
    "        return TensorDataset(self.test_x, self.test_y)\n",
    "\n",
    "    def read_data(self) -> tuple[Tensor, Tensor]:\n",
    "        xy = torch.from_numpy(pd.read_csv(self.csv_path).values)\n",
    "        return xy[:, :-1], xy[:, -1]\n",
    "\n",
    "    def download_data(self) -> None:\n",
    "        NotImplementedError\n",
    "\n",
    "    def load_data(self, overwrite: bool = False) -> tuple[Tensor, Tensor]:\n",
    "        if overwrite or not os.path.isfile(self.csv_path):\n",
    "            self.download_data()\n",
    "        return self.read_data()\n",
    "\n",
    "    def normalize(self, x: Tensor) -> Tensor:\n",
    "        return (x - x.mean(dim=0)) / x.std(dim=0, keepdim=True)\n",
    "    \n",
    "    def shuffle(self, x: Tensor, y: Tensor, generator: torch.Generator) -> tuple[Tensor, Tensor]:\n",
    "        perm_idx = torch.randperm(x.size(0), generator=generator)\n",
    "        return x[perm_idx], y[perm_idx]\n",
    "    \n",
    "    def split(self, x: Tensor, y: Tensor, test_size: float = 0.1) -> tuple[Tensor, Tensor, Tensor, Tensor]: \n",
    "        \"\"\"\n",
    "        Split the dataset into train and test sets.\n",
    "        \"\"\"\n",
    "        split_idx = int(test_size * x.size(0))\n",
    "        return x[split_idx:], y[split_idx:], x[:split_idx], y[:split_idx]\n",
    "\n",
    "\n",
    "class Kin8mn(UCIDataset):\n",
    "\n",
    "    DEFAULT_URL = 'https://raw.githubusercontent.com/liusiyan/UQnet/master/datasets/UCI_datasets/kin8nm/dataset_2175_kin8nm.csv'\n",
    "\n",
    "    def __init__(self, path: str = '../../data/uci/', normalize: bool = True, seed: int | None = None, url: str | None = None):\n",
    "        url = url or Kin8mn.DEFAULT_URL\n",
    "        super().__init__(name='kin8nm', path=path, normalize=normalize, url=url, seed=seed)\n",
    "\n",
    "    def download_data(self) -> None:\n",
    "        df = pd.read_csv(self.url)\n",
    "        os.makedirs(self.path, exist_ok=True)\n",
    "        df.to_csv(self.csv_path, index=False)\n",
    "\n",
    "\n",
    "import csv \n",
    "from io import BytesIO\n",
    "from urllib.request import urlopen\n",
    "from zipfile import ZipFile\n",
    "\n",
    "\n",
    "uci_base = 'https://archive.ics.uci.edu/ml/machine-learning-databases/'\n",
    "\n",
    "\n",
    "class Power(UCIDataset):\n",
    "\n",
    "    DEFAULT_URL = uci_base + \"00294/CCPP.zip\"\n",
    "\n",
    "    def __init__(self, path: str = '../../data/uci/', normalize: bool = True, seed: int | None = None, url: str | None = None):\n",
    "        url = url or Power.DEFAULT_URL\n",
    "        super().__init__(name='power', path=path, normalize=normalize, url=url, seed=seed)\n",
    "\n",
    "    def download_data(self):\n",
    "        with urlopen(self.url) as zipresp:\n",
    "            with ZipFile(BytesIO(zipresp.read())) as zfile:\n",
    "                zfile.extractall('/tmp/')\n",
    "\n",
    "        df = pd.read_excel('/tmp/CCPP//Folds5x2_pp.xlsx')\n",
    "        os.makedirs(self.path, exist_ok=True)\n",
    "        df.to_csv(self.csv_path, index=False)\n",
    "\n",
    "\n",
    "class Concrete(UCIDataset):\n",
    "\n",
    "    DEFAULT_URL = uci_base + 'concrete/compressive/Concrete_Data.xls'\n",
    "\n",
    "    def __init__(self, path: str = '../../data/uci/', normalize: bool = True, seed: int | None = None, url: str | None = None):\n",
    "        url = url or Concrete.DEFAULT_URL\n",
    "        super().__init__(name='concrete', path=path, normalize=normalize, url=url, seed=seed)\n",
    "\n",
    "    def download_data(self):\n",
    "        df = pd.read_excel(self.url)\n",
    "        os.makedirs(self.path, exist_ok=True)\n",
    "        df.to_csv(self.csv_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixed parameters as in the spherical harmonics paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datasets \n",
    "kin8mn = Kin8mn()\n",
    "power = Power()\n",
    "concrete = Concrete()\n",
    "\n",
    "# Variational parameters\n",
    "dimension_to_num_harmonics_variational = {\n",
    "    4: 336,\n",
    "    6: 294,\n",
    "    8: 210,\n",
    "}\n",
    "\n",
    "# Prior parameters \n",
    "\"\"\"\n",
    "NOTE \n",
    "- It is difficult to say what number of spherical harmonics was used for the prior.\n",
    "  I set it to be the same as the number of inducing variables.\n",
    "- It is also difficult to say what lengthscale initialisation was used in the paper. \n",
    "  I set it to 1.0 for now, although a lower number, e.g. 0.001, would likely be better for higher dimensions.\n",
    "\"\"\"\n",
    "dimension_to_num_harmonics_prior = {\n",
    "    # 4: 336,\n",
    "    # 6: 294,\n",
    "    # 8: 210, \n",
    "    4: 336, \n",
    "    6: 1000,\n",
    "    8: 625,\n",
    "}\n",
    "nu = 1.5\n",
    "optimize_nu = False\n",
    "kappa = 1.0\n",
    "\n",
    "# Other model parameters\n",
    "batch_shape = torch.Size([])\n",
    "\n",
    "# Training parameters \n",
    "batch_size = 256 \n",
    "LR = 0.01\n",
    "NUM_EPOCHS = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of spherical harmonics requested does not lead to complete levels of spherical harmonics. We have thus increased the number to 660, which includes all spherical harmonics up to level 5 (exclusive)\n"
     ]
    }
   ],
   "source": [
    "from mdgp.variational.spherical_harmonic_features.utils import num_spherical_harmonics_to_num_levels\n",
    "\n",
    "\n",
    "def get_model_and_projector(dataset: UCIDataset):\n",
    "    sphere_dimension = dataset.dimension\n",
    "\n",
    "    # number of levels for variational inference \n",
    "    num_spherical_harmonics = dimension_to_num_harmonics_variational[dataset.dimension]\n",
    "    max_ell, _ = num_spherical_harmonics_to_num_levels(num_spherical_harmonics, sphere_dimension)\n",
    "\n",
    "    # number of levels for prior\n",
    "    num_spherical_harmonics_prior = dimension_to_num_harmonics_prior[dataset.dimension]\n",
    "    max_ell_prior, _ = num_spherical_harmonics_to_num_levels(num_spherical_harmonics_prior, sphere_dimension)\n",
    "\n",
    "    model = gpytorchSGP(max_ell=max_ell, d=sphere_dimension, max_ell_prior=max_ell_prior, kappa=kappa, nu=nu, optimize_nu=optimize_nu, batch_shape=batch_shape)\n",
    "    projector = SphereProjector()\n",
    "    return model, projector\n",
    "\n",
    "\n",
    "model, projector = get_model_and_projector(kin8mn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(x, y, model, projector, optimizer, mll) -> float:\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    x, y = projector(x, y)\n",
    "    output = model(x)\n",
    "    loss = mll(output, y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "\n",
    "def train(dataset, model, projector, batch_size, num_epochs=NUM_EPOCHS, lr=LR) -> list[float]: \n",
    "    # optimizer and criterion\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, maximize=True)\n",
    "    mll = gpytorch.mlls.VariationalELBO(model.likelihood, model, dataset.train_y.size(0))\n",
    "\n",
    "    # data\n",
    "    train_loader = DataLoader(dataset.train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    # Training loop\n",
    "    losses = []\n",
    "    pbar = tqdm(range(num_epochs))\n",
    "    for epoch in pbar:\n",
    "        epoch_loss = 0\n",
    "        for x_batch, y_batch in train_loader:\n",
    "            loss = train_step(x=x_batch, y=y_batch, model=model, projector=projector, optimizer=optimizer, mll=mll)\n",
    "            epoch_loss += loss\n",
    "        losses.append(epoch_loss)\n",
    "        pbar.set_postfix({'ELBO': losses[-1]})\n",
    "\n",
    "    return losses \n",
    "\n",
    "\n",
    "def evaluate(dataset, model, projector):\n",
    "    with torch.no_grad():\n",
    "        test_x, test_y = projector(dataset.test_x), dataset.test_y\n",
    "        out = model.likelihood(model(test_x))\n",
    "        out = projector.inverse(out)\n",
    "        nlpd = negative_log_predictive_density(out, test_y)\n",
    "        mse = mean_squared_error(out, test_y)\n",
    "        metrics = {\n",
    "            'nlpd': nlpd.item(), \n",
    "            'mse': mse.item(),\n",
    "        }\n",
    "        print(f\"NLPD: {metrics['nlpd']}, MSE: {metrics['mse']}\")\n",
    "    return metrics \n",
    "\n",
    "\n",
    "def reproduce_results(dataset, batch_size, num_runs: int = 5, num_epochs=NUM_EPOCHS, lr=LR):\n",
    "    print(f\"Reproducing results for {dataset.name}\".center(80, '-') + '\\n')\n",
    "\n",
    "    metrics = []\n",
    "    for run in range(num_runs):\n",
    "        print(f\"Run {run + 1}\".center(80, '-'))\n",
    "\n",
    "        torch.random.manual_seed(run)\n",
    "        model, projector = get_model_and_projector(dataset)\n",
    "        train(dataset, model, projector, num_epochs=num_epochs, lr=lr, batch_size=batch_size)\n",
    "        # print(\n",
    "        #     model.covar_module.base_kernel.lengthscale, \n",
    "        #     model.covar_module.base_kernel.nu,\n",
    "        #     model.covar_module.outputscale,\n",
    "        #     model.likelihood.noise,\n",
    "        #     model.variational_strategy._variational_distribution.variational_mean,\n",
    "        #     model.variational_strategy._variational_distribution.chol_variational_covar,\n",
    "        # )\n",
    "        run_metrics = evaluate(dataset, model, projector)\n",
    "        metrics.append(run_metrics)\n",
    "    df = pd.DataFrame(metrics)\n",
    "\n",
    "    print(\"Metrics mean\".center(80, '-'))\n",
    "    print(df.mean())\n",
    "\n",
    "    print(\"Metrics STD\".center(80, '-'))\n",
    "    print(df.std())\n",
    "\n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of spherical harmonics requested does not lead to complete levels of spherical harmonics. We have thus increased the number to 660, which includes all spherical harmonics up to level 5 (exclusive)\n",
      "torch.Size([210])\n",
      "tensor(1., grad_fn=<SoftplusBackward0>) tensor([[1.]], grad_fn=<SoftplusBackward0>) tensor([[1.5000]])\n",
      "tensor([1.0000], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "model, _ = get_model_and_projector(kin8mn)\n",
    "\n",
    "print(model.variational_strategy.variational_distribution.mean.shape)\n",
    "print(model.covar_module.outputscale, model.covar_module.base_kernel.lengthscale, model.covar_module.base_kernel.nu)\n",
    "print(model.likelihood.noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalizing X with mean [[7.63950796e-01 6.71782200e+02 3.18748191e+02 1.76517004e+02\n",
      "  5.25759768e+00 3.47756874e+00 2.32995658e-01 2.82344428e+00]] and std [[ 0.10901257 89.79381901 41.44677061 45.98855734  1.74867228  1.16290081\n",
      "   0.13683384  1.56965762]]\n",
      "Normalizing Y with mean [[22.33689725]] and std [[9.9405047]]\n"
     ]
    }
   ],
   "source": [
    "from datasets_dsvi import Energy as EnergyDSVI\n",
    "DTYPE = torch.get_default_dtype()\n",
    "\n",
    "data = EnergyDSVI().get_data()\n",
    "X, Y, Xs, Ys, Y_std = [data[_] for _ in ['X', 'Y', 'Xs', 'Ys', 'Y_std']]\n",
    "x, y = torch.from_numpy(X).to(DTYPE), torch.from_numpy(Y).to(DTYPE).squeeze(-1)\n",
    "test_x, test_y = torch.from_numpy(Xs).to(DTYPE), torch.from_numpy(Ys).to(DTYPE).squeeze(-1)\n",
    "test_y_std = torch.from_numpy(Y_std).to(DTYPE).squeeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of spherical harmonics requested does not lead to complete levels of spherical harmonics. We have thus increased the number to 660, which includes all spherical harmonics up to level 5 (exclusive)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9036c5bed03a4fc8bbc05172f31f2d1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epochs:   0%|          | 0/20000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m      9\u001b[0m x_batch, y_batch \u001b[38;5;241m=\u001b[39m projector(x, y)\n\u001b[0;32m---> 10\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# output = projector.inverse(output)\u001b[39;00m\n\u001b[1;32m     12\u001b[0m loss \u001b[38;5;241m=\u001b[39m elbo(output, y_batch)\n",
      "File \u001b[0;32m~/miniconda3/envs/mdgp_requirements_test1/lib/python3.11/site-packages/gpytorch/models/approximate_gp.py:108\u001b[0m, in \u001b[0;36mApproximateGP.__call__\u001b[0;34m(self, inputs, prior, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inputs\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    107\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 108\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvariational_strategy\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprior\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprior\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/mdgp_requirements_test1/lib/python3.11/site-packages/mdgp/variational/spherical_harmonic_features_variational_strategy.py:74\u001b[0m, in \u001b[0;36mSphericalHarmonicFeaturesVariationalStrategy.__call__\u001b[0;34m(self, x, prior, **kwargs)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m prior:\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mforward(x)\n\u001b[0;32m---> 74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/mdgp_requirements_test1/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/mdgp_requirements_test1/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/mdgp_requirements_test1/lib/python3.11/site-packages/mdgp/variational/spherical_harmonic_features_variational_strategy.py:55\u001b[0m, in \u001b[0;36mSphericalHarmonicFeaturesVariationalStrategy.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     52\u001b[0m Linv_m, Linv_S_LTinv \u001b[38;5;241m=\u001b[39m Linv_qu\u001b[38;5;241m.\u001b[39mmean, Linv_qu\u001b[38;5;241m.\u001b[39mlazy_covariance_matrix \u001b[38;5;66;03m# [..., M], [..., M, M]\u001b[39;00m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;66;03m# unwhitening + projection and vice-versa\u001b[39;00m\n\u001b[0;32m---> 55\u001b[0m LT_Phiux \u001b[38;5;241m=\u001b[39m \u001b[43mmatern_LT_Phi_from_kernel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcovar_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_levels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_levels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_levels_prior\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_ell_prior\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m Phixu_L \u001b[38;5;241m=\u001b[39m LT_Phiux\u001b[38;5;241m.\u001b[39mmT \u001b[38;5;66;03m# [..., N, M]\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;66;03m# posterior at x \u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/mdgp_requirements_test1/lib/python3.11/site-packages/mdgp/variational/spherical_harmonic_features/utils.py:176\u001b[0m, in \u001b[0;36mmatern_LT_Phi_from_kernel\u001b[0;34m(x, covar_module, num_levels, num_levels_prior)\u001b[0m\n\u001b[1;32m    173\u001b[0m max_ell \u001b[38;5;241m=\u001b[39m num_levels\n\u001b[1;32m    174\u001b[0m max_ell_prior \u001b[38;5;241m=\u001b[39m num_levels_prior\n\u001b[0;32m--> 176\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmatern_LT_Phi\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_ell\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_ell\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_ell_prior\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_ell_prior\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43md\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkappa\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkappa\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnu\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msigma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msigma\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/mdgp_requirements_test1/lib/python3.11/site-packages/mdgp/variational/spherical_harmonic_features/utils.py:156\u001b[0m, in \u001b[0;36mmatern_LT_Phi\u001b[0;34m(x, max_ell, max_ell_prior, d, kappa, nu, sigma)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmatern_LT_Phi\u001b[39m(x: Tensor, max_ell: \u001b[38;5;28mint\u001b[39m, max_ell_prior: \u001b[38;5;28mint\u001b[39m, d: \u001b[38;5;28mint\u001b[39m, kappa: \u001b[38;5;28mfloat\u001b[39m, nu: \u001b[38;5;28mfloat\u001b[39m, sigma: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor: \n\u001b[0;32m--> 156\u001b[0m     Kux \u001b[38;5;241m=\u001b[39m \u001b[43mmatern_Kux\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_ell\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_ell\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43md\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# [..., O, num_harmonics, N]\u001b[39;00m\n\u001b[1;32m    157\u001b[0m     ahat_sqrt \u001b[38;5;241m=\u001b[39m matern_repeated_ahat(max_ell\u001b[38;5;241m=\u001b[39mmax_ell, max_ell_prior\u001b[38;5;241m=\u001b[39mmax_ell_prior, d\u001b[38;5;241m=\u001b[39md, kappa\u001b[38;5;241m=\u001b[39mkappa, nu\u001b[38;5;241m=\u001b[39mnu, sigma\u001b[38;5;241m=\u001b[39msigma)\u001b[38;5;241m.\u001b[39msqrt() \u001b[38;5;66;03m# [O, num_harmonics, 1]\u001b[39;00m\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Kux \u001b[38;5;241m*\u001b[39m ahat_sqrt\n",
      "File \u001b[0;32m~/miniconda3/envs/mdgp_requirements_test1/lib/python3.11/site-packages/mdgp/variational/spherical_harmonic_features/utils.py:134\u001b[0m, in \u001b[0;36mmatern_Kux\u001b[0;34m(x, max_ell, d)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmatern_Kux\u001b[39m(x: Tensor, max_ell: \u001b[38;5;28mint\u001b[39m, d: \u001b[38;5;28mint\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor: \n\u001b[0;32m--> 134\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mspherical_harmonics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_ell\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_ell\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43md\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mmT\n",
      "File \u001b[0;32m~/miniconda3/envs/mdgp_requirements_test1/lib/python3.11/site-packages/mdgp/variational/spherical_harmonic_features/utils.py:128\u001b[0m, in \u001b[0;36mspherical_harmonics\u001b[0;34m(x, max_ell, d)\u001b[0m\n\u001b[1;32m    124\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mflatten(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    126\u001b[0m \u001b[38;5;66;03m# SphericalHarmonics works with S^{d-1}, while we work with S^d as in GeometricKernels. \u001b[39;00m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;66;03m# Also SphericalHarmonics uses levels up to `degrees` (exclusive); hence, the +1. \u001b[39;00m\n\u001b[0;32m--> 128\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mSphericalHarmonics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdimension\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43md\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdegrees\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_ell\u001b[49m\u001b[43m)\u001b[49m(x) \u001b[38;5;66;03m# [... * O, N, num_harmonics]\u001b[39;00m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m*\u001b[39mbatch_shape, n, total_num_harmonics(max_ell, d))\n",
      "File \u001b[0;32m~/miniconda3/envs/mdgp_requirements_test1/lib/python3.11/site-packages/spherical_harmonics/spherical_harmonics.py:60\u001b[0m, in \u001b[0;36mSphericalHarmonics.__init__\u001b[0;34m(self, dimension, degrees, debug)\u001b[0m\n\u001b[1;32m     57\u001b[0m     degrees \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mrange\u001b[39m(degrees))\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfundamental_system \u001b[38;5;241m=\u001b[39m FundamentalSystemCache(dimension)\n\u001b[0;32m---> 60\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mharmonic_levels \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m    \u001b[49m\u001b[43mSphericalHarmonicsLevel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdimension\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdegree\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfundamental_system\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdegree\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdegrees\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[43m\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/mdgp_requirements_test1/lib/python3.11/site-packages/spherical_harmonics/spherical_harmonics.py:61\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     57\u001b[0m     degrees \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mrange\u001b[39m(degrees))\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfundamental_system \u001b[38;5;241m=\u001b[39m FundamentalSystemCache(dimension)\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mharmonic_levels \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m---> 61\u001b[0m     \u001b[43mSphericalHarmonicsLevel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdimension\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdegree\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfundamental_system\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m degree \u001b[38;5;129;01min\u001b[39;00m degrees\n\u001b[1;32m     63\u001b[0m ]\n",
      "File \u001b[0;32m~/miniconda3/envs/mdgp_requirements_test1/lib/python3.11/site-packages/spherical_harmonics/spherical_harmonics.py:141\u001b[0m, in \u001b[0;36mSphericalHarmonicsLevel.__init__\u001b[0;34m(self, dimension, degree, fundamental_system)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mL \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mcholesky(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mA)  \u001b[38;5;66;03m# [M, M]\u001b[39;00m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;66;03m# Cholesky inverse corresponds to the weights you get from Gram-Schmidt\u001b[39;00m\n\u001b[0;32m--> 141\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mL_inv \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msolve\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mL\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meye\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mL\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgegenbauer \u001b[38;5;241m=\u001b[39m Gegenbauer(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdegree, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malpha)\n",
      "File \u001b[0;32m~/miniconda3/envs/mdgp_requirements_test1/lib/python3.11/site-packages/numpy/linalg/linalg.py:409\u001b[0m, in \u001b[0;36msolve\u001b[0;34m(a, b)\u001b[0m\n\u001b[1;32m    407\u001b[0m signature \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDD->D\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m isComplexType(t) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdd->d\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    408\u001b[0m extobj \u001b[38;5;241m=\u001b[39m get_linalg_error_extobj(_raise_linalgerror_singular)\n\u001b[0;32m--> 409\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43mgufunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    411\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrap(r\u001b[38;5;241m.\u001b[39mastype(result_t, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model, projector = get_model_and_projector(kin8mn)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, maximize=True)\n",
    "elbo = gpytorch.mlls.VariationalELBO(model.likelihood, model, y.size(0))\n",
    "\n",
    "\n",
    "for _ in (pbar := tqdm(range(20000), desc='Epochs')):\n",
    "    optimizer.zero_grad()\n",
    "    x_batch, y_batch = projector(x, y)\n",
    "    output = model(x_batch)\n",
    "    # output = projector.inverse(output)\n",
    "    loss = elbo(output, y_batch)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    pbar.set_postfix({'ELBO': loss.item()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.1485)\n",
      "tensor(0.0467)\n",
      "26.846970512768507\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    test_x = projector(test_x)\n",
    "    out = model(test_x)\n",
    "    out = projector.inverse(out)\n",
    "    mean = out.mean\n",
    "    print((test_y_std ** 2 * (mean - test_y) ** 2).mean().sqrt())\n",
    "    print(mean_squared_error(out, test_y, test_y_std))\n",
    "    print(negative_log_predictive_density(out, test_y).mean().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------Reproducing results for power--------------------------\n",
      "\n",
      "-------------------------------------Run 1--------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a76fa18e6e6545d9b6d3a2737f92ec3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLPD: 0.014695136020697464, MSE: 0.05854422073080649\n",
      "-------------------------------------Run 2--------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f4b6af2b279445db789d0438dcc903f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mreproduce_results\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpower\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkin8mn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_x\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[8], line 57\u001b[0m, in \u001b[0;36mreproduce_results\u001b[0;34m(dataset, batch_size, num_runs, num_epochs, lr)\u001b[0m\n\u001b[1;32m     55\u001b[0m torch\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mmanual_seed(run)\n\u001b[1;32m     56\u001b[0m model, projector \u001b[38;5;241m=\u001b[39m get_model_and_projector(dataset)\n\u001b[0;32m---> 57\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprojector\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;66;03m# print(\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;66;03m#     model.covar_module.base_kernel.lengthscale, \u001b[39;00m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;66;03m#     model.covar_module.base_kernel.nu,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;66;03m#     model.variational_strategy._variational_distribution.chol_variational_covar,\u001b[39;00m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;66;03m# )\u001b[39;00m\n\u001b[1;32m     66\u001b[0m run_metrics \u001b[38;5;241m=\u001b[39m evaluate(dataset, model, projector)\n",
      "Cell \u001b[0;32mIn[8], line 25\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(dataset, model, projector, batch_size, num_epochs, lr)\u001b[0m\n\u001b[1;32m     23\u001b[0m epoch_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x_batch, y_batch \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[0;32m---> 25\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprojector\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprojector\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmll\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmll\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m     epoch_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\n\u001b[1;32m     27\u001b[0m losses\u001b[38;5;241m.\u001b[39mappend(epoch_loss)\n",
      "Cell \u001b[0;32mIn[8], line 6\u001b[0m, in \u001b[0;36mtrain_step\u001b[0;34m(x, y, model, projector, optimizer, mll)\u001b[0m\n\u001b[1;32m      4\u001b[0m output \u001b[38;5;241m=\u001b[39m model(x)\n\u001b[1;32m      5\u001b[0m loss \u001b[38;5;241m=\u001b[39m mll(output, y)\n\u001b[0;32m----> 6\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/miniconda3/envs/mdgp_requirements_test1/lib/python3.11/site-packages/torch/_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    491\u001b[0m     )\n\u001b[0;32m--> 492\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/mdgp_requirements_test1/lib/python3.11/site-packages/torch/autograd/__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/mdgp_requirements_test1/lib/python3.11/site-packages/torch/autograd/function.py:276\u001b[0m, in \u001b[0;36mBackwardCFunction.apply\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mBackwardCFunction\u001b[39;00m(_C\u001b[38;5;241m.\u001b[39m_FunctionBase, FunctionCtx, _HookMixin):\n\u001b[0;32m--> 276\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs):\n\u001b[1;32m    277\u001b[0m         \u001b[38;5;66;03m# _forward_cls is defined by derived class\u001b[39;00m\n\u001b[1;32m    278\u001b[0m         \u001b[38;5;66;03m# The user should define either backward or vjp but never both.\u001b[39;00m\n\u001b[1;32m    279\u001b[0m         backward_fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_cls\u001b[38;5;241m.\u001b[39mbackward  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    280\u001b[0m         vjp_fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_cls\u001b[38;5;241m.\u001b[39mvjp  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "reproduce_results(power, num_epochs=1000, batch_size=kin8mn.train_x.size(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------Reproducing results for power--------------------------\n",
      "\n",
      "-------------------------------------Run 1--------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 20/20 [02:20<00:00,  7.04s/it, ELBO=34]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLPD: 0.018200022938892634, MSE: 0.0604323361222259\n",
      "-------------------------------------Run 2--------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 20/20 [02:12<00:00,  6.63s/it, ELBO=34]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLPD: 0.020585911675719538, MSE: 0.06111090834631231\n",
      "-------------------------------------Run 3--------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 20/20 [02:17<00:00,  6.85s/it, ELBO=34]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLPD: 0.029410862008512097, MSE: 0.06202288396624321\n",
      "-------------------------------------Run 4--------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 20/20 [02:17<00:00,  6.89s/it, ELBO=34]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLPD: 0.011682565872741057, MSE: 0.05958469777710783\n",
      "-------------------------------------Run 5--------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 20/20 [02:14<00:00,  6.71s/it, ELBO=34.2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLPD: 0.018373846236252843, MSE: 0.06075983045730417\n",
      "----------------------------------Metrics mean----------------------------------\n",
      "nlpd    0.019651\n",
      "mse     0.060782\n",
      "dtype: float64\n",
      "----------------------------------Metrics STD-----------------------------------\n",
      "nlpd    0.006391\n",
      "mse     0.000895\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nlpd</th>\n",
       "      <th>mse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.018200</td>\n",
       "      <td>0.060432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.020586</td>\n",
       "      <td>0.061111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.029411</td>\n",
       "      <td>0.062023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.011683</td>\n",
       "      <td>0.059585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.018374</td>\n",
       "      <td>0.060760</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       nlpd       mse\n",
       "0  0.018200  0.060432\n",
       "1  0.020586  0.061111\n",
       "2  0.029411  0.062023\n",
       "3  0.011683  0.059585\n",
       "4  0.018374  0.060760"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reproduce_results(power, num_epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------Reproducing results for concrete------------------------\n",
      "\n",
      "-------------------------------------Run 1--------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 125/125 [01:26<00:00,  1.44it/s, ELBO=2.44] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLPD: 0.3623051474366128, MSE: 0.1097215590579564\n",
      "-------------------------------------Run 2--------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 125/125 [01:32<00:00,  1.35it/s, ELBO=2.46] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLPD: 0.3629351313556932, MSE: 0.10951533423101913\n",
      "-------------------------------------Run 3--------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 125/125 [01:30<00:00,  1.39it/s, ELBO=2.41] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLPD: 0.3790285364454814, MSE: 0.11759354105563866\n",
      "-------------------------------------Run 4--------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 125/125 [01:28<00:00,  1.41it/s, ELBO=2.46] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLPD: 0.37304157369488944, MSE: 0.1139838157709856\n",
      "-------------------------------------Run 5--------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 125/125 [01:28<00:00,  1.41it/s, ELBO=2.41] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLPD: 0.37610820039944604, MSE: 0.11769848257163341\n",
      "----------------------------------Metrics mean----------------------------------\n",
      "nlpd    0.370684\n",
      "mse     0.113703\n",
      "dtype: float64\n",
      "----------------------------------Metrics STD-----------------------------------\n",
      "nlpd    0.007663\n",
      "mse     0.004018\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nlpd</th>\n",
       "      <th>mse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.362305</td>\n",
       "      <td>0.109722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.362935</td>\n",
       "      <td>0.109515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.379029</td>\n",
       "      <td>0.117594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.373042</td>\n",
       "      <td>0.113984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.376108</td>\n",
       "      <td>0.117698</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       nlpd       mse\n",
       "0  0.362305  0.109722\n",
       "1  0.362935  0.109515\n",
       "2  0.379029  0.117594\n",
       "3  0.373042  0.113984\n",
       "4  0.376108  0.117698"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reproduce_results(concrete, num_epochs=125)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mdgp_requirements_test1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
