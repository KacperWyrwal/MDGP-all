{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Geomstats and GeometricKernels backends \n",
    "import geometric_kernels.torch \n",
    "import os\n",
    "os.environ['GEOMSTATS_BACKEND'] = 'pytorch'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook reproduces results from the spherical harmonics paper on UCI datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Using pytorch backend\n",
      "/tmp/ipykernel_1679139/3310190072.py:14: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "from torch import Tensor \n",
    "\n",
    "\n",
    "import torch \n",
    "import gpytorch \n",
    "import geometric_kernels.torch \n",
    "from math import comb \n",
    "from spherical_harmonics import SphericalHarmonics\n",
    "from geometric_kernels.spaces import Hypersphere\n",
    "from gpytorch.variational import CholeskyVariationalDistribution\n",
    "from gpytorch.distributions import MultivariateNormal\n",
    "from linear_operator.operators import DiagLinearOperator, LinearOperator\n",
    "from mdgp.kernels import GeometricMaternKernel\n",
    "from tqdm.autonotebook import tqdm \n",
    "from gpytorch.metrics import negative_log_predictive_density, mean_squared_error\n",
    "\n",
    "\n",
    "torch.set_default_dtype(torch.float64)\n",
    "from mdgp.variational.spherical_harmonic_features.utils import * \n",
    "from mdgp.variational.spherical_harmonic_features_variational_strategy import SphericalHarmonicFeaturesVariationalStrategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class gpytorchSGP(gpytorch.models.ApproximateGP):\n",
    "    def __init__(self, max_ell, d, max_ell_prior, epsilon_sigma=1.0, kappa=1.0, nu=2.5, sigma=1.0, batch_shape=torch.Size([]), jitter_val=1e-6, optimize_nu: bool = True):\n",
    "        m = total_num_harmonics(max_ell, d)\n",
    "        variational_distribution = CholeskyVariationalDistribution(num_inducing_points=m, batch_shape=batch_shape)\n",
    "        variational_strategy = SphericalHarmonicFeaturesVariationalStrategy(self, variational_distribution, num_levels=max_ell, jitter_val=jitter_val)\n",
    "        super().__init__(variational_strategy=variational_strategy)\n",
    "\n",
    "        # constants \n",
    "        self.jitter_val = jitter_val\n",
    "        self.max_ell = max_ell\n",
    "        self.max_ell_prior = max_ell_prior\n",
    "        self.d = d\n",
    "\n",
    "        # modules \n",
    "        base_kernel = GeometricMaternKernel(\n",
    "            space=Hypersphere(d),\n",
    "            lengthscale=kappa, \n",
    "            nu=nu, \n",
    "            trainable_nu=optimize_nu, \n",
    "            num_eigenfunctions=max_ell_prior,\n",
    "        )\n",
    "        self.covar_module = gpytorch.kernels.ScaleKernel(base_kernel)\n",
    "        self.mean_module = gpytorch.means.ConstantMean()\n",
    "        self.likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "\n",
    "        # prior hyperparams \n",
    "        self.covar_module.outputscale = sigma ** 2\n",
    "        self.likelihood.noise = epsilon_sigma ** 2\n",
    "\n",
    "    def forward(self, x) -> MultivariateNormal:\n",
    "        p_sigma = self.covar_module(x)\n",
    "        p_mu = self.mean_module(x)\n",
    "        return MultivariateNormal(p_mu, p_sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mdgp.experiments.uci.model.projectors import SphereProjector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UCI data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mdgp.experiments.uci.data.datasets import Kin8mn, Power, Concrete, Energy, UCIDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixed parameters as in the spherical harmonics paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datasets \n",
    "kin8mn = Kin8mn()\n",
    "power = Power()\n",
    "concrete = Concrete()\n",
    "\n",
    "# Variational parameters\n",
    "dimension_to_num_harmonics_variational = {\n",
    "    4: 336,\n",
    "    6: 294,\n",
    "    8: 210,\n",
    "}\n",
    "\n",
    "# Prior parameters \n",
    "\"\"\"\n",
    "NOTE \n",
    "- It is difficult to say what number of spherical harmonics was used for the prior.\n",
    "  I set it to be the same as the number of inducing variables.\n",
    "- It is also difficult to say what lengthscale initialisation was used in the paper. \n",
    "  I set it to 1.0 for now, although a lower number, e.g. 0.001, would likely be better for higher dimensions.\n",
    "\"\"\"\n",
    "dimension_to_num_harmonics_prior = {\n",
    "    4: 336, \n",
    "    6: 1000,\n",
    "    8: 625,\n",
    "}\n",
    "nu = 1.5\n",
    "optimize_nu = False\n",
    "kappa = 1.0\n",
    "\n",
    "# Other model parameters\n",
    "batch_shape = torch.Size([])\n",
    "\n",
    "# Training parameters \n",
    "batch_size = 256 \n",
    "LR = 0.01\n",
    "NUM_EPOCHS = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of spherical harmonics requested does not lead to complete levels of spherical harmonics. We have thus increased the number to 660, which includes all spherical harmonics up to level 5 (exclusive)\n"
     ]
    }
   ],
   "source": [
    "from mdgp.variational.spherical_harmonic_features.utils import num_spherical_harmonics_to_num_levels\n",
    "\n",
    "\n",
    "def get_model_and_projector(dataset: UCIDataset, proj: str = 'sphere'):\n",
    "    sphere_dimension = dataset.dimension\n",
    "\n",
    "    # number of levels for variational inference \n",
    "    num_spherical_harmonics = dimension_to_num_harmonics_variational[dataset.dimension]\n",
    "    max_ell, _ = num_spherical_harmonics_to_num_levels(num_spherical_harmonics, sphere_dimension)\n",
    "\n",
    "    # number of levels for prior\n",
    "    num_spherical_harmonics_prior = dimension_to_num_harmonics_prior[dataset.dimension]\n",
    "    max_ell_prior, _ = num_spherical_harmonics_to_num_levels(num_spherical_harmonics_prior, sphere_dimension)\n",
    "\n",
    "    model = gpytorchSGP(max_ell=max_ell, d=sphere_dimension, max_ell_prior=max_ell_prior, kappa=kappa, nu=nu, optimize_nu=optimize_nu, batch_shape=batch_shape)\n",
    "    projector = SphereProjector()\n",
    "    return model, projector\n",
    "\n",
    "\n",
    "model, projector = get_model_and_projector(kin8mn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(x, y, model, projector, optimizer, mll) -> float:\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    x, y = projector(x, y)\n",
    "    # print(x.shape, y.shape)\n",
    "    output = model(x)\n",
    "    loss = mll(output, y.squeeze(-1))\n",
    "    # print(loss)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "\n",
    "def train(dataset, model, projector, batch_size, num_epochs=NUM_EPOCHS, lr=LR, optimize_projector: bool = False) -> list[float]: \n",
    "    # optimizer and criterion\n",
    "    parameters = [{\n",
    "        'params': model.parameters()\n",
    "    }]\n",
    "    if optimize_projector:\n",
    "        parameters.append({\n",
    "            'params': projector.parameters()\n",
    "        })\n",
    "    optimizer = torch.optim.Adam(parameters, lr=lr, maximize=True)\n",
    "    mll = gpytorch.mlls.DeepApproximateMLL(gpytorch.mlls.VariationalELBO(model.likelihood, model, dataset.train_y.size(0)))\n",
    "\n",
    "    # data\n",
    "    train_loader = DataLoader(dataset.train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    # Training loop\n",
    "    losses = []\n",
    "    pbar = tqdm(range(num_epochs))\n",
    "    for epoch in pbar:\n",
    "        epoch_loss = 0\n",
    "        for x_batch, y_batch in train_loader:\n",
    "            loss = train_step(x=x_batch, y=y_batch, model=model, projector=projector, optimizer=optimizer, mll=mll)\n",
    "            epoch_loss += loss\n",
    "        losses.append(epoch_loss)\n",
    "        pbar.set_postfix({'ELBO': losses[-1]})\n",
    "\n",
    "    return losses \n",
    "\n",
    "\n",
    "def train_lfbgs(dataset, model, projector, num_epochs=NUM_EPOCHS, lr=1.0) -> list[float]:\n",
    "    optimizer = torch.optim.LBFGS(model.parameters(), lr=lr, max_iter=20)\n",
    "\n",
    "    mll = gpytorch.mlls.VariationalELBO(model.likelihood, model, dataset.train_y.size(0))\n",
    "\n",
    "    def closure():\n",
    "        optimizer.zero_grad()\n",
    "        x, y = projector(dataset.train_x, dataset.train_y)\n",
    "        output = model(x)\n",
    "        loss = -mll(output, y.squeeze(-1))\n",
    "        loss.backward()\n",
    "        return loss\n",
    "\n",
    "    losses = []\n",
    "    pbar = tqdm(range(num_epochs))\n",
    "    for epoch in pbar:\n",
    "        epoch_loss = optimizer.step(closure)\n",
    "        losses.append(epoch_loss)\n",
    "        pbar.set_postfix({'ELBO': losses[-1]})\n",
    "\n",
    "    return losses\n",
    "\n",
    "\n",
    "def evaluate(dataset, model, projector):\n",
    "    with torch.no_grad():\n",
    "        test_x, test_y = projector(dataset.test_x), dataset.test_y\n",
    "        test_y = test_y.squeeze(-1)\n",
    "        out = model.likelihood(model(test_x))\n",
    "        out = projector.inverse(out)\n",
    "        nlpd = negative_log_predictive_density(out, test_y)\n",
    "        mse = mean_squared_error(out, test_y)\n",
    "        metrics = {\n",
    "            'nlpd': nlpd.item(), \n",
    "            'mse': mse.item(),\n",
    "        }\n",
    "        print(f\"NLPD: {metrics['nlpd']}, MSE: {metrics['mse']}\")\n",
    "    return metrics \n",
    "\n",
    "\n",
    "def reproduce_results(dataset, batch_size, num_runs: int = 5, num_epochs=NUM_EPOCHS, lr=LR):\n",
    "    print(f\"Reproducing results for {dataset.name}\".center(80, '-') + '\\n')\n",
    "\n",
    "    metrics = []\n",
    "    for run in range(num_runs):\n",
    "        print(f\"Run {run + 1}\".center(80, '-'))\n",
    "\n",
    "        torch.random.manual_seed(run)\n",
    "        model, projector = get_model_and_projector(dataset)\n",
    "        train(dataset, model, projector, num_epochs=num_epochs, lr=lr, batch_size=batch_size)\n",
    "        # print(\n",
    "        #     model.covar_module.base_kernel.lengthscale, \n",
    "        #     model.covar_module.base_kernel.nu,\n",
    "        #     model.covar_module.outputscale,\n",
    "        #     model.likelihood.noise,\n",
    "        #     model.variational_strategy._variational_distribution.variational_mean,\n",
    "        #     model.variational_strategy._variational_distribution.chol_variational_covar,\n",
    "        # )\n",
    "        run_metrics = evaluate(dataset, model, projector)\n",
    "        metrics.append(run_metrics)\n",
    "    df = pd.DataFrame(metrics)\n",
    "\n",
    "    print(\"Metrics mean\".center(80, '-'))\n",
    "    print(df.mean())\n",
    "\n",
    "    print(\"Metrics STD\".center(80, '-'))\n",
    "    print(df.std())\n",
    "\n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mdgp.experiments.uci.model.geometric import SHFDeepGP\n",
    "from mdgp.experiments.uci.model.euclidean import EuclideanDeepGP\n",
    "from mdgp.experiments.uci.model.projectors import IdentityProjector\n",
    "from mdgp.experiments.uci.fit import train as train_uci\n",
    "from mdgp.experiments.uci.fit import FitArguments\n",
    "\n",
    "\n",
    "model = 'euclidean'\n",
    "num_layers = 3\n",
    "\n",
    "if model == 'geometric':\n",
    "    model = SHFDeepGP(kin8mn, num_layers)\n",
    "    projector = SphereProjector()\n",
    "elif model == 'euclidean':\n",
    "    model = EuclideanDeepGP(kin8mn, num_layers, num_inducing_points=210)\n",
    "    projector = IdentityProjector()\n",
    "fit_args = FitArguments(\n",
    "    train_batch_size=1024,\n",
    "    num_iterations=100,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 8/8 [00:10<00:00,  1.33s/it]\n",
      "Batches:  25%|██▌       | 2/8 [00:03<00:09,  1.60s/it], ELBO=-17.1]\n",
      "Epochs:   1%|          | 1/100 [00:13<22:50, 13.84s/it, ELBO=-17.1]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m gpytorch\u001b[38;5;241m.\u001b[39msettings\u001b[38;5;241m.\u001b[39mnum_likelihood_samples(\u001b[38;5;241m10\u001b[39m):\n\u001b[0;32m----> 2\u001b[0m     \u001b[43mtrain_uci\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkin8mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprojector\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprojector\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfit_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfit_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minner_pbar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/mdgp_uci/lib/python3.11/site-packages/mdgp/experiments/uci/fit/fit.py:80\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(dataset, model, projector, fit_args, device, inner_pbar)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x_batch, y_batch \u001b[38;5;129;01min\u001b[39;00m batches_pbar:\n\u001b[1;32m     79\u001b[0m     x_batch, y_batch \u001b[38;5;241m=\u001b[39m projector(x_batch, y_batch)\n\u001b[0;32m---> 80\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43melbo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43melbo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     81\u001b[0m     epoch_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\n\u001b[1;32m     82\u001b[0m losses\u001b[38;5;241m.\u001b[39mappend(epoch_loss)\n",
      "File \u001b[0;32m~/miniconda3/envs/mdgp_uci/lib/python3.11/site-packages/mdgp/experiments/uci/fit/fit.py:60\u001b[0m, in \u001b[0;36mtrain_step\u001b[0;34m(x, y, model, optimizer, elbo)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_step\u001b[39m(x: Tensor, y: Tensor, model: DeepGP, optimizer: torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mOptimizer, elbo: VariationalELBO) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mfloat\u001b[39m:\n\u001b[1;32m     59\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad(set_to_none\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 60\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m     loss \u001b[38;5;241m=\u001b[39m elbo(output, y)\n\u001b[1;32m     62\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/miniconda3/envs/mdgp_uci/lib/python3.11/site-packages/gpytorch/module.py:31\u001b[0m, in \u001b[0;36mModule.__call__\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39minputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[Tensor, Distribution, LinearOperator]:\n\u001b[0;32m---> 31\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(outputs, \u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m     33\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [_validate_module_outputs(output) \u001b[38;5;28;01mfor\u001b[39;00m output \u001b[38;5;129;01min\u001b[39;00m outputs]\n",
      "File \u001b[0;32m~/miniconda3/envs/mdgp_uci/lib/python3.11/site-packages/mdgp/experiments/uci/model/euclidean.py:106\u001b[0m, in \u001b[0;36mEuclideanDeepGP.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[0;32m--> 106\u001b[0m         x \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    107\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/miniconda3/envs/mdgp_uci/lib/python3.11/site-packages/gpytorch/models/deep_gps/deep_gp.py:100\u001b[0m, in \u001b[0;36mDeepGPLayer.__call__\u001b[0;34m(self, inputs, are_samples, **kwargs)\u001b[0m\n\u001b[1;32m     97\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mexpand(\u001b[38;5;241m*\u001b[39minputs\u001b[38;5;241m.\u001b[39mshape[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m3\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_dims, \u001b[38;5;241m*\u001b[39minputs\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m:])\n\u001b[1;32m     99\u001b[0m \u001b[38;5;66;03m# Now run samples through the GP\u001b[39;00m\n\u001b[0;32m--> 100\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mApproximateGP\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_dims \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    102\u001b[0m     mean \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mloc\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/mdgp_uci/lib/python3.11/site-packages/gpytorch/models/approximate_gp.py:114\u001b[0m, in \u001b[0;36mApproximateGP.__call__\u001b[0;34m(self, inputs, prior, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inputs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m inputs\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    113\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvariational_strategy\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprior\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprior\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/mdgp_uci/lib/python3.11/site-packages/gpytorch/variational/variational_strategy.py:272\u001b[0m, in \u001b[0;36mVariationalStrategy.__call__\u001b[0;34m(self, x, prior, **kwargs)\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[38;5;66;03m# Mark that we have updated the variational strategy\u001b[39;00m\n\u001b[1;32m    270\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdated_strategy\u001b[38;5;241m.\u001b[39mfill_(\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 272\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprior\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprior\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/mdgp_uci/lib/python3.11/site-packages/gpytorch/variational/_variational_strategy.py:347\u001b[0m, in \u001b[0;36m_VariationalStrategy.__call__\u001b[0;34m(self, x, prior, **kwargs)\u001b[0m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# Get q(f)\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(variational_dist_u, MultivariateNormal):\n\u001b[0;32m--> 347\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m        \u001b[49m\u001b[43minducing_points\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m        \u001b[49m\u001b[43minducing_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvariational_dist_u\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvariational_inducing_covar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvariational_dist_u\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlazy_covariance_matrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(variational_dist_u, Delta):\n\u001b[1;32m    355\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(\n\u001b[1;32m    356\u001b[0m         x, inducing_points, inducing_values\u001b[38;5;241m=\u001b[39mvariational_dist_u\u001b[38;5;241m.\u001b[39mmean, variational_inducing_covar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    357\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/mdgp_uci/lib/python3.11/site-packages/gpytorch/module.py:31\u001b[0m, in \u001b[0;36mModule.__call__\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39minputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[Tensor, Distribution, LinearOperator]:\n\u001b[0;32m---> 31\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(outputs, \u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m     33\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [_validate_module_outputs(output) \u001b[38;5;28;01mfor\u001b[39;00m output \u001b[38;5;129;01min\u001b[39;00m outputs]\n",
      "File \u001b[0;32m~/miniconda3/envs/mdgp_uci/lib/python3.11/site-packages/gpytorch/variational/variational_strategy.py:197\u001b[0m, in \u001b[0;36mVariationalStrategy.forward\u001b[0;34m(self, x, inducing_points, inducing_values, variational_inducing_covar, **kwargs)\u001b[0m\n\u001b[1;32m    195\u001b[0m test_mean \u001b[38;5;241m=\u001b[39m full_output\u001b[38;5;241m.\u001b[39mmean[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, num_induc:]\n\u001b[1;32m    196\u001b[0m induc_induc_covar \u001b[38;5;241m=\u001b[39m full_covar[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, :num_induc, :num_induc]\u001b[38;5;241m.\u001b[39madd_jitter(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjitter_val)\n\u001b[0;32m--> 197\u001b[0m induc_data_covar \u001b[38;5;241m=\u001b[39m \u001b[43mfull_covar\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43mnum_induc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_induc\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_dense\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    198\u001b[0m data_data_covar \u001b[38;5;241m=\u001b[39m full_covar[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, num_induc:, num_induc:]\n\u001b[1;32m    200\u001b[0m \u001b[38;5;66;03m# Compute interpolation terms\u001b[39;00m\n\u001b[1;32m    201\u001b[0m \u001b[38;5;66;03m# K_ZZ^{-1/2} K_ZX\u001b[39;00m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;66;03m# K_ZZ^{-1/2} \\mu_Z\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/mdgp_uci/lib/python3.11/site-packages/gpytorch/utils/memoize.py:59\u001b[0m, in \u001b[0;36m_cached.<locals>.g\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     57\u001b[0m kwargs_pkl \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mdumps(kwargs)\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_in_cache(\u001b[38;5;28mself\u001b[39m, cache_name, \u001b[38;5;241m*\u001b[39margs, kwargs_pkl\u001b[38;5;241m=\u001b[39mkwargs_pkl):\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _add_to_cache(\u001b[38;5;28mself\u001b[39m, cache_name, \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;241m*\u001b[39margs, kwargs_pkl\u001b[38;5;241m=\u001b[39mkwargs_pkl)\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _get_from_cache(\u001b[38;5;28mself\u001b[39m, cache_name, \u001b[38;5;241m*\u001b[39margs, kwargs_pkl\u001b[38;5;241m=\u001b[39mkwargs_pkl)\n",
      "File \u001b[0;32m~/miniconda3/envs/mdgp_uci/lib/python3.11/site-packages/gpytorch/lazy/lazy_evaluated_kernel_tensor.py:414\u001b[0m, in \u001b[0;36mLazyEvaluatedKernelTensor.to_dense\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[38;5;129m@cached\u001b[39m\n\u001b[1;32m    413\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mto_dense\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 414\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate_kernel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto_dense()\n",
      "File \u001b[0;32m~/miniconda3/envs/mdgp_uci/lib/python3.11/site-packages/gpytorch/utils/memoize.py:59\u001b[0m, in \u001b[0;36m_cached.<locals>.g\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     57\u001b[0m kwargs_pkl \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mdumps(kwargs)\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_in_cache(\u001b[38;5;28mself\u001b[39m, cache_name, \u001b[38;5;241m*\u001b[39margs, kwargs_pkl\u001b[38;5;241m=\u001b[39mkwargs_pkl):\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _add_to_cache(\u001b[38;5;28mself\u001b[39m, cache_name, \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;241m*\u001b[39margs, kwargs_pkl\u001b[38;5;241m=\u001b[39mkwargs_pkl)\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _get_from_cache(\u001b[38;5;28mself\u001b[39m, cache_name, \u001b[38;5;241m*\u001b[39margs, kwargs_pkl\u001b[38;5;241m=\u001b[39mkwargs_pkl)\n",
      "File \u001b[0;32m~/miniconda3/envs/mdgp_uci/lib/python3.11/site-packages/gpytorch/lazy/lazy_evaluated_kernel_tensor.py:25\u001b[0m, in \u001b[0;36mrecall_grad_state.<locals>.wrapped\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(method)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_grad_enabled):\n\u001b[0;32m---> 25\u001b[0m         output \u001b[38;5;241m=\u001b[39m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "File \u001b[0;32m~/miniconda3/envs/mdgp_uci/lib/python3.11/site-packages/gpytorch/lazy/lazy_evaluated_kernel_tensor.py:355\u001b[0m, in \u001b[0;36mLazyEvaluatedKernelTensor.evaluate_kernel\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    353\u001b[0m     temp_active_dims \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel\u001b[38;5;241m.\u001b[39mactive_dims\n\u001b[1;32m    354\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel\u001b[38;5;241m.\u001b[39mactive_dims \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 355\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkernel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    356\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    357\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    358\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdiag\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    359\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlast_dim_is_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlast_dim_is_batch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    360\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    361\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel\u001b[38;5;241m.\u001b[39mactive_dims \u001b[38;5;241m=\u001b[39m temp_active_dims\n\u001b[1;32m    364\u001b[0m \u001b[38;5;66;03m# Check the size of the output\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/mdgp_uci/lib/python3.11/site-packages/gpytorch/kernels/kernel.py:530\u001b[0m, in \u001b[0;36mKernel.__call__\u001b[0;34m(self, x1, x2, diag, last_dim_is_batch, **params)\u001b[0m\n\u001b[1;32m    527\u001b[0m     res \u001b[38;5;241m=\u001b[39m LazyEvaluatedKernelTensor(x1_, x2_, kernel\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, last_dim_is_batch\u001b[38;5;241m=\u001b[39mlast_dim_is_batch, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[1;32m    528\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    529\u001b[0m     res \u001b[38;5;241m=\u001b[39m to_linear_operator(\n\u001b[0;32m--> 530\u001b[0m         \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mKernel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx1_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx2_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlast_dim_is_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlast_dim_is_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    531\u001b[0m     )\n\u001b[1;32m    532\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "File \u001b[0;32m~/miniconda3/envs/mdgp_uci/lib/python3.11/site-packages/gpytorch/module.py:31\u001b[0m, in \u001b[0;36mModule.__call__\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39minputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[Tensor, Distribution, LinearOperator]:\n\u001b[0;32m---> 31\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(outputs, \u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m     33\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [_validate_module_outputs(output) \u001b[38;5;28;01mfor\u001b[39;00m output \u001b[38;5;129;01min\u001b[39;00m outputs]\n",
      "File \u001b[0;32m~/miniconda3/envs/mdgp_uci/lib/python3.11/site-packages/gpytorch/kernels/scale_kernel.py:109\u001b[0m, in \u001b[0;36mScaleKernel.forward\u001b[0;34m(self, x1, x2, last_dim_is_batch, diag, **params)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x1, x2, last_dim_is_batch\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, diag\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams):\n\u001b[0;32m--> 109\u001b[0m     orig_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase_kernel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdiag\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdiag\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlast_dim_is_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlast_dim_is_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    110\u001b[0m     outputscales \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutputscale\n\u001b[1;32m    111\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m last_dim_is_batch:\n",
      "File \u001b[0;32m~/miniconda3/envs/mdgp_uci/lib/python3.11/site-packages/gpytorch/kernels/rbf_kernel.py:79\u001b[0m, in \u001b[0;36mRBFKernel.forward\u001b[0;34m(self, x1, x2, diag, **params)\u001b[0m\n\u001b[1;32m     77\u001b[0m     x1_ \u001b[38;5;241m=\u001b[39m x1\u001b[38;5;241m.\u001b[39mdiv(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlengthscale)\n\u001b[1;32m     78\u001b[0m     x2_ \u001b[38;5;241m=\u001b[39m x2\u001b[38;5;241m.\u001b[39mdiv(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlengthscale)\n\u001b[0;32m---> 79\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m postprocess_rbf(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcovar_dist\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx1_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx2_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msquare_dist\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdiag\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdiag\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m RBFCovariance\u001b[38;5;241m.\u001b[39mapply(\n\u001b[1;32m     81\u001b[0m     x1,\n\u001b[1;32m     82\u001b[0m     x2,\n\u001b[1;32m     83\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlengthscale,\n\u001b[1;32m     84\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m x1, x2: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcovar_dist(x1, x2, square_dist\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, diag\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams),\n\u001b[1;32m     85\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/mdgp_uci/lib/python3.11/site-packages/gpytorch/kernels/kernel.py:357\u001b[0m, in \u001b[0;36mKernel.covar_dist\u001b[0;34m(self, x1, x2, diag, last_dim_is_batch, square_dist, **params)\u001b[0m\n\u001b[1;32m    355\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    356\u001b[0m     dist_func \u001b[38;5;241m=\u001b[39m sq_dist \u001b[38;5;28;01mif\u001b[39;00m square_dist \u001b[38;5;28;01melse\u001b[39;00m dist\n\u001b[0;32m--> 357\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdist_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx1_eq_x2\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/mdgp_uci/lib/python3.11/site-packages/gpytorch/kernels/kernel.py:49\u001b[0m, in \u001b[0;36msq_dist\u001b[0;34m(x1, x2, x1_eq_x2)\u001b[0m\n\u001b[1;32m     46\u001b[0m     res\u001b[38;5;241m.\u001b[39mdiagonal(dim1\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m, dim2\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mfill_(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m# Zero out negative values\u001b[39;00m\n\u001b[0;32m---> 49\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mres\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclamp_min_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with gpytorch.settings.num_likelihood_samples(10):\n",
    "    train_uci(kin8mn, model=model, projector=projector, fit_args=fit_args, device='cpu', inner_pbar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TLL: -0.43074761694610925, MSE: 0.03635215431338528\n"
     ]
    }
   ],
   "source": [
    "from mdgp.experiments.uci.fit.fit import evaluate_deep\n",
    "\n",
    "with torch.no_grad(), gpytorch.settings.num_likelihood_samples(10):\n",
    "    fit_args.test_num_samples = 10\n",
    "    evaluate_deep(kin8mn, model, projector, 'cpu', fit_args=fit_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TLL: 0.7194914541851841, MSE: 0.01465116672011924\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad(), gpytorch.settings.num_likelihood_samples(10):\n",
    "    fit_args.test_num_samples = 10\n",
    "    evaluate_deep(kin8mn, model, projector, 'cpu', fit_args=fit_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TLL: 1.0851964894289, MSE: 0.007424122800293092\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad(), gpytorch.settings.num_likelihood_samples(10):\n",
    "    fit_args.test_num_samples = 10\n",
    "    evaluate_deep(kin8mn, model, projector, 'cpu', fit_args=fit_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TLL: -0.8657127998655103, MSE: 0.056299769163549174\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad(), gpytorch.settings.num_likelihood_samples(10):\n",
    "    fit_args.test_num_samples = 10\n",
    "    evaluate_deep(kin8mn, model, projector, 'cpu', fit_args=fit_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TLL: 0.2188367189484403, MSE: 0.024650527151646066\n"
     ]
    }
   ],
   "source": [
    "from mdgp.experiments.uci.fit.fit import evaluate_deep, evaluate_shallow\n",
    "\n",
    "with torch.no_grad(), gpytorch.settings.num_likelihood_samples(10):\n",
    "    evaluate_deep(kin8mn, model, projector, device='cpu', fit_args=fit_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TLL: 1.209683798301345, MSE: 0.005304259921531311\n"
     ]
    }
   ],
   "source": [
    "from mdgp.experiments.uci.fit.fit import evaluate_deep, evaluate_shallow\n",
    "\n",
    "with torch.no_grad(), gpytorch.settings.num_likelihood_samples(10):\n",
    "    evaluate_deep(kin8mn, model, projector, device='cpu', fit_args=fit_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TLL: 1.0008430227727956, MSE: 0.007140704163331918\n"
     ]
    }
   ],
   "source": [
    "from mdgp.experiments.uci.fit.fit import evaluate_deep, evaluate_shallow\n",
    "\n",
    "with torch.no_grad(), gpytorch.settings.num_likelihood_samples(100):\n",
    "    evaluate_deep(kin8mn, model, projector, device='cpu', fit_args=fit_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TLL: 1.2228897539138972, MSE: 0.005064238676492455\n"
     ]
    }
   ],
   "source": [
    "from mdgp.experiments.uci.fit.fit import evaluate_deep, evaluate_shallow\n",
    "\n",
    "with torch.no_grad(), gpytorch.settings.num_likelihood_samples(100):\n",
    "    evaluate_deep(kin8mn, model, projector, device='cpu', fit_args=fit_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TLL: 1.2651115829407433, MSE: 0.004955803643329355\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from mdgp.experiments.uci.fit.fit import evaluate_deep, evaluate_shallow\n",
    "\n",
    "with torch.no_grad(), gpytorch.settings.num_likelihood_samples(200):\n",
    "    evaluate_deep(kin8mn, model, projector, device='cpu', fit_args=fit_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TLL: 1.0000001444029862, MSE: 0.007093938590989231\n",
      "NLPD 0.3235617586172367\n"
     ]
    }
   ],
   "source": [
    "from mdgp.experiments.uci.fit.fit import evaluate_deep, evaluate_shallow\n",
    "\n",
    "with torch.no_grad():\n",
    "    evaluate_deep(kin8mn, model, projector, device='cpu', fit_args=fit_args)\n",
    "    out = model.likelihood(model(kin8mn.test_x))\n",
    "    out = projector.inverse(out)\n",
    "    nlpd = negative_log_predictive_density(out, kin8mn.test_y)\n",
    "    print(f\"NLPD {nlpd.mean().item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TLL: 1.0026375218917551, MSE: 0.007027994436844125\n",
      "TLL: 1.0026375218917551, MSE: 0.007027994436844124\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    evaluate_shallow(kin8mn, model, projector, device='cpu', fit_args=fit_args)\n",
    "    evaluate_deep(kin8mn, model, projector, device='cpu', fit_args=fit_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of spherical harmonics requested does not lead to complete levels of spherical harmonics. We have thus increased the number to 660, which includes all spherical harmonics up to level 5 (exclusive)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4998afbebda4af280052314b5499368",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[tensor(1.4776, grad_fn=<NegBackward0>),\n",
       " tensor(0.9105, grad_fn=<NegBackward0>),\n",
       " tensor(0.6691, grad_fn=<NegBackward0>),\n",
       " tensor(0.5100, grad_fn=<NegBackward0>),\n",
       " tensor(0.4262, grad_fn=<NegBackward0>),\n",
       " tensor(0.3034, grad_fn=<NegBackward0>),\n",
       " tensor(0.2287, grad_fn=<NegBackward0>),\n",
       " tensor(0.1842, grad_fn=<NegBackward0>),\n",
       " tensor(0.1534, grad_fn=<NegBackward0>),\n",
       " tensor(0.1279, grad_fn=<NegBackward0>),\n",
       " tensor(0.0992, grad_fn=<NegBackward0>),\n",
       " tensor(0.0627, grad_fn=<NegBackward0>),\n",
       " tensor(0.0159, grad_fn=<NegBackward0>),\n",
       " tensor(-0.0425, grad_fn=<NegBackward0>),\n",
       " tensor(-0.0696, grad_fn=<NegBackward0>),\n",
       " tensor(-0.0945, grad_fn=<NegBackward0>),\n",
       " tensor(-0.1192, grad_fn=<NegBackward0>),\n",
       " tensor(-0.1430, grad_fn=<NegBackward0>),\n",
       " tensor(-0.1667, grad_fn=<NegBackward0>),\n",
       " tensor(-0.1870, grad_fn=<NegBackward0>),\n",
       " tensor(-0.2044, grad_fn=<NegBackward0>),\n",
       " tensor(-0.2241, grad_fn=<NegBackward0>),\n",
       " tensor(-0.2484, grad_fn=<NegBackward0>),\n",
       " tensor(-0.2625, grad_fn=<NegBackward0>),\n",
       " tensor(-0.2697, grad_fn=<NegBackward0>),\n",
       " tensor(-0.2742, grad_fn=<NegBackward0>),\n",
       " tensor(-0.2775, grad_fn=<NegBackward0>),\n",
       " tensor(-0.2815, grad_fn=<NegBackward0>),\n",
       " tensor(-0.2889, grad_fn=<NegBackward0>),\n",
       " tensor(-0.2957, grad_fn=<NegBackward0>),\n",
       " tensor(-0.3003, grad_fn=<NegBackward0>),\n",
       " tensor(-0.3038, grad_fn=<NegBackward0>),\n",
       " tensor(-0.3064, grad_fn=<NegBackward0>),\n",
       " tensor(-0.3085, grad_fn=<NegBackward0>),\n",
       " tensor(-0.3102, grad_fn=<NegBackward0>),\n",
       " tensor(-0.3115, grad_fn=<NegBackward0>),\n",
       " tensor(-0.3126, grad_fn=<NegBackward0>),\n",
       " tensor(-0.3134, grad_fn=<NegBackward0>),\n",
       " tensor(-0.3142, grad_fn=<NegBackward0>),\n",
       " tensor(-0.3148, grad_fn=<NegBackward0>)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model, projector = get_model_and_projector(kin8mn)\n",
    "train_lfbgs(kin8mn, model, projector, batch_size, num_epochs=40, lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLPD: 0.5905679521542057, MSE: 0.21266969401689906\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'nlpd': 0.5905679521542057, 'mse': 0.21266969401689906}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(kin8mn, model, projector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of spherical harmonics requested does not lead to complete levels of spherical harmonics. We have thus increased the number to 660, which includes all spherical harmonics up to level 5 (exclusive)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "836e7ccf73d2428c946a4e580361856a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m model, projector \u001b[38;5;241m=\u001b[39m get_model_and_projector(kin8mn, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msphere\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkin8mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprojector\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mNUM_EPOCHS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mLR\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m evaluate(kin8mn, model, projector)\n",
      "Cell \u001b[0;32mIn[8], line 34\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(dataset, model, projector, batch_size, num_epochs, lr, optimize_projector)\u001b[0m\n\u001b[1;32m     32\u001b[0m epoch_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x_batch, y_batch \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[0;32m---> 34\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprojector\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprojector\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmll\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmll\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m     epoch_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\n\u001b[1;32m     36\u001b[0m losses\u001b[38;5;241m.\u001b[39mappend(epoch_loss)\n",
      "Cell \u001b[0;32mIn[8], line 5\u001b[0m, in \u001b[0;36mtrain_step\u001b[0;34m(x, y, model, projector, optimizer, mll)\u001b[0m\n\u001b[1;32m      3\u001b[0m x, y \u001b[38;5;241m=\u001b[39m projector(x, y)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# print(x.shape, y.shape)\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m loss \u001b[38;5;241m=\u001b[39m mll(output, y\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# print(loss)\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/mdgp_requirements_test1/lib/python3.11/site-packages/gpytorch/models/approximate_gp.py:108\u001b[0m, in \u001b[0;36mApproximateGP.__call__\u001b[0;34m(self, inputs, prior, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inputs\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    107\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 108\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvariational_strategy\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprior\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprior\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/mdgp_requirements_test1/lib/python3.11/site-packages/mdgp/variational/spherical_harmonic_features_variational_strategy.py:74\u001b[0m, in \u001b[0;36mSphericalHarmonicFeaturesVariationalStrategy.__call__\u001b[0;34m(self, x, prior, **kwargs)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m prior:\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mforward(x)\n\u001b[0;32m---> 74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/mdgp_requirements_test1/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/mdgp_requirements_test1/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/mdgp_requirements_test1/lib/python3.11/site-packages/mdgp/variational/spherical_harmonic_features_variational_strategy.py:55\u001b[0m, in \u001b[0;36mSphericalHarmonicFeaturesVariationalStrategy.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     52\u001b[0m Linv_m, Linv_S_LTinv \u001b[38;5;241m=\u001b[39m Linv_qu\u001b[38;5;241m.\u001b[39mmean, Linv_qu\u001b[38;5;241m.\u001b[39mlazy_covariance_matrix \u001b[38;5;66;03m# [..., M], [..., M, M]\u001b[39;00m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;66;03m# unwhitening + projection and vice-versa\u001b[39;00m\n\u001b[0;32m---> 55\u001b[0m LT_Phiux \u001b[38;5;241m=\u001b[39m \u001b[43mmatern_LT_Phi_from_kernel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcovar_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_levels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_levels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_levels_prior\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_ell_prior\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m Phixu_L \u001b[38;5;241m=\u001b[39m LT_Phiux\u001b[38;5;241m.\u001b[39mmT \u001b[38;5;66;03m# [..., N, M]\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;66;03m# posterior at x \u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/mdgp_requirements_test1/lib/python3.11/site-packages/mdgp/variational/spherical_harmonic_features/utils.py:176\u001b[0m, in \u001b[0;36mmatern_LT_Phi_from_kernel\u001b[0;34m(x, covar_module, num_levels, num_levels_prior)\u001b[0m\n\u001b[1;32m    173\u001b[0m max_ell \u001b[38;5;241m=\u001b[39m num_levels\n\u001b[1;32m    174\u001b[0m max_ell_prior \u001b[38;5;241m=\u001b[39m num_levels_prior\n\u001b[0;32m--> 176\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmatern_LT_Phi\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_ell\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_ell\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_ell_prior\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_ell_prior\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43md\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkappa\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkappa\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnu\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msigma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msigma\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/mdgp_requirements_test1/lib/python3.11/site-packages/mdgp/variational/spherical_harmonic_features/utils.py:156\u001b[0m, in \u001b[0;36mmatern_LT_Phi\u001b[0;34m(x, max_ell, max_ell_prior, d, kappa, nu, sigma)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmatern_LT_Phi\u001b[39m(x: Tensor, max_ell: \u001b[38;5;28mint\u001b[39m, max_ell_prior: \u001b[38;5;28mint\u001b[39m, d: \u001b[38;5;28mint\u001b[39m, kappa: \u001b[38;5;28mfloat\u001b[39m, nu: \u001b[38;5;28mfloat\u001b[39m, sigma: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor: \n\u001b[0;32m--> 156\u001b[0m     Kux \u001b[38;5;241m=\u001b[39m \u001b[43mmatern_Kux\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_ell\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_ell\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43md\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# [..., O, num_harmonics, N]\u001b[39;00m\n\u001b[1;32m    157\u001b[0m     ahat_sqrt \u001b[38;5;241m=\u001b[39m matern_repeated_ahat(max_ell\u001b[38;5;241m=\u001b[39mmax_ell, max_ell_prior\u001b[38;5;241m=\u001b[39mmax_ell_prior, d\u001b[38;5;241m=\u001b[39md, kappa\u001b[38;5;241m=\u001b[39mkappa, nu\u001b[38;5;241m=\u001b[39mnu, sigma\u001b[38;5;241m=\u001b[39msigma)\u001b[38;5;241m.\u001b[39msqrt() \u001b[38;5;66;03m# [O, num_harmonics, 1]\u001b[39;00m\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Kux \u001b[38;5;241m*\u001b[39m ahat_sqrt\n",
      "File \u001b[0;32m~/miniconda3/envs/mdgp_requirements_test1/lib/python3.11/site-packages/mdgp/variational/spherical_harmonic_features/utils.py:134\u001b[0m, in \u001b[0;36mmatern_Kux\u001b[0;34m(x, max_ell, d)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmatern_Kux\u001b[39m(x: Tensor, max_ell: \u001b[38;5;28mint\u001b[39m, d: \u001b[38;5;28mint\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor: \n\u001b[0;32m--> 134\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mspherical_harmonics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_ell\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_ell\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43md\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mmT\n",
      "File \u001b[0;32m~/miniconda3/envs/mdgp_requirements_test1/lib/python3.11/site-packages/mdgp/variational/spherical_harmonic_features/utils.py:128\u001b[0m, in \u001b[0;36mspherical_harmonics\u001b[0;34m(x, max_ell, d)\u001b[0m\n\u001b[1;32m    124\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mflatten(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    126\u001b[0m \u001b[38;5;66;03m# SphericalHarmonics works with S^{d-1}, while we work with S^d as in GeometricKernels. \u001b[39;00m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;66;03m# Also SphericalHarmonics uses levels up to `degrees` (exclusive); hence, the +1. \u001b[39;00m\n\u001b[0;32m--> 128\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mSphericalHarmonics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdimension\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43md\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdegrees\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_ell\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# [... * O, N, num_harmonics]\u001b[39;00m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m*\u001b[39mbatch_shape, n, total_num_harmonics(max_ell, d))\n",
      "File \u001b[0;32m~/miniconda3/envs/mdgp_requirements_test1/lib/python3.11/site-packages/spherical_harmonics/spherical_harmonics.py:80\u001b[0m, in \u001b[0;36mSphericalHarmonics.__call__\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;124;03mEvaluates each of the spherical harmonic level in the collection,\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;124;03mand stacks the results.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;124;03m:return: [N, num harmonics in collection]\u001b[39;00m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     76\u001b[0m values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmap\u001b[39m(\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m harmonic: harmonic(x), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mharmonic_levels\n\u001b[1;32m     78\u001b[0m )  \u001b[38;5;66;03m# List of length `max_degree` with Tensor [num_harmonics_degree, N]\u001b[39;00m\n\u001b[0;32m---> 80\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m B\u001b[38;5;241m.\u001b[39mtranspose(B\u001b[38;5;241m.\u001b[39mconcat(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlist\u001b[39m(values), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m))\n",
      "File \u001b[0;32m~/miniconda3/envs/mdgp_requirements_test1/lib/python3.11/site-packages/spherical_harmonics/spherical_harmonics.py:77\u001b[0m, in \u001b[0;36mSphericalHarmonics.__call__.<locals>.<lambda>\u001b[0;34m(harmonic)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     67\u001b[0m     x: B\u001b[38;5;241m.\u001b[39mNumeric,\n\u001b[1;32m     68\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m B\u001b[38;5;241m.\u001b[39mNumeric:\n\u001b[1;32m     69\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;124;03m    Evaluates each of the spherical harmonic level in the collection,\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;124;03m    and stacks the results.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;124;03m    :return: [N, num harmonics in collection]\u001b[39;00m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m     76\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmap\u001b[39m(\n\u001b[0;32m---> 77\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m harmonic: \u001b[43mharmonic\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mharmonic_levels\n\u001b[1;32m     78\u001b[0m     )  \u001b[38;5;66;03m# List of length `max_degree` with Tensor [num_harmonics_degree, N]\u001b[39;00m\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m B\u001b[38;5;241m.\u001b[39mtranspose(B\u001b[38;5;241m.\u001b[39mconcat(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlist\u001b[39m(values), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m))\n",
      "File \u001b[0;32m~/miniconda3/envs/mdgp_requirements_test1/lib/python3.11/site-packages/spherical_harmonics/spherical_harmonics.py:154\u001b[0m, in \u001b[0;36mSphericalHarmonicsLevel.__call__\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;124;03m:param X: M normalised (i.e. unit) D-dimensional vector, [N, D]\u001b[39;00m\n\u001b[1;32m    147\u001b[0m \n\u001b[1;32m    148\u001b[0m \u001b[38;5;124;03m:return: `X` evaluated at the M spherical harmonics in the set.\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;124;03m    [\\phi_m(x_i)], shape [M, N]\u001b[39;00m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    151\u001b[0m VXT \u001b[38;5;241m=\u001b[39m B\u001b[38;5;241m.\u001b[39mmatmul(\n\u001b[1;32m    152\u001b[0m     B\u001b[38;5;241m.\u001b[39mcast(B\u001b[38;5;241m.\u001b[39mdtype(X), from_numpy(X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mV)), X, tr_b\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    153\u001b[0m )  \u001b[38;5;66;03m# [M, N]\u001b[39;00m\n\u001b[0;32m--> 154\u001b[0m zonals \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgegenbauer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mVXT\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# [M, N]\u001b[39;00m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m B\u001b[38;5;241m.\u001b[39mmatmul(B\u001b[38;5;241m.\u001b[39mcast(B\u001b[38;5;241m.\u001b[39mdtype(X), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mL_inv), zonals)\n",
      "File \u001b[0;32m~/miniconda3/envs/mdgp_requirements_test1/lib/python3.11/site-packages/spherical_harmonics/gegenbauer_polynomial.py:157\u001b[0m, in \u001b[0;36mGegenbauerScipyCoefficients.__call__\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    155\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malpha \u001b[38;5;241m*\u001b[39m x\n\u001b[0;32m--> 157\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpolyval\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcoefficients\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/mdgp_requirements_test1/lib/python3.11/site-packages/plum/function.py:399\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kw_args)\u001b[0m\n\u001b[1;32m    397\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw_args):\n\u001b[1;32m    398\u001b[0m     method, return_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_resolve_method_with_cache(args\u001b[38;5;241m=\u001b[39margs)\n\u001b[0;32m--> 399\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _convert(\u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw_args\u001b[49m\u001b[43m)\u001b[49m, return_type)\n",
      "File \u001b[0;32m~/miniconda3/envs/mdgp_requirements_test1/lib/python3.11/site-packages/spherical_harmonics/lab_extras/torch/extras.py:24\u001b[0m, in \u001b[0;36mpolyval\u001b[0;34m(coeffs, x)\u001b[0m\n\u001b[1;32m     22\u001b[0m curVal \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(coeffs) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m---> 24\u001b[0m     curVal \u001b[38;5;241m=\u001b[39m (curVal \u001b[38;5;241m+\u001b[39m coeffs[i]) \u001b[38;5;241m*\u001b[39m x\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m curVal \u001b[38;5;241m+\u001b[39m coeffs[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model, projector = get_model_and_projector(kin8mn, 'sphere')\n",
    "train(kin8mn, model, projector, batch_size, num_epochs=NUM_EPOCHS, lr=LR)\n",
    "evaluate(kin8mn, model, projector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------Reproducing results for power--------------------------\n",
      "\n",
      "-------------------------------------Run 1--------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a76fa18e6e6545d9b6d3a2737f92ec3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLPD: 0.014695136020697464, MSE: 0.05854422073080649\n",
      "-------------------------------------Run 2--------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f4b6af2b279445db789d0438dcc903f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mreproduce_results\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpower\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkin8mn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_x\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[8], line 57\u001b[0m, in \u001b[0;36mreproduce_results\u001b[0;34m(dataset, batch_size, num_runs, num_epochs, lr)\u001b[0m\n\u001b[1;32m     55\u001b[0m torch\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mmanual_seed(run)\n\u001b[1;32m     56\u001b[0m model, projector \u001b[38;5;241m=\u001b[39m get_model_and_projector(dataset)\n\u001b[0;32m---> 57\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprojector\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;66;03m# print(\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;66;03m#     model.covar_module.base_kernel.lengthscale, \u001b[39;00m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;66;03m#     model.covar_module.base_kernel.nu,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;66;03m#     model.variational_strategy._variational_distribution.chol_variational_covar,\u001b[39;00m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;66;03m# )\u001b[39;00m\n\u001b[1;32m     66\u001b[0m run_metrics \u001b[38;5;241m=\u001b[39m evaluate(dataset, model, projector)\n",
      "Cell \u001b[0;32mIn[8], line 25\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(dataset, model, projector, batch_size, num_epochs, lr)\u001b[0m\n\u001b[1;32m     23\u001b[0m epoch_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x_batch, y_batch \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[0;32m---> 25\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprojector\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprojector\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmll\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmll\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m     epoch_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\n\u001b[1;32m     27\u001b[0m losses\u001b[38;5;241m.\u001b[39mappend(epoch_loss)\n",
      "Cell \u001b[0;32mIn[8], line 6\u001b[0m, in \u001b[0;36mtrain_step\u001b[0;34m(x, y, model, projector, optimizer, mll)\u001b[0m\n\u001b[1;32m      4\u001b[0m output \u001b[38;5;241m=\u001b[39m model(x)\n\u001b[1;32m      5\u001b[0m loss \u001b[38;5;241m=\u001b[39m mll(output, y)\n\u001b[0;32m----> 6\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/miniconda3/envs/mdgp_requirements_test1/lib/python3.11/site-packages/torch/_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    491\u001b[0m     )\n\u001b[0;32m--> 492\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/mdgp_requirements_test1/lib/python3.11/site-packages/torch/autograd/__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/mdgp_requirements_test1/lib/python3.11/site-packages/torch/autograd/function.py:276\u001b[0m, in \u001b[0;36mBackwardCFunction.apply\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mBackwardCFunction\u001b[39;00m(_C\u001b[38;5;241m.\u001b[39m_FunctionBase, FunctionCtx, _HookMixin):\n\u001b[0;32m--> 276\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs):\n\u001b[1;32m    277\u001b[0m         \u001b[38;5;66;03m# _forward_cls is defined by derived class\u001b[39;00m\n\u001b[1;32m    278\u001b[0m         \u001b[38;5;66;03m# The user should define either backward or vjp but never both.\u001b[39;00m\n\u001b[1;32m    279\u001b[0m         backward_fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_cls\u001b[38;5;241m.\u001b[39mbackward  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    280\u001b[0m         vjp_fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_cls\u001b[38;5;241m.\u001b[39mvjp  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "reproduce_results(power, num_epochs=1000, batch_size=kin8mn.train_x.size(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------Reproducing results for power--------------------------\n",
      "\n",
      "-------------------------------------Run 1--------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [02:20<00:00,  7.04s/it, ELBO=34]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLPD: 0.018200022938892634, MSE: 0.0604323361222259\n",
      "-------------------------------------Run 2--------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [02:12<00:00,  6.63s/it, ELBO=34]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLPD: 0.020585911675719538, MSE: 0.06111090834631231\n",
      "-------------------------------------Run 3--------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [02:17<00:00,  6.85s/it, ELBO=34]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLPD: 0.029410862008512097, MSE: 0.06202288396624321\n",
      "-------------------------------------Run 4--------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [02:17<00:00,  6.89s/it, ELBO=34]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLPD: 0.011682565872741057, MSE: 0.05958469777710783\n",
      "-------------------------------------Run 5--------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [02:14<00:00,  6.71s/it, ELBO=34.2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLPD: 0.018373846236252843, MSE: 0.06075983045730417\n",
      "----------------------------------Metrics mean----------------------------------\n",
      "nlpd    0.019651\n",
      "mse     0.060782\n",
      "dtype: float64\n",
      "----------------------------------Metrics STD-----------------------------------\n",
      "nlpd    0.006391\n",
      "mse     0.000895\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nlpd</th>\n",
       "      <th>mse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.018200</td>\n",
       "      <td>0.060432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.020586</td>\n",
       "      <td>0.061111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.029411</td>\n",
       "      <td>0.062023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.011683</td>\n",
       "      <td>0.059585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.018374</td>\n",
       "      <td>0.060760</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       nlpd       mse\n",
       "0  0.018200  0.060432\n",
       "1  0.020586  0.061111\n",
       "2  0.029411  0.062023\n",
       "3  0.011683  0.059585\n",
       "4  0.018374  0.060760"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reproduce_results(power, num_epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------Reproducing results for concrete------------------------\n",
      "\n",
      "-------------------------------------Run 1--------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [01:26<00:00,  1.44it/s, ELBO=2.44] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLPD: 0.3623051474366128, MSE: 0.1097215590579564\n",
      "-------------------------------------Run 2--------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [01:32<00:00,  1.35it/s, ELBO=2.46] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLPD: 0.3629351313556932, MSE: 0.10951533423101913\n",
      "-------------------------------------Run 3--------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [01:30<00:00,  1.39it/s, ELBO=2.41] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLPD: 0.3790285364454814, MSE: 0.11759354105563866\n",
      "-------------------------------------Run 4--------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [01:28<00:00,  1.41it/s, ELBO=2.46] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLPD: 0.37304157369488944, MSE: 0.1139838157709856\n",
      "-------------------------------------Run 5--------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [01:28<00:00,  1.41it/s, ELBO=2.41] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLPD: 0.37610820039944604, MSE: 0.11769848257163341\n",
      "----------------------------------Metrics mean----------------------------------\n",
      "nlpd    0.370684\n",
      "mse     0.113703\n",
      "dtype: float64\n",
      "----------------------------------Metrics STD-----------------------------------\n",
      "nlpd    0.007663\n",
      "mse     0.004018\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nlpd</th>\n",
       "      <th>mse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.362305</td>\n",
       "      <td>0.109722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.362935</td>\n",
       "      <td>0.109515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.379029</td>\n",
       "      <td>0.117594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.373042</td>\n",
       "      <td>0.113984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.376108</td>\n",
       "      <td>0.117698</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       nlpd       mse\n",
       "0  0.362305  0.109722\n",
       "1  0.362935  0.109515\n",
       "2  0.379029  0.117594\n",
       "3  0.373042  0.113984\n",
       "4  0.376108  0.117698"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reproduce_results(concrete, num_epochs=125)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mdgp_requirements_test1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
