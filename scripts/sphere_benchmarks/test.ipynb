{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Using numpy backend\n"
     ]
    }
   ],
   "source": [
    "from mdgp.experiments.sphere.experiment import ExperimentConfig\n",
    "\n",
    "ExperimentConfig().to_json(\"../../experiment_tree_configs/sphere/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Using pytorch backend\n",
      "/home/kacperwyrwal/miniconda3/envs/mdgp_uci/lib/python3.11/site-packages/mdgp/samplers/rff_sampler.py:25: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self._num_features = self.compute_features(torch.tensor(self.base_kernel.space.random_point()[None])).shape[-1]\n"
     ]
    }
   ],
   "source": [
    "import geometric_kernels.torch \n",
    "import os \n",
    "os.environ['GEOMSTATS_BACKEND'] = 'pytorch'\n",
    "\n",
    "\n",
    "import torch \n",
    "import gpytorch \n",
    "from mdgp.experiments.sphere.fit.metrics import test_log_likelihood\n",
    "from mdgp.experiments.sphere.fit import evaluate_deep\n",
    "from mdgp.experiments.sphere.data import SphereDataset\n",
    "from mdgp.experiments.sphere.model import ModelArguments\n",
    "from mdgp.experiments.sphere.fit import FitArguments\n",
    "from gpytorch.metrics import negative_log_predictive_density\n",
    "\n",
    "\n",
    "\n",
    "torch.set_default_dtype(torch.float64)\n",
    "\n",
    "\n",
    "dataset = SphereDataset(name='singular', num_train=400, num_test=2000)\n",
    "model_args = ModelArguments(num_layers=1, model_name='input_geometric', learn_inducing_locations=True, geometric_optimizer=False)\n",
    "model = model_args.get_model(dataset)\n",
    "fit_args = FitArguments(num_epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using RiemannianAdam\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46a735e2518f479688b2fce1d8e15b00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epochs:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[1.4463814033111848,\n",
       " 1.4091384155556022,\n",
       " 1.374715684714166,\n",
       " 1.3427098302384455,\n",
       " 1.312879834437156,\n",
       " 1.2851181226564399,\n",
       " 1.2593685349582724,\n",
       " 1.2355605657432225,\n",
       " 1.2135947441422232,\n",
       " 1.1933539629727996,\n",
       " 1.1747226116036982,\n",
       " 1.1575814779228393,\n",
       " 1.1417909944948272,\n",
       " 1.127188299089953,\n",
       " 1.113604538881677,\n",
       " 1.1008878745768447,\n",
       " 1.0889134346582876,\n",
       " 1.0775789268463412,\n",
       " 1.0667991285238703,\n",
       " 1.056506249254816,\n",
       " 1.0466490249067746,\n",
       " 1.0371866622209613,\n",
       " 1.0280826197632675,\n",
       " 1.0193030016455262,\n",
       " 1.010818856541647,\n",
       " 1.0026069213193198,\n",
       " 0.994646626712022,\n",
       " 0.986917397289712,\n",
       " 0.9793996276880064,\n",
       " 0.9720768460993268,\n",
       " 0.9649351578222074,\n",
       " 0.9579608265885782,\n",
       " 0.951139536044199,\n",
       " 0.9444581546207885,\n",
       " 0.9379058311322023,\n",
       " 0.9314725325225803,\n",
       " 0.9251476583233282,\n",
       " 0.9189210454516026,\n",
       " 0.9127843749153929,\n",
       " 0.9067305185138783,\n",
       " 0.9007521615912978,\n",
       " 0.8948421665844772,\n",
       " 0.8889948074612029,\n",
       " 0.8832054190751355,\n",
       " 0.8774692126753016,\n",
       " 0.8717815353089271,\n",
       " 0.8661388037565223,\n",
       " 0.8605380811936689,\n",
       " 0.8549761615397424,\n",
       " 0.8494499367175787,\n",
       " 0.8439570079616221,\n",
       " 0.8384951130312605,\n",
       " 0.8330616630214729,\n",
       " 0.8276543427085695,\n",
       " 0.8222713160538969,\n",
       " 0.8169106116376188,\n",
       " 0.8115701501996864,\n",
       " 0.8062482583861874,\n",
       " 0.8009434042615627,\n",
       " 0.7956538655335578,\n",
       " 0.7903781495107897,\n",
       " 0.7851150952337256,\n",
       " 0.77986345837612,\n",
       " 0.7746220524550926,\n",
       " 0.7693900088722493,\n",
       " 0.7641664749862594,\n",
       " 0.7589505833443867,\n",
       " 0.753741714791421,\n",
       " 0.7485392937892515,\n",
       " 0.7433426720541095,\n",
       " 0.7381513460823357,\n",
       " 0.7329648267975316,\n",
       " 0.7277825416783484,\n",
       " 0.7226040432515738,\n",
       " 0.71742891539231,\n",
       " 0.7122566859840453,\n",
       " 0.7070869893356118,\n",
       " 0.7019194805859102,\n",
       " 0.6967538034843919,\n",
       " 0.6915897166816976,\n",
       " 0.6864269876497131,\n",
       " 0.6812653964238978,\n",
       " 0.6761048045126063,\n",
       " 0.6709450522095257,\n",
       " 0.6657860141580595,\n",
       " 0.6606276104362464,\n",
       " 0.6554697334334713,\n",
       " 0.650312315380104,\n",
       " 0.6451552866392559,\n",
       " 0.6399985734503275,\n",
       " 0.6348421418557433,\n",
       " 0.6296859382417515,\n",
       " 0.6245299280379631,\n",
       " 0.6193740817950966,\n",
       " 0.6142183675696107,\n",
       " 0.6090627856750619,\n",
       " 0.6039073279213355,\n",
       " 0.5987520054924077,\n",
       " 0.5935968322502689,\n",
       " 0.5884418297170247,\n",
       " 0.5832870388687205,\n",
       " 0.5781324959897682,\n",
       " 0.572978252632463,\n",
       " 0.5678243551371502,\n",
       " 0.5626708634362096,\n",
       " 0.5575178382410324,\n",
       " 0.5523653420444968,\n",
       " 0.5472134390756057,\n",
       " 0.5420621929693373,\n",
       " 0.5369116745561826,\n",
       " 0.5317619500974065,\n",
       " 0.5266130899158493,\n",
       " 0.5214651606256155,\n",
       " 0.516318235680056,\n",
       " 0.5111723846401277,\n",
       " 0.506027679364586,\n",
       " 0.5008841881035756,\n",
       " 0.4957419834271496,\n",
       " 0.4906011348307957,\n",
       " 0.48546171267628013,\n",
       " 0.480323784501106,\n",
       " 0.47518742094366617,\n",
       " 0.4700526902235601,\n",
       " 0.4649196608416012,\n",
       " 0.4597883995730686,\n",
       " 0.45465897508895187,\n",
       " 0.44953145424492025,\n",
       " 0.4444059031873716,\n",
       " 0.4392823878761144,\n",
       " 0.43416097406442217,\n",
       " 0.42904172645594735,\n",
       " 0.4239247080578973,\n",
       " 0.4188099825265262,\n",
       " 0.4136976118039858,\n",
       " 0.40858765661856633,\n",
       " 0.40348017693428606,\n",
       " 0.3983752318260706,\n",
       " 0.39327287898842866,\n",
       " 0.38817317463549983,\n",
       " 0.3830761746575406,\n",
       " 0.3779819334359925,\n",
       " 0.3728905039321126,\n",
       " 0.3678019388477185,\n",
       " 0.3627162895502564,\n",
       " 0.35763360617903633,\n",
       " 0.35255393857724265,\n",
       " 0.34747733548865267,\n",
       " 0.3424038446213749,\n",
       " 0.33733351344305357,\n",
       " 0.3322663885296031,\n",
       " 0.32720251565533803,\n",
       " 0.32214194046407346,\n",
       " 0.3170847078867139,\n",
       " 0.3120308623458721,\n",
       " 0.3069804481498425,\n",
       " 0.3019335090294507,\n",
       " 0.29689008854584065,\n",
       " 0.29185023002764526,\n",
       " 0.2868139763957075,\n",
       " 0.28178137063266867,\n",
       " 0.2767524553751294,\n",
       " 0.27172727318944756,\n",
       " 0.26670586658691975,\n",
       " 0.26168827786272597,\n",
       " 0.256674549467802,\n",
       " 0.2516647236250199,\n",
       " 0.24665884277241718,\n",
       " 0.24165694920032305,\n",
       " 0.23665908543016498,\n",
       " 0.23166529391572946,\n",
       " 0.22667561739494707,\n",
       " 0.22169009855163352,\n",
       " 0.21670878053147394,\n",
       " 0.21173170639014,\n",
       " 0.2067589205333892,\n",
       " 0.20179046866191808,\n",
       " 0.19682640814582733,\n",
       " 0.19186683778304423,\n",
       " 0.1869120845279699,\n",
       " 0.18196356702404554,\n",
       " 0.1770273324492247,\n",
       " 0.1721123347777358,\n",
       " 0.1671755958550487,\n",
       " 0.162205173631545,\n",
       " 0.15730030365462894,\n",
       " 0.15237513022435833,\n",
       " 0.1474378471132852,\n",
       " 0.14254776966474325,\n",
       " 0.13761908562843142,\n",
       " 0.13272407743422537,\n",
       " 0.12782729559380016,\n",
       " 0.12292282838165178,\n",
       " 0.11804861829893765,\n",
       " 0.1131521920259039,\n",
       " 0.10828215065176586,\n",
       " 0.10340790179736889,\n",
       " 0.09853586631067883,\n",
       " 0.0936819631695805,\n",
       " 0.08881693681647862,\n",
       " 0.08397142495647944,\n",
       " 0.07912463873766967,\n",
       " 0.07428146623701508,\n",
       " 0.06945247526706998,\n",
       " 0.06461872846504696,\n",
       " 0.05979784862981109,\n",
       " 0.054981858308235806,\n",
       " 0.050166777459994386,\n",
       " 0.0453645517402764,\n",
       " 0.04056367434792558,\n",
       " 0.0357683104465131,\n",
       " 0.03098327380008049,\n",
       " 0.026199884460946378,\n",
       " 0.021423592512890374,\n",
       " 0.016656123499458577,\n",
       " 0.011891512060577444,\n",
       " 0.007133836225203247,\n",
       " 0.0023846526453552,\n",
       " -0.002360386953355162,\n",
       " -0.007099382329542846,\n",
       " -0.011829942118075984,\n",
       " -0.016554755243211854,\n",
       " -0.02127433996980298,\n",
       " -0.025986307986750078,\n",
       " -0.03069086067553952,\n",
       " -0.035389681641661425,\n",
       " -0.04008235393436591,\n",
       " -0.044767545457729166,\n",
       " -0.04944537321289476,\n",
       " -0.054116741902625345,\n",
       " -0.05878176910970427,\n",
       " -0.06343982470240983,\n",
       " -0.06809046490941491,\n",
       " -0.07273378383970391,\n",
       " -0.07737006984403477,\n",
       " -0.0819994535752007,\n",
       " -0.08662186480702821,\n",
       " -0.09123714758475035,\n",
       " -0.09584517252072013,\n",
       " -0.10044586420217416,\n",
       " -0.10503918576759057,\n",
       " -0.10962511208356829,\n",
       " -0.1142036113522225,\n",
       " -0.11877463114676293,\n",
       " -0.12333806483351875,\n",
       " -0.12789364347116924,\n",
       " -0.13244055783016012,\n",
       " -0.13697614872465308,\n",
       " -0.1414922720535451,\n",
       " -0.14597203293444297,\n",
       " -0.1504349946012105,\n",
       " -0.15499147403695182,\n",
       " -0.15957384531849006,\n",
       " -0.1640125920124357,\n",
       " -0.1684858921375235,\n",
       " -0.1730334101257382,\n",
       " -0.1774656854411359,\n",
       " -0.18192174952166748,\n",
       " -0.18642590299008632,\n",
       " -0.190836715530919,\n",
       " -0.1952843800461169,\n",
       " -0.1997454042694811,\n",
       " -0.20413749690517907,\n",
       " -0.2085709609885707,\n",
       " -0.21299258339906207,\n",
       " -0.21736927276932536,\n",
       " -0.221780860227695,\n",
       " -0.2261697688838073,\n",
       " -0.23053017925649327,\n",
       " -0.23491548419931516,\n",
       " -0.239277777943314,\n",
       " -0.24361896412231682,\n",
       " -0.247976570327359,\n",
       " -0.2523161719677709,\n",
       " -0.25663589424602967,\n",
       " -0.26096520162241205,\n",
       " -0.2652840045877299,\n",
       " -0.26958225488165,\n",
       " -0.2738823741099549,\n",
       " -0.2781798263150508,\n",
       " -0.2824590813546545,\n",
       " -0.2867304633603159,\n",
       " -0.2910024613710461,\n",
       " -0.2952646497520401,\n",
       " -0.2995126865256823,\n",
       " -0.3037551206776634,\n",
       " -0.30799490849770805,\n",
       " -0.3122257623892247,\n",
       " -0.3164447444812216,\n",
       " -0.32065578969388986,\n",
       " -0.3248622163003762,\n",
       " -0.32906268616042095,\n",
       " -0.3332542097205527,\n",
       " -0.3374359800815436,\n",
       " -0.3416093282997982,\n",
       " -0.3457757018167909,\n",
       " -0.3499356052748425,\n",
       " -0.3540886476788236,\n",
       " -0.3582342588379968,\n",
       " -0.36237200578604556,\n",
       " -0.3665017773154832,\n",
       " -0.37062358980455956,\n",
       " -0.3747375296247879,\n",
       " -0.37884364013858335,\n",
       " -0.3829419382142135,\n",
       " -0.3870324044900402,\n",
       " -0.391114995299691,\n",
       " -0.39518963547566727,\n",
       " -0.39925614559573736,\n",
       " -0.40331402239848824,\n",
       " -0.40736140047544794,\n",
       " -0.4113909755479668,\n",
       " -0.41537401016042885,\n",
       " -0.41922532616399016,\n",
       " -0.42296843255452954,\n",
       " -0.42717621263031147,\n",
       " -0.43148942889053377,\n",
       " -0.4351629915298121,\n",
       " -0.4393027598426739,\n",
       " -0.44338950778893826,\n",
       " -0.44714090995633493,\n",
       " -0.4513407739469811,\n",
       " -0.4551489563761023,\n",
       " -0.4591288873665301,\n",
       " -0.4631371336331565,\n",
       " -0.46693025211638994,\n",
       " -0.4709898029699853,\n",
       " -0.4747858912298809,\n",
       " -0.47873192618292676,\n",
       " -0.4826331937073235,\n",
       " -0.486444926170405,\n",
       " -0.49039664194164495,\n",
       " -0.4941766609955861,\n",
       " -0.4980648424850342,\n",
       " -0.501901527032264,\n",
       " -0.5056899357596182,\n",
       " -0.5095586995592962,\n",
       " -0.5133184718920388,\n",
       " -0.5171320747884175,\n",
       " -0.5209292502114025,\n",
       " -0.5246704679372635,\n",
       " -0.528467453642867,\n",
       " -0.5322058771791769,\n",
       " -0.5359388197176578,\n",
       " -0.5396944063136913,\n",
       " -0.5433966375438323,\n",
       " -0.5471113313939197,\n",
       " -0.5508257475820304,\n",
       " -0.5544991943733144,\n",
       " -0.5581831843911447,\n",
       " -0.5618617915991441,\n",
       " -0.5655068163415574,\n",
       " -0.5691557012969627,\n",
       " -0.5728014196599766,\n",
       " -0.5764178063150781,\n",
       " -0.5800296397495546,\n",
       " -0.5836414210193038,\n",
       " -0.587231068906857,\n",
       " -0.5908061742950113,\n",
       " -0.5943794158553584,\n",
       " -0.5979419167069921,\n",
       " -0.6014851333941801,\n",
       " -0.605018886022097,\n",
       " -0.6085467564807692,\n",
       " -0.612063065413901,\n",
       " -0.6155639810345279,\n",
       " -0.6190511056060858,\n",
       " -0.6225300569699208,\n",
       " -0.6259988192282759,\n",
       " -0.6294567961526594,\n",
       " -0.6329027442245412,\n",
       " -0.6363313094877712,\n",
       " -0.6397524637945677,\n",
       " -0.6431621552098168,\n",
       " -0.646559889956735,\n",
       " -0.6499482247397028,\n",
       " -0.6533223948287802,\n",
       " -0.6566864269346101,\n",
       " -0.6600367208408262,\n",
       " -0.6633758594828957,\n",
       " -0.666702296860958,\n",
       " -0.670015844730195,\n",
       " -0.673316013023421,\n",
       " -0.6766053152523279,\n",
       " -0.6798879047677494,\n",
       " -0.6831508945897632,\n",
       " -0.6864000677652817,\n",
       " -0.6896295390161366,\n",
       " -0.6928022471300146,\n",
       " -0.6958277210315594,\n",
       " -0.698476438696947,\n",
       " -0.7011186863288826,\n",
       " -0.7050788984256728,\n",
       " -0.7087728064118379,\n",
       " -0.7111241955266834,\n",
       " -0.7147649511374872,\n",
       " -0.7181059265114502,\n",
       " -0.7206977237206966,\n",
       " -0.7243874652294874,\n",
       " -0.7272070368283721,\n",
       " -0.7302609879149855,\n",
       " -0.7336447452110485,\n",
       " -0.736325753119889,\n",
       " -0.7396786742573636,\n",
       " -0.7425995626688914,\n",
       " -0.7455391462528627,\n",
       " -0.7487607723104525,\n",
       " -0.7515168910853713,\n",
       " -0.7546610246736373,\n",
       " -0.7575962269526766,\n",
       " -0.7604538482137857,\n",
       " -0.7635468590501283,\n",
       " -0.7663334865901963,\n",
       " -0.7692905820963788,\n",
       " -0.772232201140306,\n",
       " -0.7750234550774584,\n",
       " -0.777983887488799,\n",
       " -0.7808029047317104,\n",
       " -0.7836133513242027,\n",
       " -0.786514879491642,\n",
       " -0.78927035470047,\n",
       " -0.792076354780835,\n",
       " -0.7949138174114003,\n",
       " -0.7976349882145306,\n",
       " -0.8004090383273678,\n",
       " -0.8031902972380415,\n",
       " -0.8058853816552857,\n",
       " -0.8086128770309726,\n",
       " -0.811347975497217,\n",
       " -0.814014933954166,\n",
       " -0.8166882515163889,\n",
       " -0.8193825409817335,\n",
       " -0.8220261072858059,\n",
       " -0.8246479262599531,\n",
       " -0.8272886406782117,\n",
       " -0.8299058428611747,\n",
       " -0.8324873799204886,\n",
       " -0.835066449177398,\n",
       " -0.8376473456759197,\n",
       " -0.840194831649845,\n",
       " -0.8426865988519904,\n",
       " -0.8451374903858857,\n",
       " -0.8476202521041852,\n",
       " -0.8502567948622722,\n",
       " -0.8527591148379685,\n",
       " -0.8551395016545292,\n",
       " -0.8576981678546897,\n",
       " -0.8601356632093055,\n",
       " -0.8625317134601749,\n",
       " -0.8650285182769124,\n",
       " -0.8673779207193049,\n",
       " -0.8697889822245564,\n",
       " -0.8722007256129094,\n",
       " -0.8745196932078485,\n",
       " -0.8769207322176484,\n",
       " -0.8792414016317756,\n",
       " -0.8815439215242463,\n",
       " -0.8838936728112806,\n",
       " -0.8861730623823727,\n",
       " -0.8884632403167704,\n",
       " -0.8907169733191598,\n",
       " -0.8929438943828965,\n",
       " -0.8952362604596622,\n",
       " -0.8974394425393543,\n",
       " -0.899575155852993,\n",
       " -0.9017081732189978,\n",
       " -0.9036047507717815,\n",
       " -0.905158417241888,\n",
       " -0.9067277974375487,\n",
       " -0.9093722265996862,\n",
       " -0.9125753060001671,\n",
       " -0.9144399401678796,\n",
       " -0.9158528035535941,\n",
       " -0.9185289996204082,\n",
       " -0.9210175176230544,\n",
       " -0.922458221527615,\n",
       " -0.9246369734202989,\n",
       " -0.9271646209408837,\n",
       " -0.9287855013411044,\n",
       " -0.9307264287375359,\n",
       " -0.9331387421419045,\n",
       " -0.9348891907329004,\n",
       " -0.9367008158517983,\n",
       " -0.9389572424759252,\n",
       " -0.9408093689421895,\n",
       " -0.9425619586657665,\n",
       " -0.9446782973752736,\n",
       " -0.9465824721205468,\n",
       " -0.9482849156439063,\n",
       " -0.9502824470884145,\n",
       " -0.9521927657218778,\n",
       " -0.9539068686573223,\n",
       " -0.9558023610918603,\n",
       " -0.9577039279701898,\n",
       " -0.9594261951351439,\n",
       " -0.9611641044835384,\n",
       " -0.9630100789137763,\n",
       " -0.9647570897072614,\n",
       " -0.9664336904652583,\n",
       " -0.9682134774603149,\n",
       " -0.9700107113380116,\n",
       " -0.9716906874849499,\n",
       " -0.9732951831330041,\n",
       " -0.9749564473834855,\n",
       " -0.9766053388184248,\n",
       " -0.9781591287588313,\n",
       " -0.9797782003371125,\n",
       " -0.9815278104697966,\n",
       " -0.9832379627561881,\n",
       " -0.9847761819490864,\n",
       " -0.9862881998660751,\n",
       " -0.9879801143462122,\n",
       " -0.989598902277492,\n",
       " -0.9910680243037591,\n",
       " -0.9926590865506834,\n",
       " -0.994222912086203,\n",
       " -0.9956827460311356,\n",
       " -0.9971867370028111,\n",
       " -0.9986935034646789,\n",
       " -1.0001482614383643,\n",
       " -1.0015436708462224,\n",
       " -1.00296032363973,\n",
       " -1.0044613046889266,\n",
       " -1.0059701672321564,\n",
       " -1.0074403592655519,\n",
       " -1.008827951883043,\n",
       " -1.0101629775640801,\n",
       " -1.0115743466991067,\n",
       " -1.0130311634965712,\n",
       " -1.0144120763678084,\n",
       " -1.0157339026182248,\n",
       " -1.0170641809140746,\n",
       " -1.0184192925756617,\n",
       " -1.0197659842366016,\n",
       " -1.021066263708977,\n",
       " -1.0223404799560516,\n",
       " -1.0235726873980544,\n",
       " -1.0247165782864003,\n",
       " -1.0257543224766619,\n",
       " -1.0266913728481746,\n",
       " -1.027437822847936,\n",
       " -1.0278428540593059,\n",
       " -1.0287403178140047,\n",
       " -1.0311960402684155,\n",
       " -1.033462038537301,\n",
       " -1.033860045193097,\n",
       " -1.0344058713029893,\n",
       " -1.0364830286088977,\n",
       " -1.037954826918786,\n",
       " -1.0383470884953074,\n",
       " -1.039685172142485,\n",
       " -1.041438521486132,\n",
       " -1.0421201395662485,\n",
       " -1.0429337793281301,\n",
       " -1.0445224541304392,\n",
       " -1.0455530161996798,\n",
       " -1.0462266384070238,\n",
       " -1.0475444297639733,\n",
       " -1.048787045807103,\n",
       " -1.0495610015755266,\n",
       " -1.0506759125890928,\n",
       " -1.0519058885034585,\n",
       " -1.0526515263810463,\n",
       " -1.053468529291123,\n",
       " -1.0546070084467087,\n",
       " -1.055494056152578,\n",
       " -1.0562206522345057,\n",
       " -1.0572660682758552,\n",
       " -1.058428385446864,\n",
       " -1.059341079513774,\n",
       " -1.0601673438510868,\n",
       " -1.0611140778829147,\n",
       " -1.0620779118121941,\n",
       " -1.0629987557403675,\n",
       " -1.0639339820802762,\n",
       " -1.064824359041818,\n",
       " -1.065609344986325,\n",
       " -1.0664214292637233,\n",
       " -1.0673297006565925,\n",
       " -1.0681823084201703,\n",
       " -1.06891014433315,\n",
       " -1.0696622287357425,\n",
       " -1.0705089145805968,\n",
       " -1.0713096226823833,\n",
       " -1.0720056009312808,\n",
       " -1.072745144000046,\n",
       " -1.0736271568802584,\n",
       " -1.0744277231279773,\n",
       " -1.0750580440292326,\n",
       " -1.0758148877120337,\n",
       " -1.0766234756155089,\n",
       " -1.0772380774072077,\n",
       " -1.0778975959046444,\n",
       " -1.0786808929441876,\n",
       " -1.0793846818091277,\n",
       " -1.0800520270832552,\n",
       " -1.080742321666722,\n",
       " -1.0814375911255685,\n",
       " -1.0821770663911499,\n",
       " -1.0828728793925235,\n",
       " -1.0834514677950062,\n",
       " -1.0840741799819669,\n",
       " -1.0847954294926294,\n",
       " -1.0854785323592058,\n",
       " -1.0861032443573808,\n",
       " -1.0866907705441915,\n",
       " -1.0872399831351933,\n",
       " -1.087809727660091,\n",
       " -1.0884319721303024,\n",
       " -1.0890466103928276,\n",
       " -1.0896170896416013,\n",
       " -1.0901752077865163,\n",
       " -1.0907562940275202,\n",
       " -1.091349087093573,\n",
       " -1.0918815953938388,\n",
       " -1.0923544503842466,\n",
       " -1.0928725195533766,\n",
       " -1.093438697748248,\n",
       " -1.0939828511472685,\n",
       " -1.0945026705710912,\n",
       " -1.0950042771916475,\n",
       " -1.0954601102758283,\n",
       " -1.0958923885231038,\n",
       " -1.0963563428759122,\n",
       " -1.0968467583765134,\n",
       " -1.0972847425234218,\n",
       " -1.0976199468891419,\n",
       " -1.0979204296915461,\n",
       " -1.0983039152452354,\n",
       " -1.0986716840539257,\n",
       " -1.0988657609032206,\n",
       " -1.0990818368905324,\n",
       " -1.0996046495416556,\n",
       " -1.1003653716542001,\n",
       " -1.1011677795667563,\n",
       " -1.1018058693244488,\n",
       " -1.1020878990966743,\n",
       " -1.1021827204079777,\n",
       " -1.102552929805164,\n",
       " -1.1031921526413464,\n",
       " -1.1036477708726966,\n",
       " -1.1038581679553854,\n",
       " -1.1041264594600235,\n",
       " -1.1045682392821112,\n",
       " -1.1050895177541753,\n",
       " -1.105546803080697,\n",
       " -1.1058798186456924,\n",
       " -1.106176016221426,\n",
       " -1.1064510162451662,\n",
       " -1.10665516764392,\n",
       " -1.1069419191113519,\n",
       " -1.1074611956277003,\n",
       " -1.1079241845692405,\n",
       " -1.108134905392046,\n",
       " -1.1084151554124335,\n",
       " -1.1089018076647046,\n",
       " -1.109285110510655,\n",
       " -1.1094731213952047,\n",
       " -1.1097442703578688,\n",
       " -1.1101214866115432,\n",
       " -1.1104134543358162,\n",
       " -1.1107107589626124,\n",
       " -1.111084903770378,\n",
       " -1.111359641089281,\n",
       " -1.1115442619723486,\n",
       " -1.1118053146058782,\n",
       " -1.1121050971648503,\n",
       " -1.1123910189032526,\n",
       " -1.112724494546574,\n",
       " -1.1130370738881141,\n",
       " -1.1132405325692245,\n",
       " -1.1134193697502752,\n",
       " -1.1136456101292767,\n",
       " -1.1138923759551027,\n",
       " -1.1141491964378765,\n",
       " -1.1143864370856273,\n",
       " -1.1145409949813345,\n",
       " -1.1146627870612418,\n",
       " -1.114883147649798,\n",
       " -1.115188807059419,\n",
       " -1.115474070875947,\n",
       " -1.1157124303857957,\n",
       " -1.1159123355013028,\n",
       " -1.1160766901931034,\n",
       " -1.1163021494012386,\n",
       " -1.1166167860723886,\n",
       " -1.1168550592450588,\n",
       " -1.1169760825596424,\n",
       " -1.1171358170253511,\n",
       " -1.1173465218139997,\n",
       " -1.1174946262392471,\n",
       " -1.1175974011859475,\n",
       " -1.1177350386464897,\n",
       " -1.117946029443812,\n",
       " -1.1182301699870092,\n",
       " -1.1184912388829966,\n",
       " -1.1186433406808391,\n",
       " -1.118745346001265,\n",
       " -1.118887376236496,\n",
       " -1.1190673331284915,\n",
       " -1.1192373489991179,\n",
       " -1.1193897202127798,\n",
       " -1.119544245635974,\n",
       " -1.1197049896519888,\n",
       " -1.119852326298667,\n",
       " -1.1199878811972632,\n",
       " -1.120148673050645,\n",
       " -1.1203302328890394,\n",
       " -1.1204577123786836,\n",
       " -1.120489638417582,\n",
       " -1.1204858945641667,\n",
       " -1.1205016898224402,\n",
       " -1.1205143199840932,\n",
       " -1.1205378849418393,\n",
       " -1.1206691357881295,\n",
       " -1.1209854233132033,\n",
       " -1.121402263403712,\n",
       " -1.1217467449498104,\n",
       " -1.1219221354133424,\n",
       " -1.1219591823776098,\n",
       " -1.1219502080347852,\n",
       " -1.1220080480916443,\n",
       " -1.1222107232753082,\n",
       " -1.1224993663524523,\n",
       " -1.1227204174825764,\n",
       " -1.1228073258500004,\n",
       " -1.1228423870540891,\n",
       " -1.1229353852974315,\n",
       " -1.1231125510197584,\n",
       " -1.1233188185074572,\n",
       " -1.1234763773521352,\n",
       " -1.1235621273456058,\n",
       " -1.1236309335568504,\n",
       " -1.1237388735014286,\n",
       " -1.1238789826142999,\n",
       " -1.1240137601998987,\n",
       " -1.1241217172867803,\n",
       " -1.1241973539547307,\n",
       " -1.1242554351037397,\n",
       " -1.1243336498285594,\n",
       " -1.1244614669446795,\n",
       " -1.124622806436953,\n",
       " -1.1247599138260538,\n",
       " -1.1248396509188614,\n",
       " -1.1248946522754923,\n",
       " -1.1249809633246899,\n",
       " -1.125103907814244,\n",
       " -1.125218095696196,\n",
       " -1.1253054729352252,\n",
       " -1.1253944660984145,\n",
       " -1.1255015484546143,\n",
       " -1.125603935084446,\n",
       " -1.1256811725167175,\n",
       " -1.125753313432119,\n",
       " -1.125851441429267,\n",
       " -1.1259619706939232,\n",
       " -1.1260511265264677,\n",
       " -1.1261279466051994,\n",
       " -1.126219281144058,\n",
       " -1.1263124839488627,\n",
       " -1.1263797781348641,\n",
       " -1.1264394773904731,\n",
       " -1.1265242636204098,\n",
       " -1.1266219353504088,\n",
       " -1.126708346644347,\n",
       " -1.1267962664482287,\n",
       " -1.1268977728277143,\n",
       " -1.1269918799433951,\n",
       " -1.1270650578643358,\n",
       " -1.1271317691823803,\n",
       " -1.1272040090724638,\n",
       " -1.1272802751077435,\n",
       " -1.1273590636404396,\n",
       " -1.1274379224927706,\n",
       " -1.127512992119734,\n",
       " -1.1275868016700075,\n",
       " -1.1276614969468088,\n",
       " -1.1277355122332484,\n",
       " -1.1278142646574465,\n",
       " -1.127903748437483,\n",
       " -1.1279953760010524,\n",
       " -1.1280759989276443,\n",
       " -1.128147262004459,\n",
       " -1.1282174410396808,\n",
       " -1.1282849937435817,\n",
       " -1.1283451957207469,\n",
       " -1.1284015483597913,\n",
       " -1.1284592422220425,\n",
       " -1.1285186424240472,\n",
       " -1.1285805527081303,\n",
       " -1.1286495143373034,\n",
       " -1.128727221176289,\n",
       " -1.128808883891303,\n",
       " -1.1288868635138531,\n",
       " -1.1289571675894436,\n",
       " -1.1290218315466145,\n",
       " -1.1290866906165424,\n",
       " -1.1291565293216053,\n",
       " -1.1292327577089605,\n",
       " -1.129312598754414,\n",
       " -1.1293901152076538,\n",
       " -1.1294602062486847,\n",
       " -1.1295231764138818,\n",
       " -1.129584410641474,\n",
       " -1.1296483270112756,\n",
       " -1.1297135737524084,\n",
       " -1.129775539849966,\n",
       " -1.1298325958780522,\n",
       " -1.1298895108687035,\n",
       " -1.129952967274262,\n",
       " -1.130022628312485,\n",
       " -1.1300920366591565,\n",
       " -1.1301591712188983,\n",
       " -1.1302286209473738,\n",
       " -1.1303030851984317,\n",
       " -1.1303775051830314,\n",
       " -1.1304428498285735,\n",
       " -1.1304980481885254,\n",
       " -1.1305536861502516,\n",
       " -1.130619747563021,\n",
       " -1.1306931380773158,\n",
       " -1.1307619005008902,\n",
       " -1.1308207950850748,\n",
       " -1.1308763080913025,\n",
       " -1.130936410160112,\n",
       " -1.1310011722161468,\n",
       " -1.1310654840163785,\n",
       " -1.1311270137704554,\n",
       " -1.1311875186006448,\n",
       " -1.1312482832738022,\n",
       " -1.1313082290485725,\n",
       " -1.1313668103171857,\n",
       " -1.131425630908807,\n",
       " -1.131486206294688,\n",
       " -1.1315476702968983,\n",
       " -1.1316076167574411,\n",
       " -1.1316648714820785,\n",
       " -1.1317204938294123,\n",
       " -1.1317756259440068,\n",
       " -1.1318297405983233,\n",
       " -1.131881963300015,\n",
       " -1.1319336910364257,\n",
       " -1.131989342713453,\n",
       " -1.132052737626115,\n",
       " -1.1321221476432064,\n",
       " -1.1321903146464323,\n",
       " -1.1322513145141342,\n",
       " -1.1323058694540302,\n",
       " -1.132359778668962,\n",
       " -1.1324176720315229,\n",
       " -1.1324782557122328,\n",
       " -1.1325368543876686,\n",
       " -1.1325917505275593,\n",
       " -1.1326459175302859,\n",
       " -1.1327029941981206,\n",
       " -1.132762584213796,\n",
       " -1.1328206781178813,\n",
       " -1.1328752848506145,\n",
       " -1.1329289708920764,\n",
       " -1.1329849916297483,\n",
       " -1.1330429616168167,\n",
       " -1.133099553980037,\n",
       " -1.1331531119517386,\n",
       " -1.1332057361626338,\n",
       " -1.1332601288168753,\n",
       " -1.1333160734634367,\n",
       " -1.1333713405316093,\n",
       " -1.1334249782039643,\n",
       " -1.1334781913904215,\n",
       " -1.1335318834624983,\n",
       " -1.1335851111303286,\n",
       " -1.133636475035868,\n",
       " -1.1336862569150024,\n",
       " -1.1337359960457378,\n",
       " -1.1337866524313447,\n",
       " -1.1338379292539411,\n",
       " -1.1338896183550093,\n",
       " -1.1339421904656914,\n",
       " -1.1339961989630905,\n",
       " -1.1340513292394732,\n",
       " -1.1341069385686164,\n",
       " -1.134162914429156,\n",
       " -1.13421984449401,\n",
       " -1.134278163426835,\n",
       " -1.1343377146332567,\n",
       " -1.1343979193693023,\n",
       " -1.134458320781966,\n",
       " -1.1345185108485467,\n",
       " -1.1345779089783274,\n",
       " -1.134635846215606,\n",
       " -1.134691930739435,\n",
       " -1.134746331003829,\n",
       " -1.134799505600167,\n",
       " -1.1348518918437283,\n",
       " -1.134903813820686,\n",
       " -1.1349555291698086,\n",
       " -1.1350072974346523,\n",
       " -1.135059200338928,\n",
       " -1.1351112353858,\n",
       " -1.1351633318511767,\n",
       " -1.1352155791813934,\n",
       " -1.1352680505189496,\n",
       " -1.1353207868779707,\n",
       " -1.1353736351159325,\n",
       " -1.1354264477241458,\n",
       " -1.1354791110298406,\n",
       " -1.1355316644338416,\n",
       " -1.1355841480645126,\n",
       " -1.1356365963775077,\n",
       " -1.1356889470201432,\n",
       " -1.135741111321105,\n",
       " -1.1357929878619641,\n",
       " -1.1358445494628726,\n",
       " -1.1358958427831851,\n",
       " -1.135946970461339,\n",
       " -1.1359980277444834,\n",
       " -1.1360490365583549,\n",
       " -1.1360999665316927,\n",
       " -1.1361507744396662,\n",
       " -1.1362014896140917,\n",
       " -1.136252171396506,\n",
       " -1.1363028888501425,\n",
       " -1.1363536337606484,\n",
       " -1.1364043542415465,\n",
       " -1.136454948882423,\n",
       " -1.1365053609734783,\n",
       " -1.136555565551229,\n",
       " -1.136605610719161,\n",
       " -1.136655549369573,\n",
       " -1.1367054502972234,\n",
       " -1.1367553385385571,\n",
       " -1.1368052241483233,\n",
       " -1.1368550736788545,\n",
       " -1.1369048514910578,\n",
       " -1.136954500603744,\n",
       " -1.1370039904818197,\n",
       " -1.137053300490105,\n",
       " -1.1371024497438955,\n",
       " -1.1371514552003406,\n",
       " -1.1372003471038028,\n",
       " -1.1372491435491654,\n",
       " -1.1372978896617665,\n",
       " -1.1373466476858671,\n",
       " -1.1373954738262702,\n",
       " -1.1374443021709655,\n",
       " -1.1374929552922368,\n",
       " -1.1375412954272182,\n",
       " -1.1375893825985846,\n",
       " -1.1376373913500344,\n",
       " -1.1376854772153806,\n",
       " -1.1377336446718844,\n",
       " -1.1377817772481367,\n",
       " -1.1378297738336591,\n",
       " -1.137877680152018,\n",
       " -1.1379255976407499,\n",
       " -1.1379735490755531,\n",
       " -1.138021378283798,\n",
       " -1.1380688853981815,\n",
       " -1.1381159559079166,\n",
       " -1.1381626716719868,\n",
       " -1.1382091677135315,\n",
       " -1.1382555548282425,\n",
       " -1.138301836551455,\n",
       " -1.1383479901314821,\n",
       " -1.1383940024655481,\n",
       " -1.1384398797879776,\n",
       " -1.1384856160148746,\n",
       " -1.1385311709073536,\n",
       " -1.138576515359415,\n",
       " -1.1386216223242152,\n",
       " -1.138666503619224,\n",
       " -1.1387111482755594,\n",
       " -1.1387556034941708,\n",
       " -1.1387999260695463,\n",
       " -1.1388443016026215,\n",
       " -1.1388888908841066,\n",
       " -1.1389339182889788,\n",
       " -1.1389794489227463,\n",
       " -1.1390255517780814,\n",
       " -1.1390721566571111,\n",
       " -1.1391192453475636,\n",
       " -1.1391667509341383,\n",
       " -1.139214649529341,\n",
       " -1.1392628656446364,\n",
       " -1.1393112969663852,\n",
       " -1.1393597732788248,\n",
       " -1.1394080756118221,\n",
       " -1.139455983916745,\n",
       " -1.1395032956032,\n",
       " -1.1395499223480723,\n",
       " -1.139595849875421,\n",
       " -1.1396411718961752,\n",
       " -1.1396860041246595,\n",
       " -1.1397304748660044,\n",
       " -1.1397746856682773,\n",
       " -1.139818703416031,\n",
       " -1.139862581723853,\n",
       " -1.1399063469048294,\n",
       " -1.13995004531467,\n",
       " -1.1399936986036845,\n",
       " -1.1400373493536555]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mdgp.experiments.sphere.fit import train\n",
    "\n",
    "train(dataset, model, fit_args, device='cpu', model_args=model_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-1.5385)\n",
      "tensor(1.4754)\n",
      "TLL: 1.4753534411584655, MSE: 2.9211824935749977\n",
      "{'tll': 1.4753534411584655, 'mse': 2.9211824935749977}\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad(), gpytorch.settings.lazily_evaluate_kernels(True):\n",
    "    model.eval()\n",
    "    out = model.likelihood(model(dataset.test_x))\n",
    "    print(negative_log_predictive_density(out, dataset.test_y).mean())\n",
    "    print(test_log_likelihood(out, dataset.test_y).mean())\n",
    "    print(evaluate_deep(dataset, model, device='cpu', fit_args=fit_args))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-1.4674)\n",
      "tensor(1.4139)\n",
      "TLL: 1.4139029094540665, MSE: 3.371658927564193\n",
      "{'tll': 1.4139029094540665, 'mse': 3.371658927564193}\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad(), gpytorch.settings.lazily_evaluate_kernels(True):\n",
    "    model.eval()\n",
    "    out = model.likelihood(model(dataset.test_x))\n",
    "    print(negative_log_predictive_density(out, dataset.test_y).mean())\n",
    "    print(test_log_likelihood(out, dataset.test_y).mean())\n",
    "    print(evaluate_deep(dataset, model, device='cpu', fit_args=fit_args))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-1.5190)\n",
      "tensor(1.4419)\n",
      "TLL: 1.4418937102455684, MSE: 3.107017470473463\n",
      "{'tll': 1.4418937102455684, 'mse': 3.107017470473463}\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad(), gpytorch.settings.lazily_evaluate_kernels(True):\n",
    "    model.eval()\n",
    "    out = model.likelihood(model(dataset.test_x))\n",
    "    print(negative_log_predictive_density(out, dataset.test_y).mean())\n",
    "    print(test_log_likelihood(out, dataset.test_y).mean())\n",
    "    print(evaluate_deep(dataset, model, device='cpu', fit_args=fit_args))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-1.4927)\n",
      "tensor(1.4087)\n",
      "TLL: 1.4086610760522458, MSE: 3.310065180829759\n",
      "{'tll': 1.4086610760522458, 'mse': 3.310065180829759}\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad(), gpytorch.settings.lazily_evaluate_kernels(True):\n",
    "    model.eval()\n",
    "    out = model.likelihood(model(dataset.test_x))\n",
    "    print(negative_log_predictive_density(out, dataset.test_y).mean())\n",
    "    print(test_log_likelihood(out, dataset.test_y).mean())\n",
    "    print(evaluate_deep(dataset, model, device='cpu', fit_args=fit_args))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-1.6259)\n",
      "tensor(1.5755)\n",
      "TLL: 1.5755119609054846, MSE: 2.293658530675006\n",
      "{'tll': 1.5755119609054846, 'mse': 2.293658530675006}\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad(), gpytorch.settings.lazily_evaluate_kernels(True):\n",
    "    model.eval()\n",
    "    out = model.likelihood(model(dataset.test_x))\n",
    "    print(negative_log_predictive_density(out, dataset.test_y).mean())\n",
    "    print(test_log_likelihood(out, dataset.test_y).mean())\n",
    "    print(evaluate_deep(dataset, model, device='cpu', fit_args=fit_args))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-2.0060)\n",
      "tensor(1.9826)\n",
      "TLL: 1.9849100886333266, MSE: 0.9665258399276684\n",
      "{'tll': 1.9849100886333266, 'mse': 0.9665258399276684}\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad(), gpytorch.settings.lazily_evaluate_kernels(True):\n",
    "    model.eval()\n",
    "    out = model.likelihood(model(dataset.test_x))\n",
    "    print(negative_log_predictive_density(out, dataset.test_y).mean())\n",
    "    print(test_log_likelihood(out, dataset.test_y).mean())\n",
    "    print(evaluate_deep(dataset, model, device='cpu', fit_args=fit_args))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-1.5837)\n",
      "tensor(1.5150)\n",
      "TLL: 1.5150098232825242, MSE: 2.730845144096171\n",
      "{'tll': 1.5150098232825242, 'mse': 2.730845144096171}\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad(), gpytorch.settings.lazily_evaluate_kernels(True):\n",
    "    model.eval()\n",
    "    out = model.likelihood(model(dataset.test_x))\n",
    "    print(negative_log_predictive_density(out, dataset.test_y).mean())\n",
    "    print(test_log_likelihood(out, dataset.test_y).mean())\n",
    "    print(evaluate_deep(dataset, model, device='cpu', fit_args=fit_args))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-1.5837)\n",
      "tensor(1.5150)\n",
      "TLL: 1.5150098232825242, MSE: 2.730845144096171\n",
      "{'tll': 1.5150098232825242, 'mse': 2.730845144096171}\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad(), gpytorch.settings.lazily_evaluate_kernels(True):\n",
    "    model.eval()\n",
    "    out = model.likelihood(model(dataset.test_x))\n",
    "    print(negative_log_predictive_density(out, dataset.test_y).mean())\n",
    "    print(test_log_likelihood(out, dataset.test_y).mean())\n",
    "    print(evaluate_deep(dataset, model, device='cpu', fit_args=fit_args))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-1.4540)\n",
      "tensor(1.4963)\n",
      "TLL: 1.4976224392447333, MSE: 3.171534558223885\n",
      "{'tll': 1.4976224392447333, 'mse': 3.171534558223885}\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad(), gpytorch.settings.lazily_evaluate_kernels(True):\n",
    "    model.eval()\n",
    "    out = model.likelihood(model(dataset.test_x))\n",
    "    print(negative_log_predictive_density(out, dataset.test_y).mean())\n",
    "    print(test_log_likelihood(out, dataset.test_y).mean())\n",
    "    print(evaluate_deep(dataset, model, device='cpu', fit_args=fit_args))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-1.7925)\n",
      "tensor(1.7560)\n",
      "TLL: 1.7580813852959216, MSE: 1.6493648474350493\n",
      "{'tll': 1.7580813852959216, 'mse': 1.6493648474350493}\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad(), gpytorch.settings.lazily_evaluate_kernels(True):\n",
    "    model.eval()\n",
    "    out = model.likelihood(model(dataset.test_x))\n",
    "    print(negative_log_predictive_density(out, dataset.test_y).mean())\n",
    "    print(test_log_likelihood(out, dataset.test_y).mean())\n",
    "    print(evaluate_deep(dataset, model, device='cpu', fit_args=fit_args))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-1.4769)\n",
      "tensor(1.4387)\n",
      "TLL: 1.4362026696876082, MSE: 3.220999641748814\n",
      "{'tll': 1.4362026696876082, 'mse': 3.220999641748814}\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad(), gpytorch.settings.lazily_evaluate_kernels(True):\n",
    "    model.eval()\n",
    "    out = model.likelihood(model(dataset.test_x))\n",
    "    print(negative_log_predictive_density(out, dataset.test_y).mean())\n",
    "    print(test_log_likelihood(out, dataset.test_y).mean())\n",
    "    print(evaluate_deep(dataset, model, device='cpu', fit_args=fit_args))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-1.5306)\n",
      "tensor(1.5914)\n",
      "TLL: 1.5941970710467066, MSE: 2.7187909138725166\n",
      "{'tll': 1.5941970710467066, 'mse': 2.7187909138725166}\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad(), gpytorch.settings.lazily_evaluate_kernels(True):\n",
    "    model.eval()\n",
    "    out = model.likelihood(model(dataset.test_x))\n",
    "    print(negative_log_predictive_density(out, dataset.test_y).mean())\n",
    "    print(test_log_likelihood(out, dataset.test_y).mean())\n",
    "    print(evaluate_deep(dataset, model, device='cpu', fit_args=fit_args))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-1.4990)\n",
      "tensor(1.4258)\n",
      "TLL: 1.4258268771968479, MSE: 3.225532577392901\n",
      "{'tll': 1.4258268771968479, 'mse': 3.225532577392901}\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad(), gpytorch.settings.lazily_evaluate_kernels(True):\n",
    "    model.eval()\n",
    "    out = model.likelihood(model(dataset.test_x))\n",
    "    print(negative_log_predictive_density(out, dataset.test_y).mean())\n",
    "    print(test_log_likelihood(out, dataset.test_y).mean())\n",
    "    print(evaluate_deep(dataset, model, device='cpu', fit_args=fit_args))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-2.1232)\n",
      "tensor(2.1673)\n",
      "TLL: 2.1659141491474663, MSE: 0.8473110577170997\n",
      "{'tll': 2.1659141491474663, 'mse': 0.8473110577170997}\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad(), gpytorch.settings.lazily_evaluate_kernels(True):\n",
    "    model.eval()\n",
    "    out = model.likelihood(model(dataset.test_x))\n",
    "    print(negative_log_predictive_density(out, dataset.test_y).mean())\n",
    "    print(test_log_likelihood(out, dataset.test_y).mean())\n",
    "    print(evaluate_deep(dataset, model, device='cpu', fit_args=fit_args))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-1.4322)\n",
      "tensor(1.4708)\n",
      "TLL: 1.4691835160955424, MSE: 3.355063199836631\n",
      "{'tll': 1.4691835160955424, 'mse': 3.355063199836631}\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad(), gpytorch.settings.lazily_evaluate_kernels(True):\n",
    "    model.eval()\n",
    "    out = model.likelihood(model(dataset.test_x, sample='elementwise'))\n",
    "    print(negative_log_predictive_density(out, dataset.test_y).mean())\n",
    "    print(test_log_likelihood(out, dataset.test_y).mean())\n",
    "    print(evaluate_deep(dataset, model, device='cpu', fit_args=fit_args))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mdgp_uci",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
